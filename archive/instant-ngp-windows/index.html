<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="author" content="Mert Cobanov" />
      <link rel="shortcut icon" href="../../img/favicon.ico" />
    <title>Instang NGP - Cobanov</title>
    <link rel="stylesheet" href="../../css/theme.css" />
    <link rel="stylesheet" href="../../css/theme_extra.css" />
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.5.0/styles/github.min.css" />
    
      <script>
        // Current page data
        var mkdocs_page_name = "Instang NGP";
        var mkdocs_page_input_path = "archive/instant-ngp-windows.md";
        var mkdocs_page_url = null;
      </script>
    
    <script src="../../js/jquery-3.6.0.min.js" defer></script>
    <!--[if lt IE 9]>
      <script src="../../js/html5shiv.min.js"></script>
    <![endif]-->
      <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.5.0/highlight.min.js"></script>
      <script>hljs.initHighlightingOnLoad();</script> 
</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side stickynav">
    <div class="wy-side-scroll">
      <div class="wy-side-nav-search">
          <a href="../.." class="icon icon-home"> Cobanov
        </a><div role="search">
  <form id ="rtd-search-form" class="wy-form" action="../../search.html" method="get">
      <input type="text" name="q" placeholder="Search docs" title="Type search term here" />
  </form>
</div>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption"><span class="caption-text">Blog</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../..">Hello ðŸ‘‹</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../reading-list/">2023 Reading List</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../helpers/">Helper one-liners</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../new-macbook/">New Macbook Installation</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../cyberpunk/">Cypherpunk Manifesto</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../python-conf/">Doing Python Configuration Right</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../windows-wsl-ssh/">Windows WSL Activate SSH</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../nerf/">NeRF</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../instagram/">Instagram Non-followers</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">Portfolio</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../../portfolio/">Hey</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">About</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../../about/">Main Page</a>
                  </li>
              </ul>
      </div>
    </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">
      <nav class="wy-nav-top" role="navigation" aria-label="Mobile navigation menu">
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../..">Cobanov</a>
        
      </nav>
      <div class="wy-nav-content">
        <div class="rst-content"><div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="../.." class="icon icon-home" alt="Docs"></a> &raquo;</li>
      <li>Instang NGP</li>
    <li class="wy-breadcrumbs-aside">
    </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
            <div class="section" itemprop="articleBody">
              
                <h1 id="instant-neural-graphics-primitives">Instant Neural Graphics Primitives !</h1>
<h2 id="requirements">Requirements</h2>
<ul>
<li>An <strong>NVIDIA GPU</strong>; tensor cores increase performance when available. All shown results come from an RTX 3090.</li>
<li>Python ver: 3.9.*</li>
<li><a href="https://docs.microsoft.com/en-us/visualstudio/releases/2019/history">Visual Studio Community 2019</a> (Latest the best, ~8GB) Below are the install requirements
  <img alt="image" src="https://user-images.githubusercontent.com/29135514/151634222-6ac236c9-5fa7-4762-9144-73e50959cb65.png" /></li>
<li><strong><a href="https://developer.nvidia.com/cuda-downloads?target_os=Windows&amp;target_arch=x86_64&amp;target_version=10&amp;target_type=exe_network">CUDA</a> v11.6</strong>. You can check ur CUDA version via <code>nvcc --version</code> in any prompt and if it's not CUDA11.6, refer to <a href="https://github.com/bycloudai/SwapCudaVersionWindows">this</a> to swap/install the correct version.</li>
<li>On some machines, <code>pyexr</code> refuses to install via <code>pip</code>. This can be resolved by installing OpenEXR from <a href="https://www.lfd.uci.edu/~gohlke/pythonlibs/#openexr">here</a>. See later.</li>
<li>This installation tutorial will be using Anaconda. Download anaconda prompt <a href="https://www.anaconda.com/products/individual">here</a>.</li>
<li><strong><a href="https://developer.nvidia.com/optix">OptiX</a> 7.3 or higher</strong> for faster mesh SDF training. You need to either login or join to obtain the installer. Set the system environment variables <code>OptiX_INSTALL_DIR</code> to the installation directory if it is not discovered automatically. Should look like this: <img alt="image" src="https://user-images.githubusercontent.com/29135514/151631220-7a934f5c-c299-41ab-a44e-184e2dc142b9.png" /></li>
</ul>
<h2 id="compilation">Compilation</h2>
<p>copy these files <code>C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6\extras\visual_studio_integration\MSBuildExtensions</code>
to here <code>C:\Program Files (x86)\Microsoft Visual Studio\2019\Community\MSBuild\Microsoft\VC\v160\BuildCustomizations</code></p>
<p><code>cd</code> into a directory that you want to download the codes at. Eg. <code>cd F:\Tutorial\ngp\</code></p>
<p>Begin by cloning this repository and all its submodules using the following command (if you don't have git, download <a href="https://git-scm.com/download/win">here</a> and add to path):</p>
<pre><code class="language-sh">$ git clone --recursive https://github.com/nvlabs/instant-ngp
$ cd instant-ngp
</code></pre>
<p>if your python is not 3.9 (check with command <code>python --version</code>) then you need to run the following command to get it to ver 3.9.*</p>
<pre><code>conda install python=3.9
</code></pre>
<p>Then, open <strong>Developer Command Prompt</strong>, you can find this in your search bar.</p>
<p><img alt="image" src="https://user-images.githubusercontent.com/29135514/151631759-ff8538ab-74c6-4c7b-962e-d7b097e819db.png" /></p>
<p>Then <code>cd</code> to where you cloned your repository so you are in its root folder <code>/instant-ng/</code>:</p>
<pre><code class="language-sh">cmake . -B build
cmake --build build --config RelWithDebInfo -j 16
</code></pre>
<p>If the any of these build fails, please consult <a href="https://github.com/NVlabs/instant-ngp#troubleshooting-compile-errors">this list of possible fixes</a> before opening an issue.</p>
<p>If automatic GPU architecture detection fails, (as can happen if you have multiple GPUs installed), set the <code>TCNN_CUDA_ARCHITECTURES</code> enivonment variable for the GPU you would like to use. The following table lists the values for common GPUs. If your GPU is not listed, consult <a href="https://developer.nvidia.com/cuda-gpus">this exhaustive list</a>.</p>
<table>
<thead>
<tr>
<th>RTX 30X0</th>
<th>A100</th>
<th>RTX 20X0</th>
<th>TITAN V / V100</th>
<th>GTX 10X0 / TITAN Xp</th>
<th>GTX 9X0</th>
<th>K80</th>
</tr>
</thead>
<tbody>
<tr>
<td>86</td>
<td>80</td>
<td>75</td>
<td>70</td>
<td>61</td>
<td>52</td>
<td>37</td>
</tr>
</tbody>
</table>
<h2 id="interactive-training-and-rendering-on-custom-image-sets">Interactive Training and Rendering on Custom Image Sets</h2>
<p>Install <a href="https://github.com/colmap/colmap/releases/tag/3.7">COLMAP</a>, I used ver 3.7</p>
<p>Add it to your system environment variables at Environment Variables &gt; System Variables Path &gt; Edit environment variable</p>
<p><img alt="image" src="https://user-images.githubusercontent.com/29135514/151633058-e45f9220-c417-4249-aff3-09d29c1a4e9b.png" /></p>
<p>open anaconda prompt, if you don't have you don't have you can get it <a href="https://www.anaconda.com/products/individual">here</a>
<code>cd</code> into isntant-ngp as root</p>
<pre><code class="language-sh">conda create -n ngp python=3.9
conda activate ngp
pip install -r requirements.txt
</code></pre>
<p>if <code>pyexr</code> cannot be installed via <code>pip install pyexr</code>, download <a href="https://www.lfd.uci.edu/~gohlke/pythonlibs/#openexr">OpenEXRâ€‘1.3.2â€‘cp39â€‘cp39â€‘win_amd64.whl</a> and move it to your root folder. Then you can run:</p>
<pre><code>pip install OpenEXR-1.3.2-cp39-cp39-win_amd64.whl
</code></pre>
<p>Place your custom image set under <code>data/&lt;image_set_name&gt;</code></p>
<p>Get <code>transform.json</code> from the following command. Insert your path to your images at <code>&lt;image/path&gt;</code></p>
<pre><code class="language-sh">python scripts/colmap2nerf.py --colmap_matcher exhaustive --run_colmap --aabb_scale 16 --images &lt;image/path&gt;
</code></pre>
<p><code>transform.json</code> will be generated at the root folder, drag and drop it into your <code>data/&lt;image_set_name&gt;</code> folder.</p>
<p>You have to reorganize the folder structure due to how <code>transforms.json</code> is created...</p>
<p>For example:</p>
<p>File Structure <strong>BEFORE</strong> generating transform.json</p>
<pre><code>ðŸ“‚instant-ngp/ # this is root
â”œâ”€â”€ ðŸ“‚data/
â”‚   â”œâ”€â”€ ðŸ“‚toy_truck/
â”‚   â”‚   â”œâ”€â”€ ðŸ“œtoy_truck_001.jpg
â”‚   â”‚   â”œâ”€â”€ ðŸ“œtoy_truck_002.jpg
â”‚   â”‚   â”‚...
â”‚   â”‚...
â”‚...
</code></pre>
<p>File Structure <strong>AFTER</strong> generating transform.json</p>
<pre><code>ðŸ“‚instant-ngp/ # this is root
â”œâ”€â”€ ðŸ“‚data/
â”‚   â”œâ”€â”€ ðŸ“‚toy_truck/
â”‚   â”‚   â”œâ”€â”€ ðŸ“œtransforms.json/
â”‚   â”‚   â”œâ”€â”€ ðŸ“‚data/
â”‚   â”‚   â”‚   â”œâ”€â”€ ðŸ“‚toy_truck/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ ðŸ“œtoy_truck_001.jpg
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ ðŸ“œtoy_truck_002.jpg
â”‚   â”‚   â”‚   â”‚   â”‚...
â”‚   â”‚   â”‚   â”‚...
â”‚   â”‚   â”‚...
â”‚   â”‚...
â”‚...
</code></pre>
<p>Note: adjusting the <code>"aabb_scale"</code> inside <code>transform.json</code> can reduce load on GPU VRAM. The lower the value the less intensive it'll be.</p>
<p>Finally, to run instant-ngp:</p>
<pre><code class="language-sh">&lt;path_to_your_ngp&gt;\instant-ngp\build\testbed.exe --scene data/&lt;image_set_name&gt;
</code></pre>
<p>eg.</p>
<pre><code>C:\user\user\download\instant-ngp\build\testbed.exe --scene data/toy_truck
</code></pre>
<p>And it should launch the GUI and everything amazing with it</p>
<h2 id="rendering-custom-camera-path">Rendering custom camera path</h2>
<ol>
<li>May need to install more dependencies. Install <code>pip install tqdm scipy pillow opencv-python</code>, <code>conda install -c conda-forge ffmpeg</code>, might be needed in the conda virtual environment. Refer to installation of <code>pyexr</code> above in the installation section if you didn't install that too.</li>
<li>Train any image set like above.</li>
<li>After you have reached a point that you are satisfied with your training, save a Snapshot on the GUI. (one of the tabs &amp; no need to edit the path &amp; the name)</li>
<li>Find another GUI called camera path, it'll play hide and seek with you but it is there so find that window.</li>
<li>The GUI is so well made, if you know how to use any 3D engine, it's really similar. Add camera path will give you a new angle of the camera.</li>
<li>After you have finished adding your camera points, save the camera path. (no need to edit the path &amp; the name)</li>
<li>Render the path with the following command:</li>
</ol>
<pre><code class="language-sh">python scripts/render.py --scene &lt;scene_path&gt; --n_seconds &lt;seconds&gt; --fps &lt;fps&gt; --render_name &lt;name&gt; --width &lt;resolution_width&gt; --height &lt;resolution_height&gt;

</code></pre>
<p>eg.</p>
<pre><code class="language-sh">python scripts/render.py --scene data/toy --n_seconds 5 --fps 60 --render_name test --width 1920 --height 1080
</code></pre>
<p>Your video will be saved at root. You might have to play around with the <code>fps</code> and <code>n_seconds</code> to speed up or slow down. I couldn't get it accurately because of the lack of information and this is the best I could come up with. To be honest, this is only a short-term solution too, since the author has promised to publish an official one. So stay tuned!</p>
<p>And my fork edits end here.</p>
<h2 id="interactive-training-and-rendering">Interactive training and rendering</h2>
<p><img src="docs/assets_readme/testbed.png" width="100%"/></p>
<p>This codebase comes with an interactive testbed that includes many features beyond our academic publication:</p>
<ul>
<li>Additional training features, such as extrinsics and intrinsics optimization.</li>
<li>Marching cubes for <code>NeRF-&gt;Mesh</code> and <code>SDF-&gt;Mesh</code> conversion.</li>
<li>A spline-based camera path editor to create videos.</li>
<li>Debug visualizations of the activations of every neuron input and output.</li>
<li>And many more task-specific settings.</li>
<li>See also our <a href="https://nvlabs.github.io/instant-ngp/assets/mueller2022instant.mp4">one minute demonstration video of the tool</a>.</li>
</ul>
<h3 id="nerf-fox">NeRF fox</h3>
<p>One test scene is provided in this repository, using a small number of frames from a casually captured phone video:</p>
<pre><code class="language-sh">instant-ngp$ ./build/testbed --scene data/nerf/fox
</code></pre>
<p><img src="docs/assets_readme/fox.png"/></p>
<p>Alternatively, download any NeRF-compatible scene (e.g. <a href="https://drive.google.com/drive/folders/1JDdLGDruGNXWnM1eqY1FNL9PlStjaKWi">from the NeRF authors' drive</a>).
Now you can run:</p>
<pre><code class="language-sh">instant-ngp$ ./build/testbed --scene data/nerf_synthetic/lego/transforms_train.json
</code></pre>
<p>For more information about preparing datasets for use with our NeRF implementation, please see <a href="docs/nerf_dataset_tips.md">this document</a>.</p>
<h3 id="sdf-armadillo">SDF armadillo</h3>
<pre><code class="language-sh">instant-ngp$ ./build/testbed --scene data/sdf/armadillo.obj
</code></pre>
<p><img src="docs/assets_readme/armadillo.png"/></p>
<h3 id="image-of-einstein">Image of Einstein</h3>
<pre><code class="language-sh">instant-ngp$ ./build/testbed --scene data/image/albert.exr
</code></pre>
<p><img src="docs/assets_readme/albert.png"/></p>
<p>To reproduce the gigapixel results, download, for example, <a href="https://www.flickr.com/photos/trevor_dobson_inefekt69/29314390837">the Tokyo image</a> and convert it to <code>.bin</code> using the <code>scripts/image2bin.py</code> script. This custom format improves compatibility and loading speed when resolution is high. Now you can run:</p>
<pre><code class="language-sh">instant-ngp$ ./build/testbed --scene data/image/tokyo.bin
</code></pre>
<h3 id="volume-renderer">Volume Renderer</h3>
<p>Download the <a href="https://drive.google.com/drive/folders/1SuycSAOSG64k2KLV7oWgyNWyCvZAkafK?usp=sharing">nanovdb volume for the Disney cloud</a>, which is derived <a href="https://disneyanimation.com/data-sets/?drawer=/resources/clouds/">from here</a> (<a href="https://media.disneyanimation.com/uploads/production/data_set_asset/6/asset/License_Cloud.pdf">CC BY-SA 3.0</a>).</p>
<pre><code class="language-sh">instant-ngp$ ./build/testbed --mode volume --scene data/volume/wdas_cloud_quarter.nvdb
</code></pre>
<p><img src="docs/assets_readme/cloud.png"/></p>
<h2 id="python-bindings">Python bindings</h2>
<p>To conduct controlled experiments in an automated fashion, all features from the interactive testbed (and more!) have Python bindings that can be easily instrumented.
For an example of how the <code>./build/testbed</code> application can be implemented and extended from within Python, see <code>./scripts/run.py</code>, which supports a superset of the command line arguments that <code>./build/testbed</code> does.</p>
<p>Happy hacking!</p>
<h2 id="troubleshooting-compile-errors">Troubleshooting compile errors</h2>
<p>Before investigating further, make sure all submodules are up-to-date and try compiling again.</p>
<pre><code class="language-sh">instant-ngp$ git submodule sync --recursive
instant-ngp$ git submodule update --init --recursive
</code></pre>
<p>If <strong>instant-ngp</strong> still fails to compile, update CUDA as well as your compiler to the latest versions you can install on your system. It is crucial that you update <em>both</em>, as newer CUDA versions are not always compatible with earlier compilers and vice versa.
If your problem persists, consult the following table of known issues.</p>
<table>
<thead>
<tr>
<th>Problem</th>
<th>Resolution</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>CMake error:</strong> No CUDA toolset found / CUDA_ARCHITECTURES is empty for target "cmTC_0c70f"</td>
<td><strong>Windows:</strong> the Visual Studio CUDA integration was not installed correctly. Follow <a href="https://github.com/mitsuba-renderer/mitsuba2/issues/103#issuecomment-618378963">these instructions</a> to fix the problem without re-installing CUDA. (<a href="https://github.com/NVlabs/instant-ngp/issues/18">#18</a>)</td>
</tr>
<tr>
<td></td>
<td><strong>Linux:</strong> Environment variables for your CUDA installation are probably incorrectly set. You may work around the issue using <code>cmake . -B build -DCMAKE_CUDA_COMPILER=/usr/local/cuda-&lt;your cuda version&gt;/bin/nvcc</code> (<a href="https://github.com/NVlabs/instant-ngp/issues/28">#28</a>)</td>
</tr>
<tr>
<td><strong>CMake error:</strong> No known features for CXX compiler "MSVC"</td>
<td>Reinstall Visual Studio &amp; make sure you run CMake from a developer shell. (<a href="https://github.com/NVlabs/instant-ngp/issues/21">#21</a>)</td>
</tr>
<tr>
<td><strong>Compile error:</strong> undefined references to "cudaGraphExecUpdate" / identifier "cublasSetWorkspace" is undefined</td>
<td>Update your CUDA installation (which is likely 11.0) to 11.3 or higher. (<a href="https://github.com/NVlabs/instant-ngp/issues/34">#34</a> <a href="https://github.com/NVlabs/instant-ngp/issues/41">#41</a> <a href="https://github.com/NVlabs/instant-ngp/issues/42">#42</a>)</td>
</tr>
<tr>
<td><strong>Compile error:</strong> too few arguments in function call</td>
<td>Update submodules with the above two <code>git</code> commands. (<a href="https://github.com/NVlabs/instant-ngp/issues/37">#37</a> <a href="https://github.com/NVlabs/instant-ngp/issues/52">#52</a>)</td>
</tr>
<tr>
<td><strong>Python error:</strong> No module named 'pyngp'</td>
<td>It is likely that CMake did not detect your Python installation and therefore did not build <code>pyngp</code>. Check CMake logs to verify this. If <code>pyngp</code> was built in a different folder than <code>instant-ngp/build</code>, Python will be unable to detect it and you have to supply the full path to the import statement. (<a href="https://github.com/NVlabs/instant-ngp/issues/43">#43</a>)</td>
</tr>
</tbody>
</table>
<p>If you cannot find your problem in the table, please feel free to <a href="https://github.com/NVlabs/instant-ngp/issues/new">open an issue</a> and ask for help.</p>
<h2 id="thanks">Thanks</h2>
<p>Many thanks to <a href="https://research.nvidia.com/person/jonathan-tremblay">Jonathan Tremblay</a> and <a href="https://developer.nvidia.com/blog/author/atao/">Andrew Tao</a> for testing early versions of this codebase and to Arman Toorians and Saurabh Jain for the factory robot dataset.
We also thank <a href="https://github.com/grey-area">Andrew Webb</a> for noticing that one of the prime numbers in the spatial hash was not actually prime; this has been fixed since.</p>
<p>This project makes use of a number of awesome open source libraries, including:</p>
<ul>
<li><a href="https://github.com/NVlabs/tiny-cuda-nn">tiny-cuda-nn</a> for fast CUDA MLP networks</li>
<li><a href="https://github.com/syoyo/tinyexr">tinyexr</a> for EXR format support</li>
<li><a href="https://github.com/tinyobjloader/tinyobjloader">tinyobjloader</a> for OBJ format support</li>
<li><a href="https://github.com/nothings/stb">stb_image</a> for PNG and JPEG support</li>
<li><a href="https://github.com/ocornut/imgui">Dear ImGui</a> an excellent immediate mode GUI library</li>
<li><a href="https://eigen.tuxfamily.org/index.php?title=Main_Page">Eigen</a> a C++ template library for linear algebra</li>
<li><a href="https://github.com/pybind/pybind11">pybind11</a> for seamless C++ / Python interop</li>
<li>and others! See the <code>dependencies</code> folder.</li>
</ul>
<p>Many thanks to the authors of these brilliant projects!</p>
<h2 id="license-and-citation">License and Citation</h2>
<pre><code class="language-bibtex">@article{mueller2022instant,
    title = {Instant Neural Graphics Primitives with a Multiresolution Hash Encoding},
    author = {Thomas M\&quot;uller and Alex Evans and Christoph Schied and Alexander Keller},
    journal = {arXiv:2201.05989},
    year = {2022},
    month = jan
}
</code></pre>
<p>Copyright Â© 2022, NVIDIA Corporation. All rights reserved.</p>
<p>This work is made available under the Nvidia Source Code License-NC. Click <a href="LICENSE.txt">here</a> to view a copy of this license.</p>
              
            </div>
          </div><footer>

  <hr/>

  <div role="contentinfo">
    <!-- Copyright etc -->
  </div>

  Built with <a href="https://www.mkdocs.org/">MkDocs</a> using a <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
</footer>
          
        </div>
      </div>

    </section>

  </div>

  <div class="rst-versions" role="note" aria-label="Versions">
  <span class="rst-current-version" data-toggle="rst-current-version">
    
    
    
  </span>
</div>
    <script>var base_url = '../..';</script>
    <script src="../../js/theme_extra.js" defer></script>
    <script src="../../js/theme.js" defer></script>
      <script src="../../search/main.js" defer></script>
    <script defer>
        window.onload = function () {
            SphinxRtdTheme.Navigation.enable(true);
        };
    </script>

</body>
</html>
