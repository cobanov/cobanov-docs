{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Mert Cobanov #0001 Username: @cobanov Job: Data Scientist, Refik Anadol Studio Date of Birth: 02.01.1996 About Community lover, data scientist and generative artist. I love to share what I know, so I try to provide free data science and machine learning education to everyone on my twitter and youtube channel. I teach at several schools and communities each year. I work as a data scientist at Refik Anadol Studio , where we do great artistic works with my excellent team, and we try to digitize the memories of humanity to immortalize it. Links More You can see my work in my github repos and my humble portfolio . I really enjoy writing minimal tools that make the lives of software developers easier, building end-to-end pipelines, and doing AI artistic painting works that motivate me immensely. I also digitize and repair old video tapes and bring them to high resolution and high fps forms.","title":"Main Page"},{"location":"#mert-cobanov-0001","text":"Username: @cobanov Job: Data Scientist, Refik Anadol Studio Date of Birth: 02.01.1996","title":"Mert Cobanov #0001"},{"location":"#about","text":"Community lover, data scientist and generative artist. I love to share what I know, so I try to provide free data science and machine learning education to everyone on my twitter and youtube channel. I teach at several schools and communities each year. I work as a data scientist at Refik Anadol Studio , where we do great artistic works with my excellent team, and we try to digitize the memories of humanity to immortalize it.","title":"About"},{"location":"#links","text":"","title":"Links"},{"location":"#more","text":"You can see my work in my github repos and my humble portfolio . I really enjoy writing minimal tools that make the lives of software developers easier, building end-to-end pipelines, and doing AI artistic painting works that motivate me immensely. I also digitize and repair old video tapes and bring them to high resolution and high fps forms.","title":"More"},{"location":"cyberpunk/","text":"Bir Cypherpunk'\u0131n Manifestosu by Eric Hughes Elektronik \u00e7a\u011fda a\u00e7\u0131k bir toplum i\u00e7in mahremiyet gereklidir. Gizlilik gizlilik de\u011fildir. \u00d6zel bir konu, t\u00fcm d\u00fcnyan\u0131n bilmesini istemedi\u011fi bir \u015feydir, ancak gizli bir konu, kimsenin bilmesini istemedi\u011fi bir \u015feydir. Gizlilik, kendini d\u00fcnyaya se\u00e7ici olarak g\u00f6sterme g\u00fcc\u00fcd\u00fcr. E\u011fer iki taraf bir t\u00fcr anla\u015fmaya sahipse, her birinin etkile\u015fimlerinin bir an\u0131s\u0131 vard\u0131r. Her bir taraf bununla ilgili kendi an\u0131lar\u0131 hakk\u0131nda konu\u015fabilir; kimse bunu nas\u0131l engelleyebilir? Buna kar\u015f\u0131 yasalar \u00e7\u0131kar\u0131labilir, ancak konu\u015fma \u00f6zg\u00fcrl\u00fc\u011f\u00fc, mahremiyetten bile daha fazlas\u0131, a\u00e7\u0131k bir toplum i\u00e7in esast\u0131r; hi\u00e7bir konu\u015fmay\u0131 k\u0131s\u0131tlamamaya \u00e7al\u0131\u015f\u0131yoruz. Ayn\u0131 forumda bir\u00e7ok taraf birlikte konu\u015fursa, her biri di\u011ferleriyle konu\u015fabilir ve bireyler ve di\u011fer taraflar hakk\u0131ndaki bilgileri bir araya toplayabilir. Elektronik ileti\u015fimin g\u00fcc\u00fc bu t\u00fcr grup konu\u015fmalar\u0131n\u0131 m\u00fcmk\u00fcn k\u0131lm\u0131\u015ft\u0131r ve sadece biz isteyebilece\u011fimiz i\u00e7in ortadan kalkmayacakt\u0131r. Gizlili\u011fi arzulad\u0131\u011f\u0131m\u0131z i\u00e7in, bir i\u015flemin her bir taraf\u0131n\u0131n yaln\u0131zca o i\u015flem i\u00e7in do\u011frudan gerekli olan\u0131 bilmesini sa\u011flamal\u0131y\u0131z. Herhangi bir bilgi konu\u015fulabilece\u011finden, m\u00fcmk\u00fcn oldu\u011funca az a\u00e7\u0131klama yapt\u0131\u011f\u0131m\u0131zdan emin olmal\u0131y\u0131z. \u00c7o\u011fu durumda ki\u015fisel kimlik belirgin de\u011fildir. Bir ma\u011fazadan bir dergi sat\u0131n ald\u0131\u011f\u0131mda ve katiyere nakit verdi\u011fimde, kim oldu\u011fumu bilmeme gerek yok. Elektronik posta sa\u011flay\u0131c\u0131mdan mesaj g\u00f6nderip almas\u0131n\u0131 istedi\u011fimde, sa\u011flay\u0131c\u0131m\u0131n kiminle konu\u015ftu\u011fumu, ne s\u00f6yledi\u011fimi veya ba\u015fkalar\u0131n\u0131n bana ne s\u00f6yledi\u011fini bilmesine gerek yoktur; sa\u011flay\u0131c\u0131m\u0131n sadece mesaj\u0131 oraya nas\u0131l ula\u015ft\u0131raca\u011f\u0131n\u0131 ve onlara ne kadar \u00fccret bor\u00e7lu oldu\u011fumu bilmesi gerekiyor. Kimli\u011fim i\u015flemin alt\u0131nda yatan mekanizma taraf\u0131ndan if\u015fa edildi\u011finde, mahremiyetim yok. Burada se\u00e7ici olarak kendimi if\u015fa edemem; her zaman yapmal\u0131y\u0131m kendimi if\u015fa et. Bu nedenle, a\u00e7\u0131k bir toplumda mahremiyet, anonim i\u015flem sistemleri gerektirir. \u015eimdiye kadar, nakit bu t\u00fcr birincil sistem olmu\u015ftur. Anonim bir i\u015flem sistemi, gizli bir i\u015flem sistemi de\u011fildir. Anonim bir sistem, bireylere kimliklerini istendi\u011finde ve yaln\u0131zca istendi\u011finde if\u015fa etme yetkisi verir; mahremiyetin \u00f6z\u00fc budur. A\u00e7\u0131k bir toplumda gizlilik de kriptografi gerektirir. Bir \u015fey s\u00f6ylersem, sadece niyet etti\u011fim ki\u015filer taraf\u0131ndan duyulmas\u0131n\u0131 isterim. Konu\u015fmam\u0131n i\u00e7eri\u011fi d\u00fcnyaya a\u00e7\u0131ksa, mahremiyetim yok. \u015eifrelemek, mahremiyet arzusunu belirtmektir ve zay\u0131f \u015fifreleme ile \u015fifrelemek, mahremiyet i\u00e7in \u00e7ok fazla arzu olmad\u0131\u011f\u0131n\u0131 belirtmektir. Ayr\u0131ca, varsay\u0131lan anonimlik oldu\u011funda, ki\u015finin kimli\u011fini g\u00fcvence ile ortaya \u00e7\u0131karmak i\u00e7in kriptografik imza gerekir. H\u00fck\u00fcmetlerin, \u015firketlerin veya di\u011fer b\u00fcy\u00fck, kimli\u011fi belirsiz kurulu\u015flar\u0131n, kendi yararlar\u0131 d\u0131\u015f\u0131nda bize mahremiyet vermelerini bekleyemeyiz. Bizim hakk\u0131m\u0131zda konu\u015fmak onlar\u0131n yarar\u0131nad\u0131r ve konu\u015fmalar\u0131n\u0131 beklemeliyiz. Konu\u015fmalar\u0131n\u0131 engellemeye \u00e7al\u0131\u015fmak, bilgi ger\u00e7ekleriyle sava\u015fmakt\u0131r. Bilgi sadece \u00f6zg\u00fcr olmak istemez, \u00f6zg\u00fcr olmay\u0131 arzular. Bilgi, mevcut depolama alan\u0131n\u0131 dolduracak \u015fekilde geni\u015fler. Bilgi, Rumor'un daha gen\u00e7, daha g\u00fc\u00e7l\u00fc kuzenidir; Bilgi, daha h\u0131zl\u0131d\u0131r, daha fazla g\u00f6ze sahiptir, daha fazlas\u0131n\u0131 bilir ve S\u00f6ylentiden daha az anlar. Herhangi bir mahremiyete sahip olmay\u0131 umuyorsak, kendi mahremiyetimizi savunmal\u0131y\u0131z. Bir araya gelmeli ve anonim i\u015flemlerin ger\u00e7ekle\u015fmesine izin veren sistemler olu\u015fturmal\u0131y\u0131z. \u0130nsanlar y\u00fczy\u0131llard\u0131r f\u0131s\u0131lt\u0131lar, karanl\u0131k, zarflar, kapal\u0131 kap\u0131lar, gizli tokala\u015fmalar ve kuryelerle kendi mahremiyetlerini savunuyorlar. Ge\u00e7mi\u015fin teknolojileri g\u00fc\u00e7l\u00fc bir mahremiyete izin vermiyordu, ancak elektronik teknolojiler izin veriyor. Biz Cypherpunk'lar, kendimizi anonim sistemler olu\u015fturmaya adad\u0131k. Gizlili\u011fimizi kriptografi, anonim posta y\u00f6nlendirme sistemleri, dijital imzalar ve elektronik para ile koruyoruz. Cypherpunk'lar kod yazar. Birinin mahremiyeti savunmak i\u00e7in yaz\u0131l\u0131m yazmas\u0131 gerekti\u011fini biliyoruz ve hepimiz bunu yapmad\u0131k\u00e7a mahremiyet elde edemeyece\u011fimiz i\u00e7in yazaca\u011f\u0131z. Kodumuzu Cypherpunk arkada\u015flar\u0131m\u0131z\u0131n pratik yap\u0131p onunla oynayabilmeleri i\u00e7in yay\u0131nl\u0131yoruz. Kodumuz, d\u00fcnya \u00e7ap\u0131nda herkesin kullan\u0131m\u0131 i\u00e7in \u00fccretsizdir. Yazd\u0131\u011f\u0131m\u0131z yaz\u0131l\u0131m\u0131 onaylamaman\u0131z pek umurumuzda de\u011fil. Yaz\u0131l\u0131m\u0131n yok edilemeyece\u011fini ve geni\u015f bir alana yay\u0131lm\u0131\u015f bir sistemin kapat\u0131lamayaca\u011f\u0131n\u0131 biliyoruz. \u015eifreleme temelde \u00f6zel bir eylem oldu\u011fundan, Cypherpunk'lar kriptografi ile ilgili d\u00fczenlemelerden \u015fikayet\u00e7idir. \u015eifreleme eylemi asl\u0131nda bilgiyi kamusal alandan kald\u0131r\u0131r. Kriptografiye kar\u015f\u0131 yasalar bile ancak bir ulusun s\u0131n\u0131r\u0131na ve \u015fiddetinin koluna kadar ula\u015f\u0131r. Kriptografi ka\u00e7\u0131n\u0131lmaz olarak t\u00fcm d\u00fcnyaya ve onunla birlikte m\u00fcmk\u00fcn k\u0131ld\u0131\u011f\u0131 anonim i\u015flem sistemlerine yay\u0131lacakt\u0131r. Mahremiyetin yayg\u0131nla\u015fmas\u0131 i\u00e7in bir sosyal s\u00f6zle\u015fmenin par\u00e7as\u0131 olmas\u0131 gerekir. \u0130nsanlar bir araya gelmeli ve bu sistemleri ortak yarar i\u00e7in kullanmal\u0131d\u0131r. Mahremiyet ancak, ki\u015finin toplumdaki hemcinslerinin i\u015fbirli\u011fi kadar geni\u015fler. Biz Cypherpunk'lar sorular\u0131n\u0131z\u0131 ve endi\u015felerinizi ar\u0131yoruz ve kendimizi kand\u0131rmamak i\u00e7in sizi me\u015fgul edebilece\u011fimizi umuyoruz. Bununla birlikte, baz\u0131lar\u0131 hedeflerimize kat\u0131lmayabilece\u011finden, rotam\u0131zdan ayr\u0131lmayaca\u011f\u0131z. Cypherpunks, a\u011flar\u0131 gizlilik i\u00e7in daha g\u00fcvenli hale getirmek i\u00e7in aktif olarak \u00e7al\u0131\u015f\u0131yor. H\u0131zla birlikte ilerleyelim. \u0130leriye. Eric Hughes < hughes@soda.berkeley.edu > 9 Mart 1993","title":"Cypherpunk Manifesto"},{"location":"cyberpunk/#bir-cypherpunkn-manifestosu","text":"by Eric Hughes Elektronik \u00e7a\u011fda a\u00e7\u0131k bir toplum i\u00e7in mahremiyet gereklidir. Gizlilik gizlilik de\u011fildir. \u00d6zel bir konu, t\u00fcm d\u00fcnyan\u0131n bilmesini istemedi\u011fi bir \u015feydir, ancak gizli bir konu, kimsenin bilmesini istemedi\u011fi bir \u015feydir. Gizlilik, kendini d\u00fcnyaya se\u00e7ici olarak g\u00f6sterme g\u00fcc\u00fcd\u00fcr. E\u011fer iki taraf bir t\u00fcr anla\u015fmaya sahipse, her birinin etkile\u015fimlerinin bir an\u0131s\u0131 vard\u0131r. Her bir taraf bununla ilgili kendi an\u0131lar\u0131 hakk\u0131nda konu\u015fabilir; kimse bunu nas\u0131l engelleyebilir? Buna kar\u015f\u0131 yasalar \u00e7\u0131kar\u0131labilir, ancak konu\u015fma \u00f6zg\u00fcrl\u00fc\u011f\u00fc, mahremiyetten bile daha fazlas\u0131, a\u00e7\u0131k bir toplum i\u00e7in esast\u0131r; hi\u00e7bir konu\u015fmay\u0131 k\u0131s\u0131tlamamaya \u00e7al\u0131\u015f\u0131yoruz. Ayn\u0131 forumda bir\u00e7ok taraf birlikte konu\u015fursa, her biri di\u011ferleriyle konu\u015fabilir ve bireyler ve di\u011fer taraflar hakk\u0131ndaki bilgileri bir araya toplayabilir. Elektronik ileti\u015fimin g\u00fcc\u00fc bu t\u00fcr grup konu\u015fmalar\u0131n\u0131 m\u00fcmk\u00fcn k\u0131lm\u0131\u015ft\u0131r ve sadece biz isteyebilece\u011fimiz i\u00e7in ortadan kalkmayacakt\u0131r. Gizlili\u011fi arzulad\u0131\u011f\u0131m\u0131z i\u00e7in, bir i\u015flemin her bir taraf\u0131n\u0131n yaln\u0131zca o i\u015flem i\u00e7in do\u011frudan gerekli olan\u0131 bilmesini sa\u011flamal\u0131y\u0131z. Herhangi bir bilgi konu\u015fulabilece\u011finden, m\u00fcmk\u00fcn oldu\u011funca az a\u00e7\u0131klama yapt\u0131\u011f\u0131m\u0131zdan emin olmal\u0131y\u0131z. \u00c7o\u011fu durumda ki\u015fisel kimlik belirgin de\u011fildir. Bir ma\u011fazadan bir dergi sat\u0131n ald\u0131\u011f\u0131mda ve katiyere nakit verdi\u011fimde, kim oldu\u011fumu bilmeme gerek yok. Elektronik posta sa\u011flay\u0131c\u0131mdan mesaj g\u00f6nderip almas\u0131n\u0131 istedi\u011fimde, sa\u011flay\u0131c\u0131m\u0131n kiminle konu\u015ftu\u011fumu, ne s\u00f6yledi\u011fimi veya ba\u015fkalar\u0131n\u0131n bana ne s\u00f6yledi\u011fini bilmesine gerek yoktur; sa\u011flay\u0131c\u0131m\u0131n sadece mesaj\u0131 oraya nas\u0131l ula\u015ft\u0131raca\u011f\u0131n\u0131 ve onlara ne kadar \u00fccret bor\u00e7lu oldu\u011fumu bilmesi gerekiyor. Kimli\u011fim i\u015flemin alt\u0131nda yatan mekanizma taraf\u0131ndan if\u015fa edildi\u011finde, mahremiyetim yok. Burada se\u00e7ici olarak kendimi if\u015fa edemem; her zaman yapmal\u0131y\u0131m kendimi if\u015fa et. Bu nedenle, a\u00e7\u0131k bir toplumda mahremiyet, anonim i\u015flem sistemleri gerektirir. \u015eimdiye kadar, nakit bu t\u00fcr birincil sistem olmu\u015ftur. Anonim bir i\u015flem sistemi, gizli bir i\u015flem sistemi de\u011fildir. Anonim bir sistem, bireylere kimliklerini istendi\u011finde ve yaln\u0131zca istendi\u011finde if\u015fa etme yetkisi verir; mahremiyetin \u00f6z\u00fc budur. A\u00e7\u0131k bir toplumda gizlilik de kriptografi gerektirir. Bir \u015fey s\u00f6ylersem, sadece niyet etti\u011fim ki\u015filer taraf\u0131ndan duyulmas\u0131n\u0131 isterim. Konu\u015fmam\u0131n i\u00e7eri\u011fi d\u00fcnyaya a\u00e7\u0131ksa, mahremiyetim yok. \u015eifrelemek, mahremiyet arzusunu belirtmektir ve zay\u0131f \u015fifreleme ile \u015fifrelemek, mahremiyet i\u00e7in \u00e7ok fazla arzu olmad\u0131\u011f\u0131n\u0131 belirtmektir. Ayr\u0131ca, varsay\u0131lan anonimlik oldu\u011funda, ki\u015finin kimli\u011fini g\u00fcvence ile ortaya \u00e7\u0131karmak i\u00e7in kriptografik imza gerekir. H\u00fck\u00fcmetlerin, \u015firketlerin veya di\u011fer b\u00fcy\u00fck, kimli\u011fi belirsiz kurulu\u015flar\u0131n, kendi yararlar\u0131 d\u0131\u015f\u0131nda bize mahremiyet vermelerini bekleyemeyiz. Bizim hakk\u0131m\u0131zda konu\u015fmak onlar\u0131n yarar\u0131nad\u0131r ve konu\u015fmalar\u0131n\u0131 beklemeliyiz. Konu\u015fmalar\u0131n\u0131 engellemeye \u00e7al\u0131\u015fmak, bilgi ger\u00e7ekleriyle sava\u015fmakt\u0131r. Bilgi sadece \u00f6zg\u00fcr olmak istemez, \u00f6zg\u00fcr olmay\u0131 arzular. Bilgi, mevcut depolama alan\u0131n\u0131 dolduracak \u015fekilde geni\u015fler. Bilgi, Rumor'un daha gen\u00e7, daha g\u00fc\u00e7l\u00fc kuzenidir; Bilgi, daha h\u0131zl\u0131d\u0131r, daha fazla g\u00f6ze sahiptir, daha fazlas\u0131n\u0131 bilir ve S\u00f6ylentiden daha az anlar. Herhangi bir mahremiyete sahip olmay\u0131 umuyorsak, kendi mahremiyetimizi savunmal\u0131y\u0131z. Bir araya gelmeli ve anonim i\u015flemlerin ger\u00e7ekle\u015fmesine izin veren sistemler olu\u015fturmal\u0131y\u0131z. \u0130nsanlar y\u00fczy\u0131llard\u0131r f\u0131s\u0131lt\u0131lar, karanl\u0131k, zarflar, kapal\u0131 kap\u0131lar, gizli tokala\u015fmalar ve kuryelerle kendi mahremiyetlerini savunuyorlar. Ge\u00e7mi\u015fin teknolojileri g\u00fc\u00e7l\u00fc bir mahremiyete izin vermiyordu, ancak elektronik teknolojiler izin veriyor. Biz Cypherpunk'lar, kendimizi anonim sistemler olu\u015fturmaya adad\u0131k. Gizlili\u011fimizi kriptografi, anonim posta y\u00f6nlendirme sistemleri, dijital imzalar ve elektronik para ile koruyoruz. Cypherpunk'lar kod yazar. Birinin mahremiyeti savunmak i\u00e7in yaz\u0131l\u0131m yazmas\u0131 gerekti\u011fini biliyoruz ve hepimiz bunu yapmad\u0131k\u00e7a mahremiyet elde edemeyece\u011fimiz i\u00e7in yazaca\u011f\u0131z. Kodumuzu Cypherpunk arkada\u015flar\u0131m\u0131z\u0131n pratik yap\u0131p onunla oynayabilmeleri i\u00e7in yay\u0131nl\u0131yoruz. Kodumuz, d\u00fcnya \u00e7ap\u0131nda herkesin kullan\u0131m\u0131 i\u00e7in \u00fccretsizdir. Yazd\u0131\u011f\u0131m\u0131z yaz\u0131l\u0131m\u0131 onaylamaman\u0131z pek umurumuzda de\u011fil. Yaz\u0131l\u0131m\u0131n yok edilemeyece\u011fini ve geni\u015f bir alana yay\u0131lm\u0131\u015f bir sistemin kapat\u0131lamayaca\u011f\u0131n\u0131 biliyoruz. \u015eifreleme temelde \u00f6zel bir eylem oldu\u011fundan, Cypherpunk'lar kriptografi ile ilgili d\u00fczenlemelerden \u015fikayet\u00e7idir. \u015eifreleme eylemi asl\u0131nda bilgiyi kamusal alandan kald\u0131r\u0131r. Kriptografiye kar\u015f\u0131 yasalar bile ancak bir ulusun s\u0131n\u0131r\u0131na ve \u015fiddetinin koluna kadar ula\u015f\u0131r. Kriptografi ka\u00e7\u0131n\u0131lmaz olarak t\u00fcm d\u00fcnyaya ve onunla birlikte m\u00fcmk\u00fcn k\u0131ld\u0131\u011f\u0131 anonim i\u015flem sistemlerine yay\u0131lacakt\u0131r. Mahremiyetin yayg\u0131nla\u015fmas\u0131 i\u00e7in bir sosyal s\u00f6zle\u015fmenin par\u00e7as\u0131 olmas\u0131 gerekir. \u0130nsanlar bir araya gelmeli ve bu sistemleri ortak yarar i\u00e7in kullanmal\u0131d\u0131r. Mahremiyet ancak, ki\u015finin toplumdaki hemcinslerinin i\u015fbirli\u011fi kadar geni\u015fler. Biz Cypherpunk'lar sorular\u0131n\u0131z\u0131 ve endi\u015felerinizi ar\u0131yoruz ve kendimizi kand\u0131rmamak i\u00e7in sizi me\u015fgul edebilece\u011fimizi umuyoruz. Bununla birlikte, baz\u0131lar\u0131 hedeflerimize kat\u0131lmayabilece\u011finden, rotam\u0131zdan ayr\u0131lmayaca\u011f\u0131z. Cypherpunks, a\u011flar\u0131 gizlilik i\u00e7in daha g\u00fcvenli hale getirmek i\u00e7in aktif olarak \u00e7al\u0131\u015f\u0131yor. H\u0131zla birlikte ilerleyelim. \u0130leriye. Eric Hughes < hughes@soda.berkeley.edu > 9 Mart 1993","title":"Bir Cypherpunk'\u0131n Manifestosu"},{"location":"feature_selection/","text":"Feature_Selection Projects - List of Context: 1. Feature Importance Codes and Full Article YouTube Video 2. Correlation Matrix Codes and Full Article YouTube Video Dataset: Mushroom Dataset - Kaggle Projects: 1. Feature Importance Genellikle bir makine \u00f6\u011frenmesi projesine ba\u015flarken \u00e7al\u0131\u015faca\u011f\u0131n\u0131z veri istedi\u011finiz formatta ve modele uygulanmaya haz\u0131r bir \u015fekilde de\u011fildir. Farkl\u0131 uzant\u0131larda ve yap\u0131larda olabilir. (CSV, JSON, Excel veya DB etc.) Ayr\u0131ca veriseti kendi i\u00e7erisinde eksik, anormal veya gereksiz bilgiler de i\u00e7eriyor olabilir. Ayn\u0131 zamanda modelinizde kullanaca\u011f\u0131n\u0131z veriye \u00f6n haz\u0131rl\u0131klar yapman\u0131z gerekebilir, \u00f6rnek vermek gerekirse \u00f6l\u00e7eklendirme veya normalle\u015ftirme say\u0131labilir. Her \u015feye ra\u011fmen bu i\u015flemleri tamamlad\u0131\u011f\u0131n\u0131zda dahi modelinizin iyi bir performans g\u00f6stermesi i\u00e7in boyutsall\u0131\u011f\u0131n\u0131n azalt\u0131lmas\u0131 ve g\u00fc\u00e7l\u00fc ili\u015fkilere sahip parametrelerin, performans\u0131 k\u00f6t\u00fc etkileyecek di\u011fer parametrelerden ayr\u0131lmas\u0131 gerekir. \u00c7\u00fcnk\u00fc bu \u00f6znitelikler (features) modele bir bilgi getirmiyor olabilirler. Bu y\u00fczden bir veri bilimci veya makine \u00f6\u011frenmesi m\u00fchendisinin en \u00f6nemli yetkinlikleri asl\u0131nda bu verinin \u00f6ni\u015flemlerini ger\u00e7ekten iyi yapmas\u0131ndan ge\u00e7mektedir. Bu seride g\u00fcncel olarak kullan\u0131lan Feature Selection yani \u00f6znitelik se\u00e7imlerinde kullan\u0131lan etkili metodlar\u0131 inceliyor olaca\u011f\u0131z. Teoride daha fazla \u00f6znitelik eklenmesi modelin geli\u015fimi i\u00e7in daha iyidir fakat pratikte bunun tam tersi ge\u00e7erlidir. Bu \u00f6nerme asl\u0131nda hem do\u011fru hem de yanl\u0131\u015ft\u0131r, \u00e7\u00fcnk\u00fc modele getirdi\u011finiz her \u00f6zellik bilgi ta\u015f\u0131yan ve \u00f6nemli bir parametre olmas\u0131 gerekir. Burada optimum de\u011feri yakalamak \u00f6nemli, tabii ki curse of dimensionality yani boyutsall\u0131\u011f\u0131n laneti konusuna da dikkat etmemiz gerekir. Pekala boyut d\u00fc\u015f\u00fcrmenin veya \u00f6znitelik azaltman\u0131n yararlar\u0131 nedir: Daha y\u00fcksek do\u011fruluk oran\u0131 Overfitting probleminin \u00f6n\u00fcne ge\u00e7mek. Model e\u011fitim s\u00fcresinin k\u0131salt\u0131lmas\u0131. Daha etkin bir g\u00f6rselle\u015ftirme Daha a\u00e7\u0131klanabilir bir model. Burada kullanaca\u011f\u0131m\u0131z veri seti \"Mushroom Classification\" yani \"Mantar S\u0131n\u0131fland\u0131rma\" veri seti olacak. Kullanaca\u011f\u0131m\u0131z k\u00fct\u00fcphaneler tahmin edebilece\u011finiz gibi: Pandas Numpy Matplotlib Seaborn Sklearn Imports import pandas as pd from sklearn.preprocessing import LabelEncoder from sklearn.preprocessing import StandardScaler from sklearn.model_selection import train_test_split data = pd . read_csv ( \"mushrooms.csv\" ) data . head () Dataset Prep. Veri setini ve ba\u015flang\u0131\u00e7 parametrelerimizi haz\u0131rlayal\u0131m. Burada verisetimizdeki her bir kolonu one_hot_encoding y\u00f6ntemiyle encode edece\u011fim. https://www.kaggle.com/uciml/mushroom-classification X = data . drop ([ 'class' ], axis = 1 ) y = data [ 'class' ] X_encoded = pd . get_dummies ( X , prefix_sep = \"_\" ) y_encoded = LabelEncoder () . fit_transform ( y ) X_scaled = StandardScaler () . fit_transform ( X_encoded ) X_train , X_test , y_train , y_test = train_test_split ( X_scaled , y_encoded , test_size = 0.30 , random_state = 101 ) Feature Selection Techniques Feature Importance Karar a\u011fa\u00e7lar\u0131 \u00e7e\u015fitli \u00f6zniteliklerin \u00f6nem derecelerini s\u0131ralamak i\u00e7in kullan\u0131labilir. Karar a\u011fa\u00e7lar\u0131ndaki dallanma bildi\u011finiz gibi \u00f6zniteliklerin s\u0131n\u0131fland\u0131r\u0131c\u0131l\u0131\u011f\u0131yla belirlenir. Bu y\u00fczden daha \u00e7ok kullan\u0131lan nodelar daha y\u00fcksek \u00f6neme sahip olabilirler. import time from sklearn.metrics import classification_report , confusion_matrix from sklearn.ensemble import RandomForestClassifier start = time . process_time () model = RandomForestClassifier ( n_estimators = 700 ) . fit ( X_train , y_train ) print ( time . process_time () - start ) preds = model . predict ( X_test ) print ( confusion_matrix ( y_test , preds )) print ( classification_report ( y_test , preds )) 2 saniye gibi bir s\u00fcrede modelin e\u011fitimi tamamland\u0131. 1.78125 [[ 1274 0 ] [ 0 1164 ]] precision recall f1 - score support 0 1.00 1.00 1.00 1274 1 1.00 1.00 1.00 1164 accuracy 1.00 2438 macro avg 1.00 1.00 1.00 2438 weighted avg 1.00 1.00 1.00 2438 Tam bir ba\u015far\u0131 oran\u0131na sahibiz fakat burada bakaca\u011f\u0131m\u0131z konu asl\u0131nda hangi niteliklerin ne kadar \u00f6nemli oldu\u011fu. Bu y\u00fczden feature importance metoduyla e\u011fitilmi\u015f modelin en \u00f6nemli oldu\u011fu 10 parametreyi g\u00f6rselle\u015ftiriyorum. import matplotlib.pyplot as plt from matplotlib.pyplot import figure feature_imp = pd . Series ( model . feature_importances_ , index = X_encoded . columns ) feature_imp . nlargest ( 10 ) . plot ( kind = 'barh' ) \u015eimdi t\u00fcm kolonlar\u0131 kullanmak yerine sadece \u00f6nemli olarak g\u00f6rd\u00fc\u011f\u00fcm 4 parametreyle e\u011fitece\u011fim. best_feat = feature_imp . nlargest ( 4 ) . index . to_list () X_reduced = X_encoded [ feature_imp . nlargest ( 4 ) . index ] Xr_scaled = StandardScaler () . fit_transform ( X_reduced ) Xr_train , Xr_test , yr_train , yr_test = train_test_split ( Xr_scaled , y , test_size = 0.30 , random_state = 101 ) start = time . process_time () rmodel = RandomForestClassifier ( n_estimators = 700 ) . fit ( Xr_train , yr_train ) print ( time . process_time () - start ) rpred = rmodel . predict ( Xr_test ) print ( confusion_matrix ( yr_test , rpred )) print ( classification_report ( yr_test , rpred )) 0.84375 [[ 1248 26 ] [ 53 1111 ]] precision recall f1 - score support e 0.96 0.98 0.97 1274 p 0.98 0.95 0.97 1164 accuracy 0.97 2438 macro avg 0.97 0.97 0.97 2438 weighted avg 0.97 0.97 0.97 2438 \u00c7ok a\u00e7\u0131k bir \u015fekilde g\u00f6rebiliriz ki, e\u011fitim s\u00fcresi yar\u0131 yar\u0131ya inerken accuracy'den \u00e7ok az kaybettik. Asl\u0131na bakarsan\u0131z bu \u00e7ok k\u00fc\u00e7\u00fck bir veriseti kazanc\u0131m\u0131z 1 saniye kadar fakat bunu milyonlarca sat\u0131ra sahip bir verisetiyle saatlerce e\u011fitti\u011finiz bir model oldu\u011funu d\u00fc\u015f\u00fcn\u00fcrseniz kesinlikle girece\u011finiz bir tradeoff olacakt\u0131r. Bir sonraki derste Recursive Feature Elimination (RFE) tekni\u011fini g\u00f6rece\u011fiz. \u0130yi \u00e7al\u0131\u015fmalar dilerim. 2. Correlation Matrix Feature Selection \u00e7al\u0131\u015fmalar\u0131na Correlation Matrix ile devam ediyoruz. Veriye bak\u0131\u015f a\u00e7\u0131m\u0131z ve uygulad\u0131\u011f\u0131m\u0131z her tekni\u011fin bir istatistiksel altyap\u0131s\u0131 olmas\u0131 gerekir. Yapaca\u011f\u0131m\u0131z i\u015flemlerin her birini model performans\u0131n\u0131 art\u0131rmaya y\u00f6nelik ve belirli bir sistematik ile yapmak ba\u015far\u0131m\u0131 en \u00e7ok etkileyen unsurlardand\u0131r. Genel olarak featurelar\u0131m\u0131z\u0131n, target ile ili\u015fkisini \u00f6l\u00e7mek i\u00e7in en pop\u00fcler tekniklerden olan korelasyon matrisi bize basit\u00e7e kolonlar\u0131n birbiri ile olan ve hedef ile olan ili\u015fkisini g\u00f6sterir. Genel bir yakla\u015f\u0131m olarak \"-0.7\"den k\u00fc\u00e7\u00fck ve \"+0.7\"den b\u00fcy\u00fck korelasyon de\u011ferleri g\u00fc\u00e7l\u00fc korelasyonu temsil etmektedir. Buradaki amac\u0131m\u0131z \u00e7\u0131k\u0131\u015f ile ili\u015fkisi olmayan ve bilgi ta\u015f\u0131ma potansiyeli g\u00f6rece di\u011fer kolonlara az olan featurelar\u0131 elemek olmal\u0131d\u0131r. Bu sayede ilk derste verdi\u011fimiz daha sade ve etkili model, h\u0131zl\u0131 e\u011fitim gibi ba\u015far\u0131m\u0131 pozitif y\u00f6nde etkileyecek unsurlara sahip olabilir. \u015eimdi python'da korelasyon matrisi nas\u0131l olu\u015fturulabilir buna bakal\u0131m. Geli\u015ftirici Notu: T\u00fcm kolonlar\u0131 ordinal olmayan kategorik verilerde korelasyon analizi mant\u0131kl\u0131 bir yakla\u015f\u0131m olup olmad\u0131\u011f\u0131 tart\u0131\u015fmaya a\u00e7\u0131k bir konudur. Burada bahsi ge\u00e7en veri seti veya ama\u00e7tan ziyade, korelasyon matrisinin tekniklerini ve anafikrini yakalama i\u00e7in uygun say\u0131labilir diyebiliriz. !! Genellikle !! regresyon i\u015flemlerinizde ve say\u0131sal bir de\u011fer i\u00e7eren kolonlarda kullan\u0131lmas\u0131 \u015fiddetle \u00f6nerilir. Imports import pandas as pd from sklearn.preprocessing import LabelEncoder from sklearn.preprocessing import StandardScaler from sklearn.model_selection import train_test_split Veri setini haz\u0131rl\u0131klar\u0131 yapmak ad\u0131na i\u00e7eri aktaral\u0131m. data = pd . read_csv ( \"../mushrooms.csv\" ) data . shape \u0130lk yapaca\u011f\u0131m\u0131z i\u015flem veri setimiz harflerden olu\u015ftu\u011fu i\u00e7in bunu say\u0131sal bir forma \u00e7evirmek olmal\u0131, buradaki yakla\u015f\u0131m\u0131m\u0131z featurelar\u0131 one-hot encoding yapt\u0131ktan sonra standardize etmek. Y kolonumuzu label encoding yaparak korelasyon haritas\u0131n\u0131 olu\u015fturmak i\u00e7in featurlar\u0131m\u0131z\u0131n oldu\u011fu dataframe'in sonuna ekleyece\u011fiz. X = data . drop ([ 'class' ], axis = 1 ) y = data [ 'class' ] X_encoded = pd . get_dummies ( X , prefix_sep = \"_\" ) y_encoded = LabelEncoder () . fit_transform ( y ) X_encoded [ \"Class\" ] = y_encoded X_encoded . corr () Dataframe \u00fczerinden bu verilerin okunmas\u0131 olduk\u00e7a zor, seaborn k\u00fct\u00fcphanesindeki heatmap grafi\u011fi bizim i\u00e7in bu da\u011f\u0131l\u0131m\u0131 renkler ve anla\u015f\u0131lmas\u0131 kolay bir g\u00f6rselle a\u00e7\u0131klayacak. Verisetimizin e\u011fer tamam\u0131n\u0131z al\u0131rsak \u015fu anki durumda 118 kolon var, bunun \u00e7izdirilmesi mant\u0131kl de\u011fil, sadece son 7 kolonu alarak \u015fu anl\u0131k g\u00f6zlemleyelim. Birazdan \u00f6\u011frenece\u011fimiz teknikler ile en \u00f6nemli 10 parametreyi g\u00f6rselle\u015ftiriyor olaca\u011f\u0131z. sns . heatmap ( X_encoded . iloc [:, - 7 :] . corr (), annot = True ) Belirtti\u011fimiz gibi eksi ve art\u0131 de\u011ferler g\u00fc\u00e7l\u00fc korelasyonu ifade ediyor, burada say\u0131n\u0131n pozitif ve negatif olmas\u0131 ili\u015fkinin ters veya do\u011fru orant\u0131l\u0131 olarak de\u011fi\u015fmesi ile alakal\u0131, her ikisi de bizim i\u00e7in iyi featurelar olabilir bu y\u00fczden dataframe'in mutlak de\u011ferini alarak en y\u00fcksek de\u011ferli olanlar\u0131 getirece\u011fiz. X_encoded . corr () . abs ()[ \"Class\" ] # .nlarget ile s\u0131ral\u0131 bir \u015fekilde en y\u00fcksek 10 de\u011feri alabiliriz. X_encoded . corr () . abs ()[ \"Class\" ] . nlargest ( 10 ) Bu zamana kadar yazd\u0131\u011f\u0131m\u0131z k\u0131sm\u0131n sonunda index metodunu ekleyerek sadece kolon isimlerini istiyorum ve bunu ana datasetimizden ba\u015fka bir de\u011fi\u015fkene aktar\u0131yorum. Birazdan sadece bu k\u0131sm\u0131 kullan\u0131yor olaca\u011f\u0131z, bu sayede daha okunakl\u0131 ve en y\u00fcksek 10 korelasyon de\u011ferine sahip kolon ile birlikte \u00e7al\u0131\u015f\u0131yor olaca\u011f\u0131z. X_reduced_col_names = X_encoded . corr () . abs ()[ \"Class\" ] . nlargest ( 10 ) . index X_encoded [ X_reduced_col_names ] . corr () Art\u0131k g\u00f6rselle\u015ftirme k\u0131sm\u0131na ge\u00e7ebiliriz. \u00c7izdirdi\u011fimiz g\u00f6rselin b\u00fcy\u00fckl\u00fc\u011f\u00fc ve \u00e7\u00f6z\u00fcn\u00fcrl\u00fc\u011f\u00fcn\u00fc de\u011fi\u015ftirmek ad\u0131na matplotlib k\u00fct\u00fcphanesini i\u00e7eri aktar\u0131yorum. figsize ile boyut, dpi ile \u00e7\u00f6z\u00fcn\u00fcr\u00fcl\u00fck ayarlanabilmektedir. heatmap i\u00e7indeki \"annot\" ile karelerin i\u00e7erisine de\u011ferlerini yazd\u0131rabiliyorum. import matplotlib.pyplot as plt plt . figure ( figsize = ( 10 , 10 ), dpi = 400 ) sns . heatmap ( X_encoded [ X_reduced_col_names ] . corr () . abs (), annot = True )","title":"Feature Selection"},{"location":"feature_selection/#feature_selection","text":"","title":"Feature_Selection"},{"location":"feature_selection/#projects-list-of-context","text":"","title":"Projects - List of Context:"},{"location":"feature_selection/#1-feature-importance","text":"Codes and Full Article YouTube Video","title":"1. Feature Importance"},{"location":"feature_selection/#2-correlation-matrix","text":"Codes and Full Article YouTube Video","title":"2. Correlation Matrix"},{"location":"feature_selection/#dataset","text":"Mushroom Dataset - Kaggle","title":"Dataset:"},{"location":"feature_selection/#projects","text":"","title":"Projects:"},{"location":"feature_selection/#1-feature-importance_1","text":"Genellikle bir makine \u00f6\u011frenmesi projesine ba\u015flarken \u00e7al\u0131\u015faca\u011f\u0131n\u0131z veri istedi\u011finiz formatta ve modele uygulanmaya haz\u0131r bir \u015fekilde de\u011fildir. Farkl\u0131 uzant\u0131larda ve yap\u0131larda olabilir. (CSV, JSON, Excel veya DB etc.) Ayr\u0131ca veriseti kendi i\u00e7erisinde eksik, anormal veya gereksiz bilgiler de i\u00e7eriyor olabilir. Ayn\u0131 zamanda modelinizde kullanaca\u011f\u0131n\u0131z veriye \u00f6n haz\u0131rl\u0131klar yapman\u0131z gerekebilir, \u00f6rnek vermek gerekirse \u00f6l\u00e7eklendirme veya normalle\u015ftirme say\u0131labilir. Her \u015feye ra\u011fmen bu i\u015flemleri tamamlad\u0131\u011f\u0131n\u0131zda dahi modelinizin iyi bir performans g\u00f6stermesi i\u00e7in boyutsall\u0131\u011f\u0131n\u0131n azalt\u0131lmas\u0131 ve g\u00fc\u00e7l\u00fc ili\u015fkilere sahip parametrelerin, performans\u0131 k\u00f6t\u00fc etkileyecek di\u011fer parametrelerden ayr\u0131lmas\u0131 gerekir. \u00c7\u00fcnk\u00fc bu \u00f6znitelikler (features) modele bir bilgi getirmiyor olabilirler. Bu y\u00fczden bir veri bilimci veya makine \u00f6\u011frenmesi m\u00fchendisinin en \u00f6nemli yetkinlikleri asl\u0131nda bu verinin \u00f6ni\u015flemlerini ger\u00e7ekten iyi yapmas\u0131ndan ge\u00e7mektedir. Bu seride g\u00fcncel olarak kullan\u0131lan Feature Selection yani \u00f6znitelik se\u00e7imlerinde kullan\u0131lan etkili metodlar\u0131 inceliyor olaca\u011f\u0131z. Teoride daha fazla \u00f6znitelik eklenmesi modelin geli\u015fimi i\u00e7in daha iyidir fakat pratikte bunun tam tersi ge\u00e7erlidir. Bu \u00f6nerme asl\u0131nda hem do\u011fru hem de yanl\u0131\u015ft\u0131r, \u00e7\u00fcnk\u00fc modele getirdi\u011finiz her \u00f6zellik bilgi ta\u015f\u0131yan ve \u00f6nemli bir parametre olmas\u0131 gerekir. Burada optimum de\u011feri yakalamak \u00f6nemli, tabii ki curse of dimensionality yani boyutsall\u0131\u011f\u0131n laneti konusuna da dikkat etmemiz gerekir. Pekala boyut d\u00fc\u015f\u00fcrmenin veya \u00f6znitelik azaltman\u0131n yararlar\u0131 nedir: Daha y\u00fcksek do\u011fruluk oran\u0131 Overfitting probleminin \u00f6n\u00fcne ge\u00e7mek. Model e\u011fitim s\u00fcresinin k\u0131salt\u0131lmas\u0131. Daha etkin bir g\u00f6rselle\u015ftirme Daha a\u00e7\u0131klanabilir bir model. Burada kullanaca\u011f\u0131m\u0131z veri seti \"Mushroom Classification\" yani \"Mantar S\u0131n\u0131fland\u0131rma\" veri seti olacak. Kullanaca\u011f\u0131m\u0131z k\u00fct\u00fcphaneler tahmin edebilece\u011finiz gibi: Pandas Numpy Matplotlib Seaborn Sklearn","title":"1. Feature Importance"},{"location":"feature_selection/#imports","text":"import pandas as pd from sklearn.preprocessing import LabelEncoder from sklearn.preprocessing import StandardScaler from sklearn.model_selection import train_test_split data = pd . read_csv ( \"mushrooms.csv\" ) data . head ()","title":"Imports"},{"location":"feature_selection/#dataset-prep","text":"Veri setini ve ba\u015flang\u0131\u00e7 parametrelerimizi haz\u0131rlayal\u0131m. Burada verisetimizdeki her bir kolonu one_hot_encoding y\u00f6ntemiyle encode edece\u011fim. https://www.kaggle.com/uciml/mushroom-classification X = data . drop ([ 'class' ], axis = 1 ) y = data [ 'class' ] X_encoded = pd . get_dummies ( X , prefix_sep = \"_\" ) y_encoded = LabelEncoder () . fit_transform ( y ) X_scaled = StandardScaler () . fit_transform ( X_encoded ) X_train , X_test , y_train , y_test = train_test_split ( X_scaled , y_encoded , test_size = 0.30 , random_state = 101 )","title":"Dataset Prep."},{"location":"feature_selection/#feature-selection-techniques","text":"","title":"Feature Selection Techniques"},{"location":"feature_selection/#feature-importance","text":"Karar a\u011fa\u00e7lar\u0131 \u00e7e\u015fitli \u00f6zniteliklerin \u00f6nem derecelerini s\u0131ralamak i\u00e7in kullan\u0131labilir. Karar a\u011fa\u00e7lar\u0131ndaki dallanma bildi\u011finiz gibi \u00f6zniteliklerin s\u0131n\u0131fland\u0131r\u0131c\u0131l\u0131\u011f\u0131yla belirlenir. Bu y\u00fczden daha \u00e7ok kullan\u0131lan nodelar daha y\u00fcksek \u00f6neme sahip olabilirler. import time from sklearn.metrics import classification_report , confusion_matrix from sklearn.ensemble import RandomForestClassifier start = time . process_time () model = RandomForestClassifier ( n_estimators = 700 ) . fit ( X_train , y_train ) print ( time . process_time () - start ) preds = model . predict ( X_test ) print ( confusion_matrix ( y_test , preds )) print ( classification_report ( y_test , preds )) 2 saniye gibi bir s\u00fcrede modelin e\u011fitimi tamamland\u0131. 1.78125 [[ 1274 0 ] [ 0 1164 ]] precision recall f1 - score support 0 1.00 1.00 1.00 1274 1 1.00 1.00 1.00 1164 accuracy 1.00 2438 macro avg 1.00 1.00 1.00 2438 weighted avg 1.00 1.00 1.00 2438 Tam bir ba\u015far\u0131 oran\u0131na sahibiz fakat burada bakaca\u011f\u0131m\u0131z konu asl\u0131nda hangi niteliklerin ne kadar \u00f6nemli oldu\u011fu. Bu y\u00fczden feature importance metoduyla e\u011fitilmi\u015f modelin en \u00f6nemli oldu\u011fu 10 parametreyi g\u00f6rselle\u015ftiriyorum. import matplotlib.pyplot as plt from matplotlib.pyplot import figure feature_imp = pd . Series ( model . feature_importances_ , index = X_encoded . columns ) feature_imp . nlargest ( 10 ) . plot ( kind = 'barh' ) \u015eimdi t\u00fcm kolonlar\u0131 kullanmak yerine sadece \u00f6nemli olarak g\u00f6rd\u00fc\u011f\u00fcm 4 parametreyle e\u011fitece\u011fim. best_feat = feature_imp . nlargest ( 4 ) . index . to_list () X_reduced = X_encoded [ feature_imp . nlargest ( 4 ) . index ] Xr_scaled = StandardScaler () . fit_transform ( X_reduced ) Xr_train , Xr_test , yr_train , yr_test = train_test_split ( Xr_scaled , y , test_size = 0.30 , random_state = 101 ) start = time . process_time () rmodel = RandomForestClassifier ( n_estimators = 700 ) . fit ( Xr_train , yr_train ) print ( time . process_time () - start ) rpred = rmodel . predict ( Xr_test ) print ( confusion_matrix ( yr_test , rpred )) print ( classification_report ( yr_test , rpred )) 0.84375 [[ 1248 26 ] [ 53 1111 ]] precision recall f1 - score support e 0.96 0.98 0.97 1274 p 0.98 0.95 0.97 1164 accuracy 0.97 2438 macro avg 0.97 0.97 0.97 2438 weighted avg 0.97 0.97 0.97 2438 \u00c7ok a\u00e7\u0131k bir \u015fekilde g\u00f6rebiliriz ki, e\u011fitim s\u00fcresi yar\u0131 yar\u0131ya inerken accuracy'den \u00e7ok az kaybettik. Asl\u0131na bakarsan\u0131z bu \u00e7ok k\u00fc\u00e7\u00fck bir veriseti kazanc\u0131m\u0131z 1 saniye kadar fakat bunu milyonlarca sat\u0131ra sahip bir verisetiyle saatlerce e\u011fitti\u011finiz bir model oldu\u011funu d\u00fc\u015f\u00fcn\u00fcrseniz kesinlikle girece\u011finiz bir tradeoff olacakt\u0131r. Bir sonraki derste Recursive Feature Elimination (RFE) tekni\u011fini g\u00f6rece\u011fiz. \u0130yi \u00e7al\u0131\u015fmalar dilerim.","title":"Feature Importance"},{"location":"feature_selection/#2-correlation-matrix_1","text":"Feature Selection \u00e7al\u0131\u015fmalar\u0131na Correlation Matrix ile devam ediyoruz. Veriye bak\u0131\u015f a\u00e7\u0131m\u0131z ve uygulad\u0131\u011f\u0131m\u0131z her tekni\u011fin bir istatistiksel altyap\u0131s\u0131 olmas\u0131 gerekir. Yapaca\u011f\u0131m\u0131z i\u015flemlerin her birini model performans\u0131n\u0131 art\u0131rmaya y\u00f6nelik ve belirli bir sistematik ile yapmak ba\u015far\u0131m\u0131 en \u00e7ok etkileyen unsurlardand\u0131r. Genel olarak featurelar\u0131m\u0131z\u0131n, target ile ili\u015fkisini \u00f6l\u00e7mek i\u00e7in en pop\u00fcler tekniklerden olan korelasyon matrisi bize basit\u00e7e kolonlar\u0131n birbiri ile olan ve hedef ile olan ili\u015fkisini g\u00f6sterir. Genel bir yakla\u015f\u0131m olarak \"-0.7\"den k\u00fc\u00e7\u00fck ve \"+0.7\"den b\u00fcy\u00fck korelasyon de\u011ferleri g\u00fc\u00e7l\u00fc korelasyonu temsil etmektedir. Buradaki amac\u0131m\u0131z \u00e7\u0131k\u0131\u015f ile ili\u015fkisi olmayan ve bilgi ta\u015f\u0131ma potansiyeli g\u00f6rece di\u011fer kolonlara az olan featurelar\u0131 elemek olmal\u0131d\u0131r. Bu sayede ilk derste verdi\u011fimiz daha sade ve etkili model, h\u0131zl\u0131 e\u011fitim gibi ba\u015far\u0131m\u0131 pozitif y\u00f6nde etkileyecek unsurlara sahip olabilir. \u015eimdi python'da korelasyon matrisi nas\u0131l olu\u015fturulabilir buna bakal\u0131m. Geli\u015ftirici Notu: T\u00fcm kolonlar\u0131 ordinal olmayan kategorik verilerde korelasyon analizi mant\u0131kl\u0131 bir yakla\u015f\u0131m olup olmad\u0131\u011f\u0131 tart\u0131\u015fmaya a\u00e7\u0131k bir konudur. Burada bahsi ge\u00e7en veri seti veya ama\u00e7tan ziyade, korelasyon matrisinin tekniklerini ve anafikrini yakalama i\u00e7in uygun say\u0131labilir diyebiliriz. !! Genellikle !! regresyon i\u015flemlerinizde ve say\u0131sal bir de\u011fer i\u00e7eren kolonlarda kullan\u0131lmas\u0131 \u015fiddetle \u00f6nerilir.","title":"2. Correlation Matrix"},{"location":"feature_selection/#imports_1","text":"import pandas as pd from sklearn.preprocessing import LabelEncoder from sklearn.preprocessing import StandardScaler from sklearn.model_selection import train_test_split Veri setini haz\u0131rl\u0131klar\u0131 yapmak ad\u0131na i\u00e7eri aktaral\u0131m. data = pd . read_csv ( \"../mushrooms.csv\" ) data . shape \u0130lk yapaca\u011f\u0131m\u0131z i\u015flem veri setimiz harflerden olu\u015ftu\u011fu i\u00e7in bunu say\u0131sal bir forma \u00e7evirmek olmal\u0131, buradaki yakla\u015f\u0131m\u0131m\u0131z featurelar\u0131 one-hot encoding yapt\u0131ktan sonra standardize etmek. Y kolonumuzu label encoding yaparak korelasyon haritas\u0131n\u0131 olu\u015fturmak i\u00e7in featurlar\u0131m\u0131z\u0131n oldu\u011fu dataframe'in sonuna ekleyece\u011fiz. X = data . drop ([ 'class' ], axis = 1 ) y = data [ 'class' ] X_encoded = pd . get_dummies ( X , prefix_sep = \"_\" ) y_encoded = LabelEncoder () . fit_transform ( y ) X_encoded [ \"Class\" ] = y_encoded X_encoded . corr () Dataframe \u00fczerinden bu verilerin okunmas\u0131 olduk\u00e7a zor, seaborn k\u00fct\u00fcphanesindeki heatmap grafi\u011fi bizim i\u00e7in bu da\u011f\u0131l\u0131m\u0131 renkler ve anla\u015f\u0131lmas\u0131 kolay bir g\u00f6rselle a\u00e7\u0131klayacak. Verisetimizin e\u011fer tamam\u0131n\u0131z al\u0131rsak \u015fu anki durumda 118 kolon var, bunun \u00e7izdirilmesi mant\u0131kl de\u011fil, sadece son 7 kolonu alarak \u015fu anl\u0131k g\u00f6zlemleyelim. Birazdan \u00f6\u011frenece\u011fimiz teknikler ile en \u00f6nemli 10 parametreyi g\u00f6rselle\u015ftiriyor olaca\u011f\u0131z. sns . heatmap ( X_encoded . iloc [:, - 7 :] . corr (), annot = True ) Belirtti\u011fimiz gibi eksi ve art\u0131 de\u011ferler g\u00fc\u00e7l\u00fc korelasyonu ifade ediyor, burada say\u0131n\u0131n pozitif ve negatif olmas\u0131 ili\u015fkinin ters veya do\u011fru orant\u0131l\u0131 olarak de\u011fi\u015fmesi ile alakal\u0131, her ikisi de bizim i\u00e7in iyi featurelar olabilir bu y\u00fczden dataframe'in mutlak de\u011ferini alarak en y\u00fcksek de\u011ferli olanlar\u0131 getirece\u011fiz. X_encoded . corr () . abs ()[ \"Class\" ] # .nlarget ile s\u0131ral\u0131 bir \u015fekilde en y\u00fcksek 10 de\u011feri alabiliriz. X_encoded . corr () . abs ()[ \"Class\" ] . nlargest ( 10 ) Bu zamana kadar yazd\u0131\u011f\u0131m\u0131z k\u0131sm\u0131n sonunda index metodunu ekleyerek sadece kolon isimlerini istiyorum ve bunu ana datasetimizden ba\u015fka bir de\u011fi\u015fkene aktar\u0131yorum. Birazdan sadece bu k\u0131sm\u0131 kullan\u0131yor olaca\u011f\u0131z, bu sayede daha okunakl\u0131 ve en y\u00fcksek 10 korelasyon de\u011ferine sahip kolon ile birlikte \u00e7al\u0131\u015f\u0131yor olaca\u011f\u0131z. X_reduced_col_names = X_encoded . corr () . abs ()[ \"Class\" ] . nlargest ( 10 ) . index X_encoded [ X_reduced_col_names ] . corr () Art\u0131k g\u00f6rselle\u015ftirme k\u0131sm\u0131na ge\u00e7ebiliriz. \u00c7izdirdi\u011fimiz g\u00f6rselin b\u00fcy\u00fckl\u00fc\u011f\u00fc ve \u00e7\u00f6z\u00fcn\u00fcrl\u00fc\u011f\u00fcn\u00fc de\u011fi\u015ftirmek ad\u0131na matplotlib k\u00fct\u00fcphanesini i\u00e7eri aktar\u0131yorum. figsize ile boyut, dpi ile \u00e7\u00f6z\u00fcn\u00fcr\u00fcl\u00fck ayarlanabilmektedir. heatmap i\u00e7indeki \"annot\" ile karelerin i\u00e7erisine de\u011ferlerini yazd\u0131rabiliyorum. import matplotlib.pyplot as plt plt . figure ( figsize = ( 10 , 10 ), dpi = 400 ) sns . heatmap ( X_encoded [ X_reduced_col_names ] . corr () . abs (), annot = True )","title":"Imports"},{"location":"helpers/","text":"Helper Codes SSH ssh -J mert@ { servername } .ddns.net:port mert@target SCP From Local scp -o \"ProxyJump mert@servername.ddns.net -p {port}\" test.txt mert@target-pc:/home/mert/ Download File From Remote Server scp -o \"ProxyJump mert@servername.ddns.net -p {port}\" mert@target-pc:/home/mert/ test.txt Various Download File wget --user-agent Mozilla/4.0 'big address' -O dest_file_name rename files ls -v | cat -n | while read n f; do mv -n \"$f\" \"$n.ext\"; done Extract Files 7za x test.7z String Slicing # From Character for f in raw_daily/*.csv ; do echo $f /dimensions_ \" ${ f #*blocks_ } \" ; done # TO Character for f in raw_daily/*.csv ; do echo $f /dimensions_ \" ${ f %*blocks_ } \" ; done Random File Name for i in *.jpg; do mv -i \"$i\" ${RANDOM}${RANDOM}.jpg; done FFMPEG MP3 \u2192 WAV for f in *.mp3 ; do ffmpeg -i \" $f \" -acodec pcm_s16le -ac 1 -ar 16000 \"wav-exports/ ${ f %. } .wav\" ; done for f in *.flac ; do ffmpeg -i \" $f \" \"wav-exports/ ${ f %. } .wav\" ; done to mp3 for f in *.*; do ffmpeg -i \"$f\" \"wav-exports/${f%.}.wav\"; done for f in *; do ffmpeg -i \"${f}\" -vn -ab 128k -ar 44100 -y \"${f}.mp3\" ; done MP4 \u2192 PNG ffmpeg -i test.mp4 -vf fps = 1 /2 png-exports/video13_%06d.png **for f in *.mp4 ; do ffmpeg -i \" $f \" -vf fps = 2 png-exports/ ${ f %.* } _%06d.png ; done ** Move Files for f in png-exports/* ; do cp $f /*.png all_images ; done PNG Sequence to MP4 ffmpeg -f image2 -r 30 -i %6d.jpg -vcodec libx264 -crf 18 -pix_fmt yuv420p test.mp4 ESRGAN python inference_realesrgan.py -n RealESRGAN_x4plus -i v13 -s 3 --suffix 8k -t 1500 -o v13_out Delete Files Recursively find e -maxdepth 10 -type f -name \".*\" -delete Get Dimensions from Folder ls -U | while read n; do identify -format \"%f,%w,%h\\n\" \"$n\"; done > file_size.csv","title":"Helper one-liners"},{"location":"helpers/#helper-codes","text":"","title":"Helper Codes"},{"location":"helpers/#ssh","text":"ssh -J mert@ { servername } .ddns.net:port mert@target","title":"SSH"},{"location":"helpers/#scp","text":"From Local scp -o \"ProxyJump mert@servername.ddns.net -p {port}\" test.txt mert@target-pc:/home/mert/ Download File From Remote Server scp -o \"ProxyJump mert@servername.ddns.net -p {port}\" mert@target-pc:/home/mert/ test.txt","title":"SCP"},{"location":"helpers/#various","text":"Download File wget --user-agent Mozilla/4.0 'big address' -O dest_file_name rename files ls -v | cat -n | while read n f; do mv -n \"$f\" \"$n.ext\"; done Extract Files 7za x test.7z String Slicing # From Character for f in raw_daily/*.csv ; do echo $f /dimensions_ \" ${ f #*blocks_ } \" ; done # TO Character for f in raw_daily/*.csv ; do echo $f /dimensions_ \" ${ f %*blocks_ } \" ; done","title":"Various"},{"location":"helpers/#random-file-name","text":"for i in *.jpg; do mv -i \"$i\" ${RANDOM}${RANDOM}.jpg; done","title":"Random File Name"},{"location":"helpers/#ffmpeg","text":"MP3 \u2192 WAV for f in *.mp3 ; do ffmpeg -i \" $f \" -acodec pcm_s16le -ac 1 -ar 16000 \"wav-exports/ ${ f %. } .wav\" ; done for f in *.flac ; do ffmpeg -i \" $f \" \"wav-exports/ ${ f %. } .wav\" ; done to mp3 for f in *.*; do ffmpeg -i \"$f\" \"wav-exports/${f%.}.wav\"; done for f in *; do ffmpeg -i \"${f}\" -vn -ab 128k -ar 44100 -y \"${f}.mp3\" ; done MP4 \u2192 PNG ffmpeg -i test.mp4 -vf fps = 1 /2 png-exports/video13_%06d.png **for f in *.mp4 ; do ffmpeg -i \" $f \" -vf fps = 2 png-exports/ ${ f %.* } _%06d.png ; done **","title":"FFMPEG"},{"location":"helpers/#move-files","text":"for f in png-exports/* ; do cp $f /*.png all_images ; done","title":"Move Files"},{"location":"helpers/#png-sequence-to-mp4","text":"ffmpeg -f image2 -r 30 -i %6d.jpg -vcodec libx264 -crf 18 -pix_fmt yuv420p test.mp4","title":"PNG Sequence to MP4"},{"location":"helpers/#esrgan","text":"python inference_realesrgan.py -n RealESRGAN_x4plus -i v13 -s 3 --suffix 8k -t 1500 -o v13_out","title":"ESRGAN"},{"location":"helpers/#delete-files-recursively","text":"find e -maxdepth 10 -type f -name \".*\" -delete","title":"Delete Files Recursively"},{"location":"helpers/#get-dimensions-from-folder","text":"ls -U | while read n; do identify -format \"%f,%w,%h\\n\" \"$n\"; done > file_size.csv","title":"Get Dimensions from Folder"},{"location":"instant-ngp-windows/","text":"Instant Neural Graphics Primitives ! Requirements An NVIDIA GPU ; tensor cores increase performance when available. All shown results come from an RTX 3090. Python ver: 3.9.* Visual Studio Community 2019 (Latest the best, ~8GB) Below are the install requirements CUDA v11.6 . You can check ur CUDA version via nvcc --version in any prompt and if it's not CUDA11.6, refer to this to swap/install the correct version. On some machines, pyexr refuses to install via pip . This can be resolved by installing OpenEXR from here . See later. This installation tutorial will be using Anaconda. Download anaconda prompt here . OptiX 7.3 or higher for faster mesh SDF training. You need to either login or join to obtain the installer. Set the system environment variables OptiX_INSTALL_DIR to the installation directory if it is not discovered automatically. Should look like this: Compilation copy these files C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v11.6\\extras\\visual_studio_integration\\MSBuildExtensions to here C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\MSBuild\\Microsoft\\VC\\v160\\BuildCustomizations cd into a directory that you want to download the codes at. Eg. cd F:\\Tutorial\\ngp\\ Begin by cloning this repository and all its submodules using the following command (if you don't have git, download here and add to path): $ git clone --recursive https://github.com/nvlabs/instant-ngp $ cd instant-ngp if your python is not 3.9 (check with command python --version ) then you need to run the following command to get it to ver 3.9.* conda install python=3.9 Then, open Developer Command Prompt , you can find this in your search bar. Then cd to where you cloned your repository so you are in its root folder /instant-ng/ : cmake . -B build cmake --build build --config RelWithDebInfo -j 16 If the any of these build fails, please consult this list of possible fixes before opening an issue. If automatic GPU architecture detection fails, (as can happen if you have multiple GPUs installed), set the TCNN_CUDA_ARCHITECTURES enivonment variable for the GPU you would like to use. The following table lists the values for common GPUs. If your GPU is not listed, consult this exhaustive list . RTX 30X0 A100 RTX 20X0 TITAN V / V100 GTX 10X0 / TITAN Xp GTX 9X0 K80 86 80 75 70 61 52 37 Interactive Training and Rendering on Custom Image Sets Install COLMAP , I used ver 3.7 Add it to your system environment variables at Environment Variables > System Variables Path > Edit environment variable open anaconda prompt, if you don't have you don't have you can get it here cd into isntant-ngp as root conda create -n ngp python = 3 .9 conda activate ngp pip install -r requirements.txt if pyexr cannot be installed via pip install pyexr , download OpenEXR\u20111.3.2\u2011cp39\u2011cp39\u2011win_amd64.whl and move it to your root folder. Then you can run: pip install OpenEXR-1.3.2-cp39-cp39-win_amd64.whl Place your custom image set under data/<image_set_name> Get transform.json from the following command. Insert your path to your images at <image/path> python scripts/colmap2nerf.py --colmap_matcher exhaustive --run_colmap --aabb_scale 16 --images <image/path> transform.json will be generated at the root folder, drag and drop it into your data/<image_set_name> folder. You have to reorganize the folder structure due to how transforms.json is created... For example: File Structure BEFORE generating transform.json \ud83d\udcc2instant-ngp/ # this is root \u251c\u2500\u2500 \ud83d\udcc2data/ \u2502 \u251c\u2500\u2500 \ud83d\udcc2toy_truck/ \u2502 \u2502 \u251c\u2500\u2500 \ud83d\udcdctoy_truck_001.jpg \u2502 \u2502 \u251c\u2500\u2500 \ud83d\udcdctoy_truck_002.jpg \u2502 \u2502 \u2502... \u2502 \u2502... \u2502... File Structure AFTER generating transform.json \ud83d\udcc2instant-ngp/ # this is root \u251c\u2500\u2500 \ud83d\udcc2data/ \u2502 \u251c\u2500\u2500 \ud83d\udcc2toy_truck/ \u2502 \u2502 \u251c\u2500\u2500 \ud83d\udcdctransforms.json/ \u2502 \u2502 \u251c\u2500\u2500 \ud83d\udcc2data/ \u2502 \u2502 \u2502 \u251c\u2500\u2500 \ud83d\udcc2toy_truck/ \u2502 \u2502 \u2502 \u2502 \u251c\u2500\u2500 \ud83d\udcdctoy_truck_001.jpg \u2502 \u2502 \u2502 \u2502 \u251c\u2500\u2500 \ud83d\udcdctoy_truck_002.jpg \u2502 \u2502 \u2502 \u2502 \u2502... \u2502 \u2502 \u2502 \u2502... \u2502 \u2502 \u2502... \u2502 \u2502... \u2502... Note: adjusting the \"aabb_scale\" inside transform.json can reduce load on GPU VRAM. The lower the value the less intensive it'll be. Finally, to run instant-ngp: <path_to_your_ngp> \\i nstant-ngp \\b uild \\t estbed.exe --scene data/<image_set_name> eg. C:\\user\\user\\download\\instant-ngp\\build\\testbed.exe --scene data/toy_truck And it should launch the GUI and everything amazing with it Rendering custom camera path May need to install more dependencies. Install pip install tqdm scipy pillow opencv-python , conda install -c conda-forge ffmpeg , might be needed in the conda virtual environment. Refer to installation of pyexr above in the installation section if you didn't install that too. Train any image set like above. After you have reached a point that you are satisfied with your training, save a Snapshot on the GUI. (one of the tabs & no need to edit the path & the name) Find another GUI called camera path, it'll play hide and seek with you but it is there so find that window. The GUI is so well made, if you know how to use any 3D engine, it's really similar. Add camera path will give you a new angle of the camera. After you have finished adding your camera points, save the camera path. (no need to edit the path & the name) Render the path with the following command: python scripts/render.py --scene <scene_path> --n_seconds <seconds> --fps <fps> --render_name <name> --width <resolution_width> --height <resolution_height> eg. python scripts/render.py --scene data/toy --n_seconds 5 --fps 60 --render_name test --width 1920 --height 1080 Your video will be saved at root. You might have to play around with the fps and n_seconds to speed up or slow down. I couldn't get it accurately because of the lack of information and this is the best I could come up with. To be honest, this is only a short-term solution too, since the author has promised to publish an official one. So stay tuned! And my fork edits end here. Interactive training and rendering This codebase comes with an interactive testbed that includes many features beyond our academic publication: Additional training features, such as extrinsics and intrinsics optimization. Marching cubes for NeRF->Mesh and SDF->Mesh conversion. A spline-based camera path editor to create videos. Debug visualizations of the activations of every neuron input and output. And many more task-specific settings. See also our one minute demonstration video of the tool . NeRF fox One test scene is provided in this repository, using a small number of frames from a casually captured phone video: instant-ngp$ ./build/testbed --scene data/nerf/fox Alternatively, download any NeRF-compatible scene (e.g. from the NeRF authors' drive ). Now you can run: instant-ngp$ ./build/testbed --scene data/nerf_synthetic/lego/transforms_train.json For more information about preparing datasets for use with our NeRF implementation, please see this document . SDF armadillo instant-ngp$ ./build/testbed --scene data/sdf/armadillo.obj Image of Einstein instant-ngp$ ./build/testbed --scene data/image/albert.exr To reproduce the gigapixel results, download, for example, the Tokyo image and convert it to .bin using the scripts/image2bin.py script. This custom format improves compatibility and loading speed when resolution is high. Now you can run: instant-ngp$ ./build/testbed --scene data/image/tokyo.bin Volume Renderer Download the nanovdb volume for the Disney cloud , which is derived from here ( CC BY-SA 3.0 ). instant-ngp$ ./build/testbed --mode volume --scene data/volume/wdas_cloud_quarter.nvdb Python bindings To conduct controlled experiments in an automated fashion, all features from the interactive testbed (and more!) have Python bindings that can be easily instrumented. For an example of how the ./build/testbed application can be implemented and extended from within Python, see ./scripts/run.py , which supports a superset of the command line arguments that ./build/testbed does. Happy hacking! Troubleshooting compile errors Before investigating further, make sure all submodules are up-to-date and try compiling again. instant-ngp$ git submodule sync --recursive instant-ngp$ git submodule update --init --recursive If instant-ngp still fails to compile, update CUDA as well as your compiler to the latest versions you can install on your system. It is crucial that you update both , as newer CUDA versions are not always compatible with earlier compilers and vice versa. If your problem persists, consult the following table of known issues. Problem Resolution CMake error: No CUDA toolset found / CUDA_ARCHITECTURES is empty for target \"cmTC_0c70f\" Windows: the Visual Studio CUDA integration was not installed correctly. Follow these instructions to fix the problem without re-installing CUDA. ( #18 ) Linux: Environment variables for your CUDA installation are probably incorrectly set. You may work around the issue using cmake . -B build -DCMAKE_CUDA_COMPILER=/usr/local/cuda-<your cuda version>/bin/nvcc ( #28 ) CMake error: No known features for CXX compiler \"MSVC\" Reinstall Visual Studio & make sure you run CMake from a developer shell. ( #21 ) Compile error: undefined references to \"cudaGraphExecUpdate\" / identifier \"cublasSetWorkspace\" is undefined Update your CUDA installation (which is likely 11.0) to 11.3 or higher. ( #34 #41 #42 ) Compile error: too few arguments in function call Update submodules with the above two git commands. ( #37 #52 ) Python error: No module named 'pyngp' It is likely that CMake did not detect your Python installation and therefore did not build pyngp . Check CMake logs to verify this. If pyngp was built in a different folder than instant-ngp/build , Python will be unable to detect it and you have to supply the full path to the import statement. ( #43 ) If you cannot find your problem in the table, please feel free to open an issue and ask for help. Thanks Many thanks to Jonathan Tremblay and Andrew Tao for testing early versions of this codebase and to Arman Toorians and Saurabh Jain for the factory robot dataset. We also thank Andrew Webb for noticing that one of the prime numbers in the spatial hash was not actually prime; this has been fixed since. This project makes use of a number of awesome open source libraries, including: tiny-cuda-nn for fast CUDA MLP networks tinyexr for EXR format support tinyobjloader for OBJ format support stb_image for PNG and JPEG support Dear ImGui an excellent immediate mode GUI library Eigen a C++ template library for linear algebra pybind11 for seamless C++ / Python interop and others! See the dependencies folder. Many thanks to the authors of these brilliant projects! License and Citation @article { mueller2022instant , title = {Instant Neural Graphics Primitives with a Multiresolution Hash Encoding} , author = {Thomas M\\\"uller and Alex Evans and Christoph Schied and Alexander Keller} , journal = {arXiv:2201.05989} , year = {2022} , month = jan } Copyright \u00a9 2022, NVIDIA Corporation. All rights reserved. This work is made available under the Nvidia Source Code License-NC. Click here to view a copy of this license.","title":"NeRF Windows Installations"},{"location":"instant-ngp-windows/#instant-neural-graphics-primitives","text":"","title":"Instant Neural Graphics Primitives !"},{"location":"instant-ngp-windows/#requirements","text":"An NVIDIA GPU ; tensor cores increase performance when available. All shown results come from an RTX 3090. Python ver: 3.9.* Visual Studio Community 2019 (Latest the best, ~8GB) Below are the install requirements CUDA v11.6 . You can check ur CUDA version via nvcc --version in any prompt and if it's not CUDA11.6, refer to this to swap/install the correct version. On some machines, pyexr refuses to install via pip . This can be resolved by installing OpenEXR from here . See later. This installation tutorial will be using Anaconda. Download anaconda prompt here . OptiX 7.3 or higher for faster mesh SDF training. You need to either login or join to obtain the installer. Set the system environment variables OptiX_INSTALL_DIR to the installation directory if it is not discovered automatically. Should look like this:","title":"Requirements"},{"location":"instant-ngp-windows/#compilation","text":"copy these files C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v11.6\\extras\\visual_studio_integration\\MSBuildExtensions to here C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\MSBuild\\Microsoft\\VC\\v160\\BuildCustomizations cd into a directory that you want to download the codes at. Eg. cd F:\\Tutorial\\ngp\\ Begin by cloning this repository and all its submodules using the following command (if you don't have git, download here and add to path): $ git clone --recursive https://github.com/nvlabs/instant-ngp $ cd instant-ngp if your python is not 3.9 (check with command python --version ) then you need to run the following command to get it to ver 3.9.* conda install python=3.9 Then, open Developer Command Prompt , you can find this in your search bar. Then cd to where you cloned your repository so you are in its root folder /instant-ng/ : cmake . -B build cmake --build build --config RelWithDebInfo -j 16 If the any of these build fails, please consult this list of possible fixes before opening an issue. If automatic GPU architecture detection fails, (as can happen if you have multiple GPUs installed), set the TCNN_CUDA_ARCHITECTURES enivonment variable for the GPU you would like to use. The following table lists the values for common GPUs. If your GPU is not listed, consult this exhaustive list . RTX 30X0 A100 RTX 20X0 TITAN V / V100 GTX 10X0 / TITAN Xp GTX 9X0 K80 86 80 75 70 61 52 37","title":"Compilation"},{"location":"instant-ngp-windows/#interactive-training-and-rendering-on-custom-image-sets","text":"Install COLMAP , I used ver 3.7 Add it to your system environment variables at Environment Variables > System Variables Path > Edit environment variable open anaconda prompt, if you don't have you don't have you can get it here cd into isntant-ngp as root conda create -n ngp python = 3 .9 conda activate ngp pip install -r requirements.txt if pyexr cannot be installed via pip install pyexr , download OpenEXR\u20111.3.2\u2011cp39\u2011cp39\u2011win_amd64.whl and move it to your root folder. Then you can run: pip install OpenEXR-1.3.2-cp39-cp39-win_amd64.whl Place your custom image set under data/<image_set_name> Get transform.json from the following command. Insert your path to your images at <image/path> python scripts/colmap2nerf.py --colmap_matcher exhaustive --run_colmap --aabb_scale 16 --images <image/path> transform.json will be generated at the root folder, drag and drop it into your data/<image_set_name> folder. You have to reorganize the folder structure due to how transforms.json is created... For example: File Structure BEFORE generating transform.json \ud83d\udcc2instant-ngp/ # this is root \u251c\u2500\u2500 \ud83d\udcc2data/ \u2502 \u251c\u2500\u2500 \ud83d\udcc2toy_truck/ \u2502 \u2502 \u251c\u2500\u2500 \ud83d\udcdctoy_truck_001.jpg \u2502 \u2502 \u251c\u2500\u2500 \ud83d\udcdctoy_truck_002.jpg \u2502 \u2502 \u2502... \u2502 \u2502... \u2502... File Structure AFTER generating transform.json \ud83d\udcc2instant-ngp/ # this is root \u251c\u2500\u2500 \ud83d\udcc2data/ \u2502 \u251c\u2500\u2500 \ud83d\udcc2toy_truck/ \u2502 \u2502 \u251c\u2500\u2500 \ud83d\udcdctransforms.json/ \u2502 \u2502 \u251c\u2500\u2500 \ud83d\udcc2data/ \u2502 \u2502 \u2502 \u251c\u2500\u2500 \ud83d\udcc2toy_truck/ \u2502 \u2502 \u2502 \u2502 \u251c\u2500\u2500 \ud83d\udcdctoy_truck_001.jpg \u2502 \u2502 \u2502 \u2502 \u251c\u2500\u2500 \ud83d\udcdctoy_truck_002.jpg \u2502 \u2502 \u2502 \u2502 \u2502... \u2502 \u2502 \u2502 \u2502... \u2502 \u2502 \u2502... \u2502 \u2502... \u2502... Note: adjusting the \"aabb_scale\" inside transform.json can reduce load on GPU VRAM. The lower the value the less intensive it'll be. Finally, to run instant-ngp: <path_to_your_ngp> \\i nstant-ngp \\b uild \\t estbed.exe --scene data/<image_set_name> eg. C:\\user\\user\\download\\instant-ngp\\build\\testbed.exe --scene data/toy_truck And it should launch the GUI and everything amazing with it","title":"Interactive Training and Rendering on Custom Image Sets"},{"location":"instant-ngp-windows/#rendering-custom-camera-path","text":"May need to install more dependencies. Install pip install tqdm scipy pillow opencv-python , conda install -c conda-forge ffmpeg , might be needed in the conda virtual environment. Refer to installation of pyexr above in the installation section if you didn't install that too. Train any image set like above. After you have reached a point that you are satisfied with your training, save a Snapshot on the GUI. (one of the tabs & no need to edit the path & the name) Find another GUI called camera path, it'll play hide and seek with you but it is there so find that window. The GUI is so well made, if you know how to use any 3D engine, it's really similar. Add camera path will give you a new angle of the camera. After you have finished adding your camera points, save the camera path. (no need to edit the path & the name) Render the path with the following command: python scripts/render.py --scene <scene_path> --n_seconds <seconds> --fps <fps> --render_name <name> --width <resolution_width> --height <resolution_height> eg. python scripts/render.py --scene data/toy --n_seconds 5 --fps 60 --render_name test --width 1920 --height 1080 Your video will be saved at root. You might have to play around with the fps and n_seconds to speed up or slow down. I couldn't get it accurately because of the lack of information and this is the best I could come up with. To be honest, this is only a short-term solution too, since the author has promised to publish an official one. So stay tuned! And my fork edits end here.","title":"Rendering custom camera path"},{"location":"instant-ngp-windows/#interactive-training-and-rendering","text":"This codebase comes with an interactive testbed that includes many features beyond our academic publication: Additional training features, such as extrinsics and intrinsics optimization. Marching cubes for NeRF->Mesh and SDF->Mesh conversion. A spline-based camera path editor to create videos. Debug visualizations of the activations of every neuron input and output. And many more task-specific settings. See also our one minute demonstration video of the tool .","title":"Interactive training and rendering"},{"location":"instant-ngp-windows/#nerf-fox","text":"One test scene is provided in this repository, using a small number of frames from a casually captured phone video: instant-ngp$ ./build/testbed --scene data/nerf/fox Alternatively, download any NeRF-compatible scene (e.g. from the NeRF authors' drive ). Now you can run: instant-ngp$ ./build/testbed --scene data/nerf_synthetic/lego/transforms_train.json For more information about preparing datasets for use with our NeRF implementation, please see this document .","title":"NeRF fox"},{"location":"instant-ngp-windows/#sdf-armadillo","text":"instant-ngp$ ./build/testbed --scene data/sdf/armadillo.obj","title":"SDF armadillo"},{"location":"instant-ngp-windows/#image-of-einstein","text":"instant-ngp$ ./build/testbed --scene data/image/albert.exr To reproduce the gigapixel results, download, for example, the Tokyo image and convert it to .bin using the scripts/image2bin.py script. This custom format improves compatibility and loading speed when resolution is high. Now you can run: instant-ngp$ ./build/testbed --scene data/image/tokyo.bin","title":"Image of Einstein"},{"location":"instant-ngp-windows/#volume-renderer","text":"Download the nanovdb volume for the Disney cloud , which is derived from here ( CC BY-SA 3.0 ). instant-ngp$ ./build/testbed --mode volume --scene data/volume/wdas_cloud_quarter.nvdb","title":"Volume Renderer"},{"location":"instant-ngp-windows/#python-bindings","text":"To conduct controlled experiments in an automated fashion, all features from the interactive testbed (and more!) have Python bindings that can be easily instrumented. For an example of how the ./build/testbed application can be implemented and extended from within Python, see ./scripts/run.py , which supports a superset of the command line arguments that ./build/testbed does. Happy hacking!","title":"Python bindings"},{"location":"instant-ngp-windows/#troubleshooting-compile-errors","text":"Before investigating further, make sure all submodules are up-to-date and try compiling again. instant-ngp$ git submodule sync --recursive instant-ngp$ git submodule update --init --recursive If instant-ngp still fails to compile, update CUDA as well as your compiler to the latest versions you can install on your system. It is crucial that you update both , as newer CUDA versions are not always compatible with earlier compilers and vice versa. If your problem persists, consult the following table of known issues. Problem Resolution CMake error: No CUDA toolset found / CUDA_ARCHITECTURES is empty for target \"cmTC_0c70f\" Windows: the Visual Studio CUDA integration was not installed correctly. Follow these instructions to fix the problem without re-installing CUDA. ( #18 ) Linux: Environment variables for your CUDA installation are probably incorrectly set. You may work around the issue using cmake . -B build -DCMAKE_CUDA_COMPILER=/usr/local/cuda-<your cuda version>/bin/nvcc ( #28 ) CMake error: No known features for CXX compiler \"MSVC\" Reinstall Visual Studio & make sure you run CMake from a developer shell. ( #21 ) Compile error: undefined references to \"cudaGraphExecUpdate\" / identifier \"cublasSetWorkspace\" is undefined Update your CUDA installation (which is likely 11.0) to 11.3 or higher. ( #34 #41 #42 ) Compile error: too few arguments in function call Update submodules with the above two git commands. ( #37 #52 ) Python error: No module named 'pyngp' It is likely that CMake did not detect your Python installation and therefore did not build pyngp . Check CMake logs to verify this. If pyngp was built in a different folder than instant-ngp/build , Python will be unable to detect it and you have to supply the full path to the import statement. ( #43 ) If you cannot find your problem in the table, please feel free to open an issue and ask for help.","title":"Troubleshooting compile errors"},{"location":"instant-ngp-windows/#thanks","text":"Many thanks to Jonathan Tremblay and Andrew Tao for testing early versions of this codebase and to Arman Toorians and Saurabh Jain for the factory robot dataset. We also thank Andrew Webb for noticing that one of the prime numbers in the spatial hash was not actually prime; this has been fixed since. This project makes use of a number of awesome open source libraries, including: tiny-cuda-nn for fast CUDA MLP networks tinyexr for EXR format support tinyobjloader for OBJ format support stb_image for PNG and JPEG support Dear ImGui an excellent immediate mode GUI library Eigen a C++ template library for linear algebra pybind11 for seamless C++ / Python interop and others! See the dependencies folder. Many thanks to the authors of these brilliant projects!","title":"Thanks"},{"location":"instant-ngp-windows/#license-and-citation","text":"@article { mueller2022instant , title = {Instant Neural Graphics Primitives with a Multiresolution Hash Encoding} , author = {Thomas M\\\"uller and Alex Evans and Christoph Schied and Alexander Keller} , journal = {arXiv:2201.05989} , year = {2022} , month = jan } Copyright \u00a9 2022, NVIDIA Corporation. All rights reserved. This work is made available under the Nvidia Source Code License-NC. Click here to view a copy of this license.","title":"License and Citation"}]}