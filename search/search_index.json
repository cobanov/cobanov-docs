{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Hello \ud83d\udc4b Welcome to my blog, Here is a lot of stuff you can find, on my blog I usually write about topics of interest and sometimes I publish translations, in the guide part I explain some things that are difficult to set up. In the portfolio part, I have my works, sometimes I produce artistic things. If you want to see it, you can visit it. If you need more information about me or if you want to reach, you can look at the about section.","title":"Hello \ud83d\udc4b"},{"location":"#hello","text":"Welcome to my blog, Here is a lot of stuff you can find, on my blog I usually write about topics of interest and sometimes I publish translations, in the guide part I explain some things that are difficult to set up. In the portfolio part, I have my works, sometimes I produce artistic things. If you want to see it, you can visit it. If you need more information about me or if you want to reach, you can look at the about section.","title":"Hello \ud83d\udc4b"},{"location":"about/","text":"Mert Cobanov #0001 Username: @cobanov Job: Data Scientist, Refik Anadol Studio Date of Birth: 02.01.1996 About Community lover, data scientist and generative artist. I love to share what I know, so I try to provide free data science and machine learning education to everyone on my twitter and youtube channel. I teach at several schools and communities each year. I work as a data scientist at Refik Anadol Studio , where we do great artistic works with my excellent team, and we try to digitize the memories of humanity to immortalize it. Links More You can see my work in my github repos and my humble portfolio . I really enjoy writing minimal tools that make the lives of software developers easier, building end-to-end pipelines, and doing AI artistic painting works that motivate me immensely. I also digitize and repair old video tapes and bring them to high resolution and high fps forms.","title":"Main Page"},{"location":"about/#mert-cobanov-0001","text":"Username: @cobanov Job: Data Scientist, Refik Anadol Studio Date of Birth: 02.01.1996","title":"Mert Cobanov #0001"},{"location":"about/#about","text":"Community lover, data scientist and generative artist. I love to share what I know, so I try to provide free data science and machine learning education to everyone on my twitter and youtube channel. I teach at several schools and communities each year. I work as a data scientist at Refik Anadol Studio , where we do great artistic works with my excellent team, and we try to digitize the memories of humanity to immortalize it.","title":"About"},{"location":"about/#links","text":"","title":"Links"},{"location":"about/#more","text":"You can see my work in my github repos and my humble portfolio . I really enjoy writing minimal tools that make the lives of software developers easier, building end-to-end pipelines, and doing AI artistic painting works that motivate me immensely. I also digitize and repair old video tapes and bring them to high resolution and high fps forms.","title":"More"},{"location":"cyberpunk/","text":"Bir Cypherpunk'\u0131n Manifestosu by Eric Hughes Elektronik \u00e7a\u011fda a\u00e7\u0131k bir toplum i\u00e7in mahremiyet gereklidir. Gizlilik gizlilik de\u011fildir. \u00d6zel bir konu, t\u00fcm d\u00fcnyan\u0131n bilmesini istemedi\u011fi bir \u015feydir, ancak gizli bir konu, kimsenin bilmesini istemedi\u011fi bir \u015feydir. Gizlilik, kendini d\u00fcnyaya se\u00e7ici olarak g\u00f6sterme g\u00fcc\u00fcd\u00fcr. E\u011fer iki taraf bir t\u00fcr anla\u015fmaya sahipse, her birinin etkile\u015fimlerinin bir an\u0131s\u0131 vard\u0131r. Her bir taraf bununla ilgili kendi an\u0131lar\u0131 hakk\u0131nda konu\u015fabilir; kimse bunu nas\u0131l engelleyebilir? Buna kar\u015f\u0131 yasalar \u00e7\u0131kar\u0131labilir, ancak konu\u015fma \u00f6zg\u00fcrl\u00fc\u011f\u00fc, mahremiyetten bile daha fazlas\u0131, a\u00e7\u0131k bir toplum i\u00e7in esast\u0131r; hi\u00e7bir konu\u015fmay\u0131 k\u0131s\u0131tlamamaya \u00e7al\u0131\u015f\u0131yoruz. Ayn\u0131 forumda bir\u00e7ok taraf birlikte konu\u015fursa, her biri di\u011ferleriyle konu\u015fabilir ve bireyler ve di\u011fer taraflar hakk\u0131ndaki bilgileri bir araya toplayabilir. Elektronik ileti\u015fimin g\u00fcc\u00fc bu t\u00fcr grup konu\u015fmalar\u0131n\u0131 m\u00fcmk\u00fcn k\u0131lm\u0131\u015ft\u0131r ve sadece biz isteyebilece\u011fimiz i\u00e7in ortadan kalkmayacakt\u0131r. Gizlili\u011fi arzulad\u0131\u011f\u0131m\u0131z i\u00e7in, bir i\u015flemin her bir taraf\u0131n\u0131n yaln\u0131zca o i\u015flem i\u00e7in do\u011frudan gerekli olan\u0131 bilmesini sa\u011flamal\u0131y\u0131z. Herhangi bir bilgi konu\u015fulabilece\u011finden, m\u00fcmk\u00fcn oldu\u011funca az a\u00e7\u0131klama yapt\u0131\u011f\u0131m\u0131zdan emin olmal\u0131y\u0131z. \u00c7o\u011fu durumda ki\u015fisel kimlik belirgin de\u011fildir. Bir ma\u011fazadan bir dergi sat\u0131n ald\u0131\u011f\u0131mda ve katiyere nakit verdi\u011fimde, kim oldu\u011fumu bilmeme gerek yok. Elektronik posta sa\u011flay\u0131c\u0131mdan mesaj g\u00f6nderip almas\u0131n\u0131 istedi\u011fimde, sa\u011flay\u0131c\u0131m\u0131n kiminle konu\u015ftu\u011fumu, ne s\u00f6yledi\u011fimi veya ba\u015fkalar\u0131n\u0131n bana ne s\u00f6yledi\u011fini bilmesine gerek yoktur; sa\u011flay\u0131c\u0131m\u0131n sadece mesaj\u0131 oraya nas\u0131l ula\u015ft\u0131raca\u011f\u0131n\u0131 ve onlara ne kadar \u00fccret bor\u00e7lu oldu\u011fumu bilmesi gerekiyor. Kimli\u011fim i\u015flemin alt\u0131nda yatan mekanizma taraf\u0131ndan if\u015fa edildi\u011finde, mahremiyetim yok. Burada se\u00e7ici olarak kendimi if\u015fa edemem; her zaman yapmal\u0131y\u0131m kendimi if\u015fa et. Bu nedenle, a\u00e7\u0131k bir toplumda mahremiyet, anonim i\u015flem sistemleri gerektirir. \u015eimdiye kadar, nakit bu t\u00fcr birincil sistem olmu\u015ftur. Anonim bir i\u015flem sistemi, gizli bir i\u015flem sistemi de\u011fildir. Anonim bir sistem, bireylere kimliklerini istendi\u011finde ve yaln\u0131zca istendi\u011finde if\u015fa etme yetkisi verir; mahremiyetin \u00f6z\u00fc budur. A\u00e7\u0131k bir toplumda gizlilik de kriptografi gerektirir. Bir \u015fey s\u00f6ylersem, sadece niyet etti\u011fim ki\u015filer taraf\u0131ndan duyulmas\u0131n\u0131 isterim. Konu\u015fmam\u0131n i\u00e7eri\u011fi d\u00fcnyaya a\u00e7\u0131ksa, mahremiyetim yok. \u015eifrelemek, mahremiyet arzusunu belirtmektir ve zay\u0131f \u015fifreleme ile \u015fifrelemek, mahremiyet i\u00e7in \u00e7ok fazla arzu olmad\u0131\u011f\u0131n\u0131 belirtmektir. Ayr\u0131ca, varsay\u0131lan anonimlik oldu\u011funda, ki\u015finin kimli\u011fini g\u00fcvence ile ortaya \u00e7\u0131karmak i\u00e7in kriptografik imza gerekir. H\u00fck\u00fcmetlerin, \u015firketlerin veya di\u011fer b\u00fcy\u00fck, kimli\u011fi belirsiz kurulu\u015flar\u0131n, kendi yararlar\u0131 d\u0131\u015f\u0131nda bize mahremiyet vermelerini bekleyemeyiz. Bizim hakk\u0131m\u0131zda konu\u015fmak onlar\u0131n yarar\u0131nad\u0131r ve konu\u015fmalar\u0131n\u0131 beklemeliyiz. Konu\u015fmalar\u0131n\u0131 engellemeye \u00e7al\u0131\u015fmak, bilgi ger\u00e7ekleriyle sava\u015fmakt\u0131r. Bilgi sadece \u00f6zg\u00fcr olmak istemez, \u00f6zg\u00fcr olmay\u0131 arzular. Bilgi, mevcut depolama alan\u0131n\u0131 dolduracak \u015fekilde geni\u015fler. Bilgi, Rumor'un daha gen\u00e7, daha g\u00fc\u00e7l\u00fc kuzenidir; Bilgi, daha h\u0131zl\u0131d\u0131r, daha fazla g\u00f6ze sahiptir, daha fazlas\u0131n\u0131 bilir ve S\u00f6ylentiden daha az anlar. Herhangi bir mahremiyete sahip olmay\u0131 umuyorsak, kendi mahremiyetimizi savunmal\u0131y\u0131z. Bir araya gelmeli ve anonim i\u015flemlerin ger\u00e7ekle\u015fmesine izin veren sistemler olu\u015fturmal\u0131y\u0131z. \u0130nsanlar y\u00fczy\u0131llard\u0131r f\u0131s\u0131lt\u0131lar, karanl\u0131k, zarflar, kapal\u0131 kap\u0131lar, gizli tokala\u015fmalar ve kuryelerle kendi mahremiyetlerini savunuyorlar. Ge\u00e7mi\u015fin teknolojileri g\u00fc\u00e7l\u00fc bir mahremiyete izin vermiyordu, ancak elektronik teknolojiler izin veriyor. Biz Cypherpunk'lar, kendimizi anonim sistemler olu\u015fturmaya adad\u0131k. Gizlili\u011fimizi kriptografi, anonim posta y\u00f6nlendirme sistemleri, dijital imzalar ve elektronik para ile koruyoruz. Cypherpunk'lar kod yazar. Birinin mahremiyeti savunmak i\u00e7in yaz\u0131l\u0131m yazmas\u0131 gerekti\u011fini biliyoruz ve hepimiz bunu yapmad\u0131k\u00e7a mahremiyet elde edemeyece\u011fimiz i\u00e7in yazaca\u011f\u0131z. Kodumuzu Cypherpunk arkada\u015flar\u0131m\u0131z\u0131n pratik yap\u0131p onunla oynayabilmeleri i\u00e7in yay\u0131nl\u0131yoruz. Kodumuz, d\u00fcnya \u00e7ap\u0131nda herkesin kullan\u0131m\u0131 i\u00e7in \u00fccretsizdir. Yazd\u0131\u011f\u0131m\u0131z yaz\u0131l\u0131m\u0131 onaylamaman\u0131z pek umurumuzda de\u011fil. Yaz\u0131l\u0131m\u0131n yok edilemeyece\u011fini ve geni\u015f bir alana yay\u0131lm\u0131\u015f bir sistemin kapat\u0131lamayaca\u011f\u0131n\u0131 biliyoruz. \u015eifreleme temelde \u00f6zel bir eylem oldu\u011fundan, Cypherpunk'lar kriptografi ile ilgili d\u00fczenlemelerden \u015fikayet\u00e7idir. \u015eifreleme eylemi asl\u0131nda bilgiyi kamusal alandan kald\u0131r\u0131r. Kriptografiye kar\u015f\u0131 yasalar bile ancak bir ulusun s\u0131n\u0131r\u0131na ve \u015fiddetinin koluna kadar ula\u015f\u0131r. Kriptografi ka\u00e7\u0131n\u0131lmaz olarak t\u00fcm d\u00fcnyaya ve onunla birlikte m\u00fcmk\u00fcn k\u0131ld\u0131\u011f\u0131 anonim i\u015flem sistemlerine yay\u0131lacakt\u0131r. Mahremiyetin yayg\u0131nla\u015fmas\u0131 i\u00e7in bir sosyal s\u00f6zle\u015fmenin par\u00e7as\u0131 olmas\u0131 gerekir. \u0130nsanlar bir araya gelmeli ve bu sistemleri ortak yarar i\u00e7in kullanmal\u0131d\u0131r. Mahremiyet ancak, ki\u015finin toplumdaki hemcinslerinin i\u015fbirli\u011fi kadar geni\u015fler. Biz Cypherpunk'lar sorular\u0131n\u0131z\u0131 ve endi\u015felerinizi ar\u0131yoruz ve kendimizi kand\u0131rmamak i\u00e7in sizi me\u015fgul edebilece\u011fimizi umuyoruz. Bununla birlikte, baz\u0131lar\u0131 hedeflerimize kat\u0131lmayabilece\u011finden, rotam\u0131zdan ayr\u0131lmayaca\u011f\u0131z. Cypherpunks, a\u011flar\u0131 gizlilik i\u00e7in daha g\u00fcvenli hale getirmek i\u00e7in aktif olarak \u00e7al\u0131\u015f\u0131yor. H\u0131zla birlikte ilerleyelim. \u0130leriye. Eric Hughes < hughes@soda.berkeley.edu > 9 Mart 1993","title":"Cypherpunk Manifesto"},{"location":"cyberpunk/#bir-cypherpunkn-manifestosu","text":"by Eric Hughes Elektronik \u00e7a\u011fda a\u00e7\u0131k bir toplum i\u00e7in mahremiyet gereklidir. Gizlilik gizlilik de\u011fildir. \u00d6zel bir konu, t\u00fcm d\u00fcnyan\u0131n bilmesini istemedi\u011fi bir \u015feydir, ancak gizli bir konu, kimsenin bilmesini istemedi\u011fi bir \u015feydir. Gizlilik, kendini d\u00fcnyaya se\u00e7ici olarak g\u00f6sterme g\u00fcc\u00fcd\u00fcr. E\u011fer iki taraf bir t\u00fcr anla\u015fmaya sahipse, her birinin etkile\u015fimlerinin bir an\u0131s\u0131 vard\u0131r. Her bir taraf bununla ilgili kendi an\u0131lar\u0131 hakk\u0131nda konu\u015fabilir; kimse bunu nas\u0131l engelleyebilir? Buna kar\u015f\u0131 yasalar \u00e7\u0131kar\u0131labilir, ancak konu\u015fma \u00f6zg\u00fcrl\u00fc\u011f\u00fc, mahremiyetten bile daha fazlas\u0131, a\u00e7\u0131k bir toplum i\u00e7in esast\u0131r; hi\u00e7bir konu\u015fmay\u0131 k\u0131s\u0131tlamamaya \u00e7al\u0131\u015f\u0131yoruz. Ayn\u0131 forumda bir\u00e7ok taraf birlikte konu\u015fursa, her biri di\u011ferleriyle konu\u015fabilir ve bireyler ve di\u011fer taraflar hakk\u0131ndaki bilgileri bir araya toplayabilir. Elektronik ileti\u015fimin g\u00fcc\u00fc bu t\u00fcr grup konu\u015fmalar\u0131n\u0131 m\u00fcmk\u00fcn k\u0131lm\u0131\u015ft\u0131r ve sadece biz isteyebilece\u011fimiz i\u00e7in ortadan kalkmayacakt\u0131r. Gizlili\u011fi arzulad\u0131\u011f\u0131m\u0131z i\u00e7in, bir i\u015flemin her bir taraf\u0131n\u0131n yaln\u0131zca o i\u015flem i\u00e7in do\u011frudan gerekli olan\u0131 bilmesini sa\u011flamal\u0131y\u0131z. Herhangi bir bilgi konu\u015fulabilece\u011finden, m\u00fcmk\u00fcn oldu\u011funca az a\u00e7\u0131klama yapt\u0131\u011f\u0131m\u0131zdan emin olmal\u0131y\u0131z. \u00c7o\u011fu durumda ki\u015fisel kimlik belirgin de\u011fildir. Bir ma\u011fazadan bir dergi sat\u0131n ald\u0131\u011f\u0131mda ve katiyere nakit verdi\u011fimde, kim oldu\u011fumu bilmeme gerek yok. Elektronik posta sa\u011flay\u0131c\u0131mdan mesaj g\u00f6nderip almas\u0131n\u0131 istedi\u011fimde, sa\u011flay\u0131c\u0131m\u0131n kiminle konu\u015ftu\u011fumu, ne s\u00f6yledi\u011fimi veya ba\u015fkalar\u0131n\u0131n bana ne s\u00f6yledi\u011fini bilmesine gerek yoktur; sa\u011flay\u0131c\u0131m\u0131n sadece mesaj\u0131 oraya nas\u0131l ula\u015ft\u0131raca\u011f\u0131n\u0131 ve onlara ne kadar \u00fccret bor\u00e7lu oldu\u011fumu bilmesi gerekiyor. Kimli\u011fim i\u015flemin alt\u0131nda yatan mekanizma taraf\u0131ndan if\u015fa edildi\u011finde, mahremiyetim yok. Burada se\u00e7ici olarak kendimi if\u015fa edemem; her zaman yapmal\u0131y\u0131m kendimi if\u015fa et. Bu nedenle, a\u00e7\u0131k bir toplumda mahremiyet, anonim i\u015flem sistemleri gerektirir. \u015eimdiye kadar, nakit bu t\u00fcr birincil sistem olmu\u015ftur. Anonim bir i\u015flem sistemi, gizli bir i\u015flem sistemi de\u011fildir. Anonim bir sistem, bireylere kimliklerini istendi\u011finde ve yaln\u0131zca istendi\u011finde if\u015fa etme yetkisi verir; mahremiyetin \u00f6z\u00fc budur. A\u00e7\u0131k bir toplumda gizlilik de kriptografi gerektirir. Bir \u015fey s\u00f6ylersem, sadece niyet etti\u011fim ki\u015filer taraf\u0131ndan duyulmas\u0131n\u0131 isterim. Konu\u015fmam\u0131n i\u00e7eri\u011fi d\u00fcnyaya a\u00e7\u0131ksa, mahremiyetim yok. \u015eifrelemek, mahremiyet arzusunu belirtmektir ve zay\u0131f \u015fifreleme ile \u015fifrelemek, mahremiyet i\u00e7in \u00e7ok fazla arzu olmad\u0131\u011f\u0131n\u0131 belirtmektir. Ayr\u0131ca, varsay\u0131lan anonimlik oldu\u011funda, ki\u015finin kimli\u011fini g\u00fcvence ile ortaya \u00e7\u0131karmak i\u00e7in kriptografik imza gerekir. H\u00fck\u00fcmetlerin, \u015firketlerin veya di\u011fer b\u00fcy\u00fck, kimli\u011fi belirsiz kurulu\u015flar\u0131n, kendi yararlar\u0131 d\u0131\u015f\u0131nda bize mahremiyet vermelerini bekleyemeyiz. Bizim hakk\u0131m\u0131zda konu\u015fmak onlar\u0131n yarar\u0131nad\u0131r ve konu\u015fmalar\u0131n\u0131 beklemeliyiz. Konu\u015fmalar\u0131n\u0131 engellemeye \u00e7al\u0131\u015fmak, bilgi ger\u00e7ekleriyle sava\u015fmakt\u0131r. Bilgi sadece \u00f6zg\u00fcr olmak istemez, \u00f6zg\u00fcr olmay\u0131 arzular. Bilgi, mevcut depolama alan\u0131n\u0131 dolduracak \u015fekilde geni\u015fler. Bilgi, Rumor'un daha gen\u00e7, daha g\u00fc\u00e7l\u00fc kuzenidir; Bilgi, daha h\u0131zl\u0131d\u0131r, daha fazla g\u00f6ze sahiptir, daha fazlas\u0131n\u0131 bilir ve S\u00f6ylentiden daha az anlar. Herhangi bir mahremiyete sahip olmay\u0131 umuyorsak, kendi mahremiyetimizi savunmal\u0131y\u0131z. Bir araya gelmeli ve anonim i\u015flemlerin ger\u00e7ekle\u015fmesine izin veren sistemler olu\u015fturmal\u0131y\u0131z. \u0130nsanlar y\u00fczy\u0131llard\u0131r f\u0131s\u0131lt\u0131lar, karanl\u0131k, zarflar, kapal\u0131 kap\u0131lar, gizli tokala\u015fmalar ve kuryelerle kendi mahremiyetlerini savunuyorlar. Ge\u00e7mi\u015fin teknolojileri g\u00fc\u00e7l\u00fc bir mahremiyete izin vermiyordu, ancak elektronik teknolojiler izin veriyor. Biz Cypherpunk'lar, kendimizi anonim sistemler olu\u015fturmaya adad\u0131k. Gizlili\u011fimizi kriptografi, anonim posta y\u00f6nlendirme sistemleri, dijital imzalar ve elektronik para ile koruyoruz. Cypherpunk'lar kod yazar. Birinin mahremiyeti savunmak i\u00e7in yaz\u0131l\u0131m yazmas\u0131 gerekti\u011fini biliyoruz ve hepimiz bunu yapmad\u0131k\u00e7a mahremiyet elde edemeyece\u011fimiz i\u00e7in yazaca\u011f\u0131z. Kodumuzu Cypherpunk arkada\u015flar\u0131m\u0131z\u0131n pratik yap\u0131p onunla oynayabilmeleri i\u00e7in yay\u0131nl\u0131yoruz. Kodumuz, d\u00fcnya \u00e7ap\u0131nda herkesin kullan\u0131m\u0131 i\u00e7in \u00fccretsizdir. Yazd\u0131\u011f\u0131m\u0131z yaz\u0131l\u0131m\u0131 onaylamaman\u0131z pek umurumuzda de\u011fil. Yaz\u0131l\u0131m\u0131n yok edilemeyece\u011fini ve geni\u015f bir alana yay\u0131lm\u0131\u015f bir sistemin kapat\u0131lamayaca\u011f\u0131n\u0131 biliyoruz. \u015eifreleme temelde \u00f6zel bir eylem oldu\u011fundan, Cypherpunk'lar kriptografi ile ilgili d\u00fczenlemelerden \u015fikayet\u00e7idir. \u015eifreleme eylemi asl\u0131nda bilgiyi kamusal alandan kald\u0131r\u0131r. Kriptografiye kar\u015f\u0131 yasalar bile ancak bir ulusun s\u0131n\u0131r\u0131na ve \u015fiddetinin koluna kadar ula\u015f\u0131r. Kriptografi ka\u00e7\u0131n\u0131lmaz olarak t\u00fcm d\u00fcnyaya ve onunla birlikte m\u00fcmk\u00fcn k\u0131ld\u0131\u011f\u0131 anonim i\u015flem sistemlerine yay\u0131lacakt\u0131r. Mahremiyetin yayg\u0131nla\u015fmas\u0131 i\u00e7in bir sosyal s\u00f6zle\u015fmenin par\u00e7as\u0131 olmas\u0131 gerekir. \u0130nsanlar bir araya gelmeli ve bu sistemleri ortak yarar i\u00e7in kullanmal\u0131d\u0131r. Mahremiyet ancak, ki\u015finin toplumdaki hemcinslerinin i\u015fbirli\u011fi kadar geni\u015fler. Biz Cypherpunk'lar sorular\u0131n\u0131z\u0131 ve endi\u015felerinizi ar\u0131yoruz ve kendimizi kand\u0131rmamak i\u00e7in sizi me\u015fgul edebilece\u011fimizi umuyoruz. Bununla birlikte, baz\u0131lar\u0131 hedeflerimize kat\u0131lmayabilece\u011finden, rotam\u0131zdan ayr\u0131lmayaca\u011f\u0131z. Cypherpunks, a\u011flar\u0131 gizlilik i\u00e7in daha g\u00fcvenli hale getirmek i\u00e7in aktif olarak \u00e7al\u0131\u015f\u0131yor. H\u0131zla birlikte ilerleyelim. \u0130leriye. Eric Hughes < hughes@soda.berkeley.edu > 9 Mart 1993","title":"Bir Cypherpunk'\u0131n Manifestosu"},{"location":"dreambooth-rehberi/","text":"Dreambooth Extension for Stable-Diffusion-WebUI This is a WIP port of Shivam Shriao's Diffusers Repo , which is a modified version of the default Huggingface Diffusers Repo optimized for better performance on lower-VRAM GPUs. It also adds several other features, including training multiple concepts simultaneously, and (Coming soon) Inpainting training. Installation To install, simply go to the \"Extensions\" tab in the SD Web UI, select the \"Available\" sub-tab, pick \"Load from:\" to load the list of extensions, and finally, click \"install\" next to the Dreambooth entry. For 8bit adam to run properly, it may be necessary to install the CU116 version of torch and torchvision, which can be accomplished below: Refer to the appropriate script below for extra flags to install requirements: https://github.com/d8ahazard/sd_dreambooth_extension/blob/main/webui-user-dreambooth.bat https://github.com/d8ahazard/sd_dreambooth_extension/blob/main/webui-user-dreambooth.sh Setting the torch command to: TORCH_COMMAND=pip install torch==1.12.1+cu116 torchvision==0.13.1+cu116 --extra-index-url https://download.pytorch.org/whl/cu116 will ensure that the proper torch version is installed when webui-user is executed, and then left alone after that, versus trying to install conflicting versions. We also need a newer version of diffusers, as SD-WebUI uses version 0.3.0, while DB training requires > 0.6.0, so we use 0.7.2. Not having the right diffusers version is the cause of the 'UNet2DConditionModel' object has no attribute 'enable_gradient_checkpointing' error message, as well as safety checker warnings. To force sd-web-ui to only install one set of requirements, we can specify the command line argument: set/export REQS_FILE=.\\extensions\\sd_dreambooth_extension\\requirements.txt And last, if you wish to completely skip the \"native\" install routine of Dreambooth, you can set the following environment flag: DREAMBOOTH_SKIP_INSTALL=True This is ideal for \"offline mode\", where you don't want the script to constantly check things from pypi. After installing via the WebUI, it is recommended to set the above flags and re-launch the entire Stable-diffusion-webui, not just reload it. Usage Create a Model Go to the Dreambooth tab. Under the \"Create Model\" sub-tab, enter a new model name and select the source checkpoint to train from. The source checkpoint will be extracted to models\\dreambooth\\MODELNAME\\working - the original will not be touched. 2b. Optionally, you can also specify a huggingface model directory and token to create the Dreambooth dataset from huggingface.co. Model path format should be like so: 'runwayml/stable-diffusion-v1-5' Click \"Create\". This will take a minute or two, but when done, the UI should indicate that a new model directory has been set up. Training (Basic Settings) After creating a new model, select the new model name from the \"Model\" dropdown at the very top. Select the \"Train Model\" sub-tab. Fill in the paramters as described below: Concepts List - The path to a JSON file or a JSON string containing multiple concepts. See here for an example. If a concepts list is specified, then the instance prompt, class prompt, instance data dir, and class data dir fields will be ignored. Instance Prompt - A short descriptor of your subject using a UNIQUE keyword and a classifier word. If training a dog, your instance prompt could be \"photo of zkz dog\". The key here is that \"zkz\" is not a word that might overlap with something in the real world \"fluff\", and \"dog\" is a generic word to describe your subject. This is only necessary if using prior preservation. You can use [filewords] as placeholder for reading caption from the image filename or a seprarte .txt file containing caption, for example, [filewords], in the style of zymkyr . This syntax is the same as textual inversion templates. Class Prompt - A keyword indicating what type of \"thing\" your subject is. If your instance prompt is \"photo of zkz dog\", your class prompt would be \"photo of a dog\". Leave this blank to disable prior preservation training. Dataset Directory - The path to the directory where the images described in Instance Prompt are kept. REQUIRED Classification dataset directory - The path to the directory where the images described in Class Prompt are kept. If a class prompt is specified and this is left blank, images will be generated to /models/dreambooth/MODELNAME/classifiers/ Total number of classification images to use - Leave at 0 to disable prior preservation. For best results you want ~n*10 classification images - so if you have 40 training photos, then set this to 400. This is just a guess. Training steps - How many total training steps to complete. According to this guide , you should train for appx 100 steps per sample image. So, if you have 40 instance/sample images, you would train for 4k steps. This is, of course, a rough approximation, and other values will have an effect on final output fidelity. Batch size - How many training steps to process simultaneously. You probably want to leave this at 1. Class batch size - How many classification images to generate simultaneously. Set this to whatever you can safely process at once using Txt2Image, or just leave it alone. Learning rate - You probably don't want to touch this. Resolution - The resolution to train images at. You probably want to keep this number at 512 or lower unless your GPU is insane. Lowering this (and the resolution of training images) may help with lower-VRAM GPUs. Save a checkpoint every N steps - How frequently to save a checkpoint from the trained data. I should probably change the default of this to 1000. Generate a preview image every N steps - How frequently will an image be generated as an example of training progress. Preview image prompt - The prompt to use to generate preview image. Leave blank to use the instance prompt. Preview image negative prompt - Like above, but negative. Leave blank to do nothing. :P Number of samples to generate - Self explainatory? Sample guidance scale - Like CFG Scale in Txt2Image/Img2Img, used for generating preview. Sample steps - Same as sample guidance scale, but the number of steps to run to generate preview. Advanced Settings Use CPU Only - As indicated, this is more of a last resort if you can't get it to train with any other settings. Also, as indicated, it will be abysmally slow. Also, you cannot use 8Bit-Adam with CPU Training, or you'll have a bad time. Don't Cache Latents - Why is this not just called \"cache\" latents? Because that's what the original script uses, and I'm trying to maintain the ability to update this as easily as possible. Anyway...when this box is checked latents will not be cached. When latents are not cached, you will save a bit of VRAM, but train slightly slower. Train Text Encoder - Not required, but recommended. Enabling this will probably cost a bit more VRAM, but also purportedly increase output image fidelity. Use 8Bit Adam - Enable this to save VRAM. Should now work on both windows and Linux without needing WSL. Center Crop - Crop images if they aren't the right dimensions? I don't use this, and I recommend you just crop your images \"right\". Gradient Checkpointing - Enable this to save VRAM at the cost of a bit of speed. Scale Learning Rate - I don't use this, not sure what impact it has on performance or output quality. Mixed Precision - Set to 'fp16' to save VRAM at the cost of speed. Everything after 'Mixed Precision' - Adjust at your own risk. Performance/quality benefits from changing these remain to be tested. The next two were added after I wrote the above bit, so just ignore me being a big liar. Pad Tokens - Pads the text tokens to a longer length for some reason. Max Token Length - raise the tokenizer's default limit above 75. Requires Pad Tokens for > 75. Apply Horizontal Flip - \"Apply horizontal flip augmentation\". Flips images horizontally at random, which can potentially offer better editability? Use EMA for finetuning - Use exponential moving average weight to reduce overfitting during the last iterations. Continuing Training Once a model has been trained for any number of steps, a config file is saved which contains all of the parameters from the UI. If you wish to continue training a model, you can simply select the model name from the dropdown and then click the blue button next to the model name dropdown to load previous parameters. Use DreamBooth to Fine-Tune Stable Diffusion in Google Colab Prepare Images Choosing Images When choosing images, it\u2019s recommended to keep the following in mind to get the best results: Upload a variety of images of your subject. If you\u2019re uploading images of a person, try something like 70% close-ups, 20% from the chest up, 10% full body, so Stable Diffusion also gets some idea of the rest of the subject and not only the face. Try to change things up as much as possible in each picture. This means: Varying the body pose Taking pictures on different days, in different lighting conditions, and with different backgrounds Showing a variety of expressions and emotions When generating new images, whatever you capture will be over-represented. For example, if you take multiple pictures with the same green field behind you, it\u2019s likely that the generated images of you will also contain the green field, even if you want a dystopic background. This can apply to anything, like jewelry, clothes, or even people in the background. If you want to avoid seeing that element in your generated image, make sure not to repeat it in every shot. On the other hand, if you want it in the generated images, make sure it\u2019s in your pictures more often. It\u2019s recommended that you provide ~50 images of what you\u2019d like to train Stable Diffusion on to get great results. However, I\u2019ve only used 20-30 so far, and the results are pretty good. If you\u2019re just starting out and want to test it out, I think 20-30 images should be good enough for now, and you can get 50 images after you\u2019ve seen it work. Resize & Crop to 512 x 512px Once you\u2019ve chosen your images, you should prepare them. First, we need to resize and crop our images to be 512 x 512px. We can easily do this using the website https://birme.net . To do this, just: Visit the website Upload your images Set your dimensions to 512 x 512px Adjust the cropping area to center your subject Click on Save as Zip to download the archive. You can then unzip it on your computer, and we\u2019ll use them a bit later. Birme.net - Resize Images Resizing Images using Birme.net Renaming Your Images We\u2019ll also want to rename our images to contain the subject\u2019s name: Firstly, the subject name should be one unique/random/unknown keyword. This is because Stable Diffusion also has some knowledge of The Sandman from other sources other than the one played by Tom Sturridge and we don\u2019t want it to get confused and make a combination of interpretations of The Sandman. As such, I\u2019ll call it Sandman2022 to make sure it\u2019s unique. Renaming images to subject (1), subject (2) .. subject (30). This is because, using this method, you can train multiple subjects at once. If you want to fine-tune Stable Diffusion with Sandman, your friend Kevin, and your cat, you can give it prepare images for each of them. For the Sandman you\u2019d have Sandman2022 (1), Sandman2022 (2) \u2026 Sandman (30), for Kevin you\u2019d have KevinKevinson2022 (1), KevinKevinson2022 (2) \u2026 KevinKevinson (30), and for your cat you\u2019d have DexterTheCat (1), DexterTheCat (2) \u2026 DexterTheCat(30). Here\u2019s me renaming my images for Sandman2022 in bulk on Windows. Just select them all, right click one of them and click Rename and give it what name you want and click anywhere to finish the renaming. Everything else will be renamed as well.","title":"DreamBooth Rehberi"},{"location":"dreambooth-rehberi/#dreambooth-extension-for-stable-diffusion-webui","text":"This is a WIP port of Shivam Shriao's Diffusers Repo , which is a modified version of the default Huggingface Diffusers Repo optimized for better performance on lower-VRAM GPUs. It also adds several other features, including training multiple concepts simultaneously, and (Coming soon) Inpainting training.","title":"Dreambooth Extension for Stable-Diffusion-WebUI"},{"location":"dreambooth-rehberi/#installation","text":"To install, simply go to the \"Extensions\" tab in the SD Web UI, select the \"Available\" sub-tab, pick \"Load from:\" to load the list of extensions, and finally, click \"install\" next to the Dreambooth entry. For 8bit adam to run properly, it may be necessary to install the CU116 version of torch and torchvision, which can be accomplished below: Refer to the appropriate script below for extra flags to install requirements: https://github.com/d8ahazard/sd_dreambooth_extension/blob/main/webui-user-dreambooth.bat https://github.com/d8ahazard/sd_dreambooth_extension/blob/main/webui-user-dreambooth.sh Setting the torch command to: TORCH_COMMAND=pip install torch==1.12.1+cu116 torchvision==0.13.1+cu116 --extra-index-url https://download.pytorch.org/whl/cu116 will ensure that the proper torch version is installed when webui-user is executed, and then left alone after that, versus trying to install conflicting versions. We also need a newer version of diffusers, as SD-WebUI uses version 0.3.0, while DB training requires > 0.6.0, so we use 0.7.2. Not having the right diffusers version is the cause of the 'UNet2DConditionModel' object has no attribute 'enable_gradient_checkpointing' error message, as well as safety checker warnings. To force sd-web-ui to only install one set of requirements, we can specify the command line argument: set/export REQS_FILE=.\\extensions\\sd_dreambooth_extension\\requirements.txt And last, if you wish to completely skip the \"native\" install routine of Dreambooth, you can set the following environment flag: DREAMBOOTH_SKIP_INSTALL=True This is ideal for \"offline mode\", where you don't want the script to constantly check things from pypi. After installing via the WebUI, it is recommended to set the above flags and re-launch the entire Stable-diffusion-webui, not just reload it.","title":"Installation"},{"location":"dreambooth-rehberi/#usage","text":"","title":"Usage"},{"location":"dreambooth-rehberi/#create-a-model","text":"Go to the Dreambooth tab. Under the \"Create Model\" sub-tab, enter a new model name and select the source checkpoint to train from. The source checkpoint will be extracted to models\\dreambooth\\MODELNAME\\working - the original will not be touched. 2b. Optionally, you can also specify a huggingface model directory and token to create the Dreambooth dataset from huggingface.co. Model path format should be like so: 'runwayml/stable-diffusion-v1-5' Click \"Create\". This will take a minute or two, but when done, the UI should indicate that a new model directory has been set up.","title":"Create a Model"},{"location":"dreambooth-rehberi/#training-basic-settings","text":"After creating a new model, select the new model name from the \"Model\" dropdown at the very top. Select the \"Train Model\" sub-tab. Fill in the paramters as described below: Concepts List - The path to a JSON file or a JSON string containing multiple concepts. See here for an example. If a concepts list is specified, then the instance prompt, class prompt, instance data dir, and class data dir fields will be ignored. Instance Prompt - A short descriptor of your subject using a UNIQUE keyword and a classifier word. If training a dog, your instance prompt could be \"photo of zkz dog\". The key here is that \"zkz\" is not a word that might overlap with something in the real world \"fluff\", and \"dog\" is a generic word to describe your subject. This is only necessary if using prior preservation. You can use [filewords] as placeholder for reading caption from the image filename or a seprarte .txt file containing caption, for example, [filewords], in the style of zymkyr . This syntax is the same as textual inversion templates. Class Prompt - A keyword indicating what type of \"thing\" your subject is. If your instance prompt is \"photo of zkz dog\", your class prompt would be \"photo of a dog\". Leave this blank to disable prior preservation training. Dataset Directory - The path to the directory where the images described in Instance Prompt are kept. REQUIRED Classification dataset directory - The path to the directory where the images described in Class Prompt are kept. If a class prompt is specified and this is left blank, images will be generated to /models/dreambooth/MODELNAME/classifiers/ Total number of classification images to use - Leave at 0 to disable prior preservation. For best results you want ~n*10 classification images - so if you have 40 training photos, then set this to 400. This is just a guess. Training steps - How many total training steps to complete. According to this guide , you should train for appx 100 steps per sample image. So, if you have 40 instance/sample images, you would train for 4k steps. This is, of course, a rough approximation, and other values will have an effect on final output fidelity. Batch size - How many training steps to process simultaneously. You probably want to leave this at 1. Class batch size - How many classification images to generate simultaneously. Set this to whatever you can safely process at once using Txt2Image, or just leave it alone. Learning rate - You probably don't want to touch this. Resolution - The resolution to train images at. You probably want to keep this number at 512 or lower unless your GPU is insane. Lowering this (and the resolution of training images) may help with lower-VRAM GPUs. Save a checkpoint every N steps - How frequently to save a checkpoint from the trained data. I should probably change the default of this to 1000. Generate a preview image every N steps - How frequently will an image be generated as an example of training progress. Preview image prompt - The prompt to use to generate preview image. Leave blank to use the instance prompt. Preview image negative prompt - Like above, but negative. Leave blank to do nothing. :P Number of samples to generate - Self explainatory? Sample guidance scale - Like CFG Scale in Txt2Image/Img2Img, used for generating preview. Sample steps - Same as sample guidance scale, but the number of steps to run to generate preview.","title":"Training (Basic Settings)"},{"location":"dreambooth-rehberi/#advanced-settings","text":"Use CPU Only - As indicated, this is more of a last resort if you can't get it to train with any other settings. Also, as indicated, it will be abysmally slow. Also, you cannot use 8Bit-Adam with CPU Training, or you'll have a bad time. Don't Cache Latents - Why is this not just called \"cache\" latents? Because that's what the original script uses, and I'm trying to maintain the ability to update this as easily as possible. Anyway...when this box is checked latents will not be cached. When latents are not cached, you will save a bit of VRAM, but train slightly slower. Train Text Encoder - Not required, but recommended. Enabling this will probably cost a bit more VRAM, but also purportedly increase output image fidelity. Use 8Bit Adam - Enable this to save VRAM. Should now work on both windows and Linux without needing WSL. Center Crop - Crop images if they aren't the right dimensions? I don't use this, and I recommend you just crop your images \"right\". Gradient Checkpointing - Enable this to save VRAM at the cost of a bit of speed. Scale Learning Rate - I don't use this, not sure what impact it has on performance or output quality. Mixed Precision - Set to 'fp16' to save VRAM at the cost of speed. Everything after 'Mixed Precision' - Adjust at your own risk. Performance/quality benefits from changing these remain to be tested. The next two were added after I wrote the above bit, so just ignore me being a big liar. Pad Tokens - Pads the text tokens to a longer length for some reason. Max Token Length - raise the tokenizer's default limit above 75. Requires Pad Tokens for > 75. Apply Horizontal Flip - \"Apply horizontal flip augmentation\". Flips images horizontally at random, which can potentially offer better editability? Use EMA for finetuning - Use exponential moving average weight to reduce overfitting during the last iterations.","title":"Advanced Settings"},{"location":"dreambooth-rehberi/#continuing-training","text":"Once a model has been trained for any number of steps, a config file is saved which contains all of the parameters from the UI. If you wish to continue training a model, you can simply select the model name from the dropdown and then click the blue button next to the model name dropdown to load previous parameters.","title":"Continuing Training"},{"location":"dreambooth-rehberi/#use-dreambooth-to-fine-tune-stable-diffusion-in-google-colab","text":"","title":"Use DreamBooth to Fine-Tune Stable Diffusion in Google Colab"},{"location":"dreambooth-rehberi/#prepare-images","text":"","title":"Prepare Images"},{"location":"dreambooth-rehberi/#choosing-images","text":"When choosing images, it\u2019s recommended to keep the following in mind to get the best results: Upload a variety of images of your subject. If you\u2019re uploading images of a person, try something like 70% close-ups, 20% from the chest up, 10% full body, so Stable Diffusion also gets some idea of the rest of the subject and not only the face. Try to change things up as much as possible in each picture. This means: Varying the body pose Taking pictures on different days, in different lighting conditions, and with different backgrounds Showing a variety of expressions and emotions When generating new images, whatever you capture will be over-represented. For example, if you take multiple pictures with the same green field behind you, it\u2019s likely that the generated images of you will also contain the green field, even if you want a dystopic background. This can apply to anything, like jewelry, clothes, or even people in the background. If you want to avoid seeing that element in your generated image, make sure not to repeat it in every shot. On the other hand, if you want it in the generated images, make sure it\u2019s in your pictures more often. It\u2019s recommended that you provide ~50 images of what you\u2019d like to train Stable Diffusion on to get great results. However, I\u2019ve only used 20-30 so far, and the results are pretty good. If you\u2019re just starting out and want to test it out, I think 20-30 images should be good enough for now, and you can get 50 images after you\u2019ve seen it work.","title":"Choosing Images"},{"location":"dreambooth-rehberi/#resize-crop-to-512-x-512px","text":"Once you\u2019ve chosen your images, you should prepare them. First, we need to resize and crop our images to be 512 x 512px. We can easily do this using the website https://birme.net . To do this, just: Visit the website Upload your images Set your dimensions to 512 x 512px Adjust the cropping area to center your subject Click on Save as Zip to download the archive. You can then unzip it on your computer, and we\u2019ll use them a bit later. Birme.net - Resize Images Resizing Images using Birme.net","title":"Resize &amp; Crop to 512 x 512px"},{"location":"dreambooth-rehberi/#renaming-your-images","text":"We\u2019ll also want to rename our images to contain the subject\u2019s name: Firstly, the subject name should be one unique/random/unknown keyword. This is because Stable Diffusion also has some knowledge of The Sandman from other sources other than the one played by Tom Sturridge and we don\u2019t want it to get confused and make a combination of interpretations of The Sandman. As such, I\u2019ll call it Sandman2022 to make sure it\u2019s unique. Renaming images to subject (1), subject (2) .. subject (30). This is because, using this method, you can train multiple subjects at once. If you want to fine-tune Stable Diffusion with Sandman, your friend Kevin, and your cat, you can give it prepare images for each of them. For the Sandman you\u2019d have Sandman2022 (1), Sandman2022 (2) \u2026 Sandman (30), for Kevin you\u2019d have KevinKevinson2022 (1), KevinKevinson2022 (2) \u2026 KevinKevinson (30), and for your cat you\u2019d have DexterTheCat (1), DexterTheCat (2) \u2026 DexterTheCat(30). Here\u2019s me renaming my images for Sandman2022 in bulk on Windows. Just select them all, right click one of them and click Rename and give it what name you want and click anywhere to finish the renaming. Everything else will be renamed as well.","title":"Renaming Your Images"},{"location":"feature_selection/","text":"Feature_Selection Projects - List of Context: 1. Feature Importance Codes and Full Article YouTube Video 2. Correlation Matrix Codes and Full Article YouTube Video Dataset: Mushroom Dataset - Kaggle Projects: 1. Feature Importance Genellikle bir makine \u00f6\u011frenmesi projesine ba\u015flarken \u00e7al\u0131\u015faca\u011f\u0131n\u0131z veri istedi\u011finiz formatta ve modele uygulanmaya haz\u0131r bir \u015fekilde de\u011fildir. Farkl\u0131 uzant\u0131larda ve yap\u0131larda olabilir. (CSV, JSON, Excel veya DB etc.) Ayr\u0131ca veriseti kendi i\u00e7erisinde eksik, anormal veya gereksiz bilgiler de i\u00e7eriyor olabilir. Ayn\u0131 zamanda modelinizde kullanaca\u011f\u0131n\u0131z veriye \u00f6n haz\u0131rl\u0131klar yapman\u0131z gerekebilir, \u00f6rnek vermek gerekirse \u00f6l\u00e7eklendirme veya normalle\u015ftirme say\u0131labilir. Her \u015feye ra\u011fmen bu i\u015flemleri tamamlad\u0131\u011f\u0131n\u0131zda dahi modelinizin iyi bir performans g\u00f6stermesi i\u00e7in boyutsall\u0131\u011f\u0131n\u0131n azalt\u0131lmas\u0131 ve g\u00fc\u00e7l\u00fc ili\u015fkilere sahip parametrelerin, performans\u0131 k\u00f6t\u00fc etkileyecek di\u011fer parametrelerden ayr\u0131lmas\u0131 gerekir. \u00c7\u00fcnk\u00fc bu \u00f6znitelikler (features) modele bir bilgi getirmiyor olabilirler. Bu y\u00fczden bir veri bilimci veya makine \u00f6\u011frenmesi m\u00fchendisinin en \u00f6nemli yetkinlikleri asl\u0131nda bu verinin \u00f6ni\u015flemlerini ger\u00e7ekten iyi yapmas\u0131ndan ge\u00e7mektedir. Bu seride g\u00fcncel olarak kullan\u0131lan Feature Selection yani \u00f6znitelik se\u00e7imlerinde kullan\u0131lan etkili metodlar\u0131 inceliyor olaca\u011f\u0131z. Teoride daha fazla \u00f6znitelik eklenmesi modelin geli\u015fimi i\u00e7in daha iyidir fakat pratikte bunun tam tersi ge\u00e7erlidir. Bu \u00f6nerme asl\u0131nda hem do\u011fru hem de yanl\u0131\u015ft\u0131r, \u00e7\u00fcnk\u00fc modele getirdi\u011finiz her \u00f6zellik bilgi ta\u015f\u0131yan ve \u00f6nemli bir parametre olmas\u0131 gerekir. Burada optimum de\u011feri yakalamak \u00f6nemli, tabii ki curse of dimensionality yani boyutsall\u0131\u011f\u0131n laneti konusuna da dikkat etmemiz gerekir. Pekala boyut d\u00fc\u015f\u00fcrmenin veya \u00f6znitelik azaltman\u0131n yararlar\u0131 nedir: Daha y\u00fcksek do\u011fruluk oran\u0131 Overfitting probleminin \u00f6n\u00fcne ge\u00e7mek. Model e\u011fitim s\u00fcresinin k\u0131salt\u0131lmas\u0131. Daha etkin bir g\u00f6rselle\u015ftirme Daha a\u00e7\u0131klanabilir bir model. Burada kullanaca\u011f\u0131m\u0131z veri seti \"Mushroom Classification\" yani \"Mantar S\u0131n\u0131fland\u0131rma\" veri seti olacak. Kullanaca\u011f\u0131m\u0131z k\u00fct\u00fcphaneler tahmin edebilece\u011finiz gibi: Pandas Numpy Matplotlib Seaborn Sklearn Imports import pandas as pd from sklearn.preprocessing import LabelEncoder from sklearn.preprocessing import StandardScaler from sklearn.model_selection import train_test_split data = pd . read_csv ( \"mushrooms.csv\" ) data . head () Dataset Prep. Veri setini ve ba\u015flang\u0131\u00e7 parametrelerimizi haz\u0131rlayal\u0131m. Burada verisetimizdeki her bir kolonu one_hot_encoding y\u00f6ntemiyle encode edece\u011fim. https://www.kaggle.com/uciml/mushroom-classification X = data . drop ([ 'class' ], axis = 1 ) y = data [ 'class' ] X_encoded = pd . get_dummies ( X , prefix_sep = \"_\" ) y_encoded = LabelEncoder () . fit_transform ( y ) X_scaled = StandardScaler () . fit_transform ( X_encoded ) X_train , X_test , y_train , y_test = train_test_split ( X_scaled , y_encoded , test_size = 0.30 , random_state = 101 ) Feature Selection Techniques Feature Importance Karar a\u011fa\u00e7lar\u0131 \u00e7e\u015fitli \u00f6zniteliklerin \u00f6nem derecelerini s\u0131ralamak i\u00e7in kullan\u0131labilir. Karar a\u011fa\u00e7lar\u0131ndaki dallanma bildi\u011finiz gibi \u00f6zniteliklerin s\u0131n\u0131fland\u0131r\u0131c\u0131l\u0131\u011f\u0131yla belirlenir. Bu y\u00fczden daha \u00e7ok kullan\u0131lan nodelar daha y\u00fcksek \u00f6neme sahip olabilirler. import time from sklearn.metrics import classification_report , confusion_matrix from sklearn.ensemble import RandomForestClassifier start = time . process_time () model = RandomForestClassifier ( n_estimators = 700 ) . fit ( X_train , y_train ) print ( time . process_time () - start ) preds = model . predict ( X_test ) print ( confusion_matrix ( y_test , preds )) print ( classification_report ( y_test , preds )) 2 saniye gibi bir s\u00fcrede modelin e\u011fitimi tamamland\u0131. 1.78125 [[ 1274 0 ] [ 0 1164 ]] precision recall f1 - score support 0 1.00 1.00 1.00 1274 1 1.00 1.00 1.00 1164 accuracy 1.00 2438 macro avg 1.00 1.00 1.00 2438 weighted avg 1.00 1.00 1.00 2438 Tam bir ba\u015far\u0131 oran\u0131na sahibiz fakat burada bakaca\u011f\u0131m\u0131z konu asl\u0131nda hangi niteliklerin ne kadar \u00f6nemli oldu\u011fu. Bu y\u00fczden feature importance metoduyla e\u011fitilmi\u015f modelin en \u00f6nemli oldu\u011fu 10 parametreyi g\u00f6rselle\u015ftiriyorum. import matplotlib.pyplot as plt from matplotlib.pyplot import figure feature_imp = pd . Series ( model . feature_importances_ , index = X_encoded . columns ) feature_imp . nlargest ( 10 ) . plot ( kind = 'barh' ) \u015eimdi t\u00fcm kolonlar\u0131 kullanmak yerine sadece \u00f6nemli olarak g\u00f6rd\u00fc\u011f\u00fcm 4 parametreyle e\u011fitece\u011fim. best_feat = feature_imp . nlargest ( 4 ) . index . to_list () X_reduced = X_encoded [ feature_imp . nlargest ( 4 ) . index ] Xr_scaled = StandardScaler () . fit_transform ( X_reduced ) Xr_train , Xr_test , yr_train , yr_test = train_test_split ( Xr_scaled , y , test_size = 0.30 , random_state = 101 ) start = time . process_time () rmodel = RandomForestClassifier ( n_estimators = 700 ) . fit ( Xr_train , yr_train ) print ( time . process_time () - start ) rpred = rmodel . predict ( Xr_test ) print ( confusion_matrix ( yr_test , rpred )) print ( classification_report ( yr_test , rpred )) 0.84375 [[ 1248 26 ] [ 53 1111 ]] precision recall f1 - score support e 0.96 0.98 0.97 1274 p 0.98 0.95 0.97 1164 accuracy 0.97 2438 macro avg 0.97 0.97 0.97 2438 weighted avg 0.97 0.97 0.97 2438 \u00c7ok a\u00e7\u0131k bir \u015fekilde g\u00f6rebiliriz ki, e\u011fitim s\u00fcresi yar\u0131 yar\u0131ya inerken accuracy'den \u00e7ok az kaybettik. Asl\u0131na bakarsan\u0131z bu \u00e7ok k\u00fc\u00e7\u00fck bir veriseti kazanc\u0131m\u0131z 1 saniye kadar fakat bunu milyonlarca sat\u0131ra sahip bir verisetiyle saatlerce e\u011fitti\u011finiz bir model oldu\u011funu d\u00fc\u015f\u00fcn\u00fcrseniz kesinlikle girece\u011finiz bir tradeoff olacakt\u0131r. Bir sonraki derste Recursive Feature Elimination (RFE) tekni\u011fini g\u00f6rece\u011fiz. \u0130yi \u00e7al\u0131\u015fmalar dilerim. 2. Correlation Matrix Feature Selection \u00e7al\u0131\u015fmalar\u0131na Correlation Matrix ile devam ediyoruz. Veriye bak\u0131\u015f a\u00e7\u0131m\u0131z ve uygulad\u0131\u011f\u0131m\u0131z her tekni\u011fin bir istatistiksel altyap\u0131s\u0131 olmas\u0131 gerekir. Yapaca\u011f\u0131m\u0131z i\u015flemlerin her birini model performans\u0131n\u0131 art\u0131rmaya y\u00f6nelik ve belirli bir sistematik ile yapmak ba\u015far\u0131m\u0131 en \u00e7ok etkileyen unsurlardand\u0131r. Genel olarak featurelar\u0131m\u0131z\u0131n, target ile ili\u015fkisini \u00f6l\u00e7mek i\u00e7in en pop\u00fcler tekniklerden olan korelasyon matrisi bize basit\u00e7e kolonlar\u0131n birbiri ile olan ve hedef ile olan ili\u015fkisini g\u00f6sterir. Genel bir yakla\u015f\u0131m olarak \"-0.7\"den k\u00fc\u00e7\u00fck ve \"+0.7\"den b\u00fcy\u00fck korelasyon de\u011ferleri g\u00fc\u00e7l\u00fc korelasyonu temsil etmektedir. Buradaki amac\u0131m\u0131z \u00e7\u0131k\u0131\u015f ile ili\u015fkisi olmayan ve bilgi ta\u015f\u0131ma potansiyeli g\u00f6rece di\u011fer kolonlara az olan featurelar\u0131 elemek olmal\u0131d\u0131r. Bu sayede ilk derste verdi\u011fimiz daha sade ve etkili model, h\u0131zl\u0131 e\u011fitim gibi ba\u015far\u0131m\u0131 pozitif y\u00f6nde etkileyecek unsurlara sahip olabilir. \u015eimdi python'da korelasyon matrisi nas\u0131l olu\u015fturulabilir buna bakal\u0131m. Geli\u015ftirici Notu: T\u00fcm kolonlar\u0131 ordinal olmayan kategorik verilerde korelasyon analizi mant\u0131kl\u0131 bir yakla\u015f\u0131m olup olmad\u0131\u011f\u0131 tart\u0131\u015fmaya a\u00e7\u0131k bir konudur. Burada bahsi ge\u00e7en veri seti veya ama\u00e7tan ziyade, korelasyon matrisinin tekniklerini ve anafikrini yakalama i\u00e7in uygun say\u0131labilir diyebiliriz. !! Genellikle !! regresyon i\u015flemlerinizde ve say\u0131sal bir de\u011fer i\u00e7eren kolonlarda kullan\u0131lmas\u0131 \u015fiddetle \u00f6nerilir. Imports import pandas as pd from sklearn.preprocessing import LabelEncoder from sklearn.preprocessing import StandardScaler from sklearn.model_selection import train_test_split Veri setini haz\u0131rl\u0131klar\u0131 yapmak ad\u0131na i\u00e7eri aktaral\u0131m. data = pd . read_csv ( \"../mushrooms.csv\" ) data . shape \u0130lk yapaca\u011f\u0131m\u0131z i\u015flem veri setimiz harflerden olu\u015ftu\u011fu i\u00e7in bunu say\u0131sal bir forma \u00e7evirmek olmal\u0131, buradaki yakla\u015f\u0131m\u0131m\u0131z featurelar\u0131 one-hot encoding yapt\u0131ktan sonra standardize etmek. Y kolonumuzu label encoding yaparak korelasyon haritas\u0131n\u0131 olu\u015fturmak i\u00e7in featurlar\u0131m\u0131z\u0131n oldu\u011fu dataframe'in sonuna ekleyece\u011fiz. X = data . drop ([ 'class' ], axis = 1 ) y = data [ 'class' ] X_encoded = pd . get_dummies ( X , prefix_sep = \"_\" ) y_encoded = LabelEncoder () . fit_transform ( y ) X_encoded [ \"Class\" ] = y_encoded X_encoded . corr () Dataframe \u00fczerinden bu verilerin okunmas\u0131 olduk\u00e7a zor, seaborn k\u00fct\u00fcphanesindeki heatmap grafi\u011fi bizim i\u00e7in bu da\u011f\u0131l\u0131m\u0131 renkler ve anla\u015f\u0131lmas\u0131 kolay bir g\u00f6rselle a\u00e7\u0131klayacak. Verisetimizin e\u011fer tamam\u0131n\u0131z al\u0131rsak \u015fu anki durumda 118 kolon var, bunun \u00e7izdirilmesi mant\u0131kl de\u011fil, sadece son 7 kolonu alarak \u015fu anl\u0131k g\u00f6zlemleyelim. Birazdan \u00f6\u011frenece\u011fimiz teknikler ile en \u00f6nemli 10 parametreyi g\u00f6rselle\u015ftiriyor olaca\u011f\u0131z. sns . heatmap ( X_encoded . iloc [:, - 7 :] . corr (), annot = True ) Belirtti\u011fimiz gibi eksi ve art\u0131 de\u011ferler g\u00fc\u00e7l\u00fc korelasyonu ifade ediyor, burada say\u0131n\u0131n pozitif ve negatif olmas\u0131 ili\u015fkinin ters veya do\u011fru orant\u0131l\u0131 olarak de\u011fi\u015fmesi ile alakal\u0131, her ikisi de bizim i\u00e7in iyi featurelar olabilir bu y\u00fczden dataframe'in mutlak de\u011ferini alarak en y\u00fcksek de\u011ferli olanlar\u0131 getirece\u011fiz. X_encoded . corr () . abs ()[ \"Class\" ] # .nlarget ile s\u0131ral\u0131 bir \u015fekilde en y\u00fcksek 10 de\u011feri alabiliriz. X_encoded . corr () . abs ()[ \"Class\" ] . nlargest ( 10 ) Bu zamana kadar yazd\u0131\u011f\u0131m\u0131z k\u0131sm\u0131n sonunda index metodunu ekleyerek sadece kolon isimlerini istiyorum ve bunu ana datasetimizden ba\u015fka bir de\u011fi\u015fkene aktar\u0131yorum. Birazdan sadece bu k\u0131sm\u0131 kullan\u0131yor olaca\u011f\u0131z, bu sayede daha okunakl\u0131 ve en y\u00fcksek 10 korelasyon de\u011ferine sahip kolon ile birlikte \u00e7al\u0131\u015f\u0131yor olaca\u011f\u0131z. X_reduced_col_names = X_encoded . corr () . abs ()[ \"Class\" ] . nlargest ( 10 ) . index X_encoded [ X_reduced_col_names ] . corr () Art\u0131k g\u00f6rselle\u015ftirme k\u0131sm\u0131na ge\u00e7ebiliriz. \u00c7izdirdi\u011fimiz g\u00f6rselin b\u00fcy\u00fckl\u00fc\u011f\u00fc ve \u00e7\u00f6z\u00fcn\u00fcrl\u00fc\u011f\u00fcn\u00fc de\u011fi\u015ftirmek ad\u0131na matplotlib k\u00fct\u00fcphanesini i\u00e7eri aktar\u0131yorum. figsize ile boyut, dpi ile \u00e7\u00f6z\u00fcn\u00fcr\u00fcl\u00fck ayarlanabilmektedir. heatmap i\u00e7indeki \"annot\" ile karelerin i\u00e7erisine de\u011ferlerini yazd\u0131rabiliyorum. import matplotlib.pyplot as plt plt . figure ( figsize = ( 10 , 10 ), dpi = 400 ) sns . heatmap ( X_encoded [ X_reduced_col_names ] . corr () . abs (), annot = True )","title":"Feature Selection"},{"location":"feature_selection/#feature_selection","text":"","title":"Feature_Selection"},{"location":"feature_selection/#projects-list-of-context","text":"","title":"Projects - List of Context:"},{"location":"feature_selection/#1-feature-importance","text":"Codes and Full Article YouTube Video","title":"1. Feature Importance"},{"location":"feature_selection/#2-correlation-matrix","text":"Codes and Full Article YouTube Video","title":"2. Correlation Matrix"},{"location":"feature_selection/#dataset","text":"Mushroom Dataset - Kaggle","title":"Dataset:"},{"location":"feature_selection/#projects","text":"","title":"Projects:"},{"location":"feature_selection/#1-feature-importance_1","text":"Genellikle bir makine \u00f6\u011frenmesi projesine ba\u015flarken \u00e7al\u0131\u015faca\u011f\u0131n\u0131z veri istedi\u011finiz formatta ve modele uygulanmaya haz\u0131r bir \u015fekilde de\u011fildir. Farkl\u0131 uzant\u0131larda ve yap\u0131larda olabilir. (CSV, JSON, Excel veya DB etc.) Ayr\u0131ca veriseti kendi i\u00e7erisinde eksik, anormal veya gereksiz bilgiler de i\u00e7eriyor olabilir. Ayn\u0131 zamanda modelinizde kullanaca\u011f\u0131n\u0131z veriye \u00f6n haz\u0131rl\u0131klar yapman\u0131z gerekebilir, \u00f6rnek vermek gerekirse \u00f6l\u00e7eklendirme veya normalle\u015ftirme say\u0131labilir. Her \u015feye ra\u011fmen bu i\u015flemleri tamamlad\u0131\u011f\u0131n\u0131zda dahi modelinizin iyi bir performans g\u00f6stermesi i\u00e7in boyutsall\u0131\u011f\u0131n\u0131n azalt\u0131lmas\u0131 ve g\u00fc\u00e7l\u00fc ili\u015fkilere sahip parametrelerin, performans\u0131 k\u00f6t\u00fc etkileyecek di\u011fer parametrelerden ayr\u0131lmas\u0131 gerekir. \u00c7\u00fcnk\u00fc bu \u00f6znitelikler (features) modele bir bilgi getirmiyor olabilirler. Bu y\u00fczden bir veri bilimci veya makine \u00f6\u011frenmesi m\u00fchendisinin en \u00f6nemli yetkinlikleri asl\u0131nda bu verinin \u00f6ni\u015flemlerini ger\u00e7ekten iyi yapmas\u0131ndan ge\u00e7mektedir. Bu seride g\u00fcncel olarak kullan\u0131lan Feature Selection yani \u00f6znitelik se\u00e7imlerinde kullan\u0131lan etkili metodlar\u0131 inceliyor olaca\u011f\u0131z. Teoride daha fazla \u00f6znitelik eklenmesi modelin geli\u015fimi i\u00e7in daha iyidir fakat pratikte bunun tam tersi ge\u00e7erlidir. Bu \u00f6nerme asl\u0131nda hem do\u011fru hem de yanl\u0131\u015ft\u0131r, \u00e7\u00fcnk\u00fc modele getirdi\u011finiz her \u00f6zellik bilgi ta\u015f\u0131yan ve \u00f6nemli bir parametre olmas\u0131 gerekir. Burada optimum de\u011feri yakalamak \u00f6nemli, tabii ki curse of dimensionality yani boyutsall\u0131\u011f\u0131n laneti konusuna da dikkat etmemiz gerekir. Pekala boyut d\u00fc\u015f\u00fcrmenin veya \u00f6znitelik azaltman\u0131n yararlar\u0131 nedir: Daha y\u00fcksek do\u011fruluk oran\u0131 Overfitting probleminin \u00f6n\u00fcne ge\u00e7mek. Model e\u011fitim s\u00fcresinin k\u0131salt\u0131lmas\u0131. Daha etkin bir g\u00f6rselle\u015ftirme Daha a\u00e7\u0131klanabilir bir model. Burada kullanaca\u011f\u0131m\u0131z veri seti \"Mushroom Classification\" yani \"Mantar S\u0131n\u0131fland\u0131rma\" veri seti olacak. Kullanaca\u011f\u0131m\u0131z k\u00fct\u00fcphaneler tahmin edebilece\u011finiz gibi: Pandas Numpy Matplotlib Seaborn Sklearn","title":"1. Feature Importance"},{"location":"feature_selection/#imports","text":"import pandas as pd from sklearn.preprocessing import LabelEncoder from sklearn.preprocessing import StandardScaler from sklearn.model_selection import train_test_split data = pd . read_csv ( \"mushrooms.csv\" ) data . head ()","title":"Imports"},{"location":"feature_selection/#dataset-prep","text":"Veri setini ve ba\u015flang\u0131\u00e7 parametrelerimizi haz\u0131rlayal\u0131m. Burada verisetimizdeki her bir kolonu one_hot_encoding y\u00f6ntemiyle encode edece\u011fim. https://www.kaggle.com/uciml/mushroom-classification X = data . drop ([ 'class' ], axis = 1 ) y = data [ 'class' ] X_encoded = pd . get_dummies ( X , prefix_sep = \"_\" ) y_encoded = LabelEncoder () . fit_transform ( y ) X_scaled = StandardScaler () . fit_transform ( X_encoded ) X_train , X_test , y_train , y_test = train_test_split ( X_scaled , y_encoded , test_size = 0.30 , random_state = 101 )","title":"Dataset Prep."},{"location":"feature_selection/#feature-selection-techniques","text":"","title":"Feature Selection Techniques"},{"location":"feature_selection/#feature-importance","text":"Karar a\u011fa\u00e7lar\u0131 \u00e7e\u015fitli \u00f6zniteliklerin \u00f6nem derecelerini s\u0131ralamak i\u00e7in kullan\u0131labilir. Karar a\u011fa\u00e7lar\u0131ndaki dallanma bildi\u011finiz gibi \u00f6zniteliklerin s\u0131n\u0131fland\u0131r\u0131c\u0131l\u0131\u011f\u0131yla belirlenir. Bu y\u00fczden daha \u00e7ok kullan\u0131lan nodelar daha y\u00fcksek \u00f6neme sahip olabilirler. import time from sklearn.metrics import classification_report , confusion_matrix from sklearn.ensemble import RandomForestClassifier start = time . process_time () model = RandomForestClassifier ( n_estimators = 700 ) . fit ( X_train , y_train ) print ( time . process_time () - start ) preds = model . predict ( X_test ) print ( confusion_matrix ( y_test , preds )) print ( classification_report ( y_test , preds )) 2 saniye gibi bir s\u00fcrede modelin e\u011fitimi tamamland\u0131. 1.78125 [[ 1274 0 ] [ 0 1164 ]] precision recall f1 - score support 0 1.00 1.00 1.00 1274 1 1.00 1.00 1.00 1164 accuracy 1.00 2438 macro avg 1.00 1.00 1.00 2438 weighted avg 1.00 1.00 1.00 2438 Tam bir ba\u015far\u0131 oran\u0131na sahibiz fakat burada bakaca\u011f\u0131m\u0131z konu asl\u0131nda hangi niteliklerin ne kadar \u00f6nemli oldu\u011fu. Bu y\u00fczden feature importance metoduyla e\u011fitilmi\u015f modelin en \u00f6nemli oldu\u011fu 10 parametreyi g\u00f6rselle\u015ftiriyorum. import matplotlib.pyplot as plt from matplotlib.pyplot import figure feature_imp = pd . Series ( model . feature_importances_ , index = X_encoded . columns ) feature_imp . nlargest ( 10 ) . plot ( kind = 'barh' ) \u015eimdi t\u00fcm kolonlar\u0131 kullanmak yerine sadece \u00f6nemli olarak g\u00f6rd\u00fc\u011f\u00fcm 4 parametreyle e\u011fitece\u011fim. best_feat = feature_imp . nlargest ( 4 ) . index . to_list () X_reduced = X_encoded [ feature_imp . nlargest ( 4 ) . index ] Xr_scaled = StandardScaler () . fit_transform ( X_reduced ) Xr_train , Xr_test , yr_train , yr_test = train_test_split ( Xr_scaled , y , test_size = 0.30 , random_state = 101 ) start = time . process_time () rmodel = RandomForestClassifier ( n_estimators = 700 ) . fit ( Xr_train , yr_train ) print ( time . process_time () - start ) rpred = rmodel . predict ( Xr_test ) print ( confusion_matrix ( yr_test , rpred )) print ( classification_report ( yr_test , rpred )) 0.84375 [[ 1248 26 ] [ 53 1111 ]] precision recall f1 - score support e 0.96 0.98 0.97 1274 p 0.98 0.95 0.97 1164 accuracy 0.97 2438 macro avg 0.97 0.97 0.97 2438 weighted avg 0.97 0.97 0.97 2438 \u00c7ok a\u00e7\u0131k bir \u015fekilde g\u00f6rebiliriz ki, e\u011fitim s\u00fcresi yar\u0131 yar\u0131ya inerken accuracy'den \u00e7ok az kaybettik. Asl\u0131na bakarsan\u0131z bu \u00e7ok k\u00fc\u00e7\u00fck bir veriseti kazanc\u0131m\u0131z 1 saniye kadar fakat bunu milyonlarca sat\u0131ra sahip bir verisetiyle saatlerce e\u011fitti\u011finiz bir model oldu\u011funu d\u00fc\u015f\u00fcn\u00fcrseniz kesinlikle girece\u011finiz bir tradeoff olacakt\u0131r. Bir sonraki derste Recursive Feature Elimination (RFE) tekni\u011fini g\u00f6rece\u011fiz. \u0130yi \u00e7al\u0131\u015fmalar dilerim.","title":"Feature Importance"},{"location":"feature_selection/#2-correlation-matrix_1","text":"Feature Selection \u00e7al\u0131\u015fmalar\u0131na Correlation Matrix ile devam ediyoruz. Veriye bak\u0131\u015f a\u00e7\u0131m\u0131z ve uygulad\u0131\u011f\u0131m\u0131z her tekni\u011fin bir istatistiksel altyap\u0131s\u0131 olmas\u0131 gerekir. Yapaca\u011f\u0131m\u0131z i\u015flemlerin her birini model performans\u0131n\u0131 art\u0131rmaya y\u00f6nelik ve belirli bir sistematik ile yapmak ba\u015far\u0131m\u0131 en \u00e7ok etkileyen unsurlardand\u0131r. Genel olarak featurelar\u0131m\u0131z\u0131n, target ile ili\u015fkisini \u00f6l\u00e7mek i\u00e7in en pop\u00fcler tekniklerden olan korelasyon matrisi bize basit\u00e7e kolonlar\u0131n birbiri ile olan ve hedef ile olan ili\u015fkisini g\u00f6sterir. Genel bir yakla\u015f\u0131m olarak \"-0.7\"den k\u00fc\u00e7\u00fck ve \"+0.7\"den b\u00fcy\u00fck korelasyon de\u011ferleri g\u00fc\u00e7l\u00fc korelasyonu temsil etmektedir. Buradaki amac\u0131m\u0131z \u00e7\u0131k\u0131\u015f ile ili\u015fkisi olmayan ve bilgi ta\u015f\u0131ma potansiyeli g\u00f6rece di\u011fer kolonlara az olan featurelar\u0131 elemek olmal\u0131d\u0131r. Bu sayede ilk derste verdi\u011fimiz daha sade ve etkili model, h\u0131zl\u0131 e\u011fitim gibi ba\u015far\u0131m\u0131 pozitif y\u00f6nde etkileyecek unsurlara sahip olabilir. \u015eimdi python'da korelasyon matrisi nas\u0131l olu\u015fturulabilir buna bakal\u0131m. Geli\u015ftirici Notu: T\u00fcm kolonlar\u0131 ordinal olmayan kategorik verilerde korelasyon analizi mant\u0131kl\u0131 bir yakla\u015f\u0131m olup olmad\u0131\u011f\u0131 tart\u0131\u015fmaya a\u00e7\u0131k bir konudur. Burada bahsi ge\u00e7en veri seti veya ama\u00e7tan ziyade, korelasyon matrisinin tekniklerini ve anafikrini yakalama i\u00e7in uygun say\u0131labilir diyebiliriz. !! Genellikle !! regresyon i\u015flemlerinizde ve say\u0131sal bir de\u011fer i\u00e7eren kolonlarda kullan\u0131lmas\u0131 \u015fiddetle \u00f6nerilir.","title":"2. Correlation Matrix"},{"location":"feature_selection/#imports_1","text":"import pandas as pd from sklearn.preprocessing import LabelEncoder from sklearn.preprocessing import StandardScaler from sklearn.model_selection import train_test_split Veri setini haz\u0131rl\u0131klar\u0131 yapmak ad\u0131na i\u00e7eri aktaral\u0131m. data = pd . read_csv ( \"../mushrooms.csv\" ) data . shape \u0130lk yapaca\u011f\u0131m\u0131z i\u015flem veri setimiz harflerden olu\u015ftu\u011fu i\u00e7in bunu say\u0131sal bir forma \u00e7evirmek olmal\u0131, buradaki yakla\u015f\u0131m\u0131m\u0131z featurelar\u0131 one-hot encoding yapt\u0131ktan sonra standardize etmek. Y kolonumuzu label encoding yaparak korelasyon haritas\u0131n\u0131 olu\u015fturmak i\u00e7in featurlar\u0131m\u0131z\u0131n oldu\u011fu dataframe'in sonuna ekleyece\u011fiz. X = data . drop ([ 'class' ], axis = 1 ) y = data [ 'class' ] X_encoded = pd . get_dummies ( X , prefix_sep = \"_\" ) y_encoded = LabelEncoder () . fit_transform ( y ) X_encoded [ \"Class\" ] = y_encoded X_encoded . corr () Dataframe \u00fczerinden bu verilerin okunmas\u0131 olduk\u00e7a zor, seaborn k\u00fct\u00fcphanesindeki heatmap grafi\u011fi bizim i\u00e7in bu da\u011f\u0131l\u0131m\u0131 renkler ve anla\u015f\u0131lmas\u0131 kolay bir g\u00f6rselle a\u00e7\u0131klayacak. Verisetimizin e\u011fer tamam\u0131n\u0131z al\u0131rsak \u015fu anki durumda 118 kolon var, bunun \u00e7izdirilmesi mant\u0131kl de\u011fil, sadece son 7 kolonu alarak \u015fu anl\u0131k g\u00f6zlemleyelim. Birazdan \u00f6\u011frenece\u011fimiz teknikler ile en \u00f6nemli 10 parametreyi g\u00f6rselle\u015ftiriyor olaca\u011f\u0131z. sns . heatmap ( X_encoded . iloc [:, - 7 :] . corr (), annot = True ) Belirtti\u011fimiz gibi eksi ve art\u0131 de\u011ferler g\u00fc\u00e7l\u00fc korelasyonu ifade ediyor, burada say\u0131n\u0131n pozitif ve negatif olmas\u0131 ili\u015fkinin ters veya do\u011fru orant\u0131l\u0131 olarak de\u011fi\u015fmesi ile alakal\u0131, her ikisi de bizim i\u00e7in iyi featurelar olabilir bu y\u00fczden dataframe'in mutlak de\u011ferini alarak en y\u00fcksek de\u011ferli olanlar\u0131 getirece\u011fiz. X_encoded . corr () . abs ()[ \"Class\" ] # .nlarget ile s\u0131ral\u0131 bir \u015fekilde en y\u00fcksek 10 de\u011feri alabiliriz. X_encoded . corr () . abs ()[ \"Class\" ] . nlargest ( 10 ) Bu zamana kadar yazd\u0131\u011f\u0131m\u0131z k\u0131sm\u0131n sonunda index metodunu ekleyerek sadece kolon isimlerini istiyorum ve bunu ana datasetimizden ba\u015fka bir de\u011fi\u015fkene aktar\u0131yorum. Birazdan sadece bu k\u0131sm\u0131 kullan\u0131yor olaca\u011f\u0131z, bu sayede daha okunakl\u0131 ve en y\u00fcksek 10 korelasyon de\u011ferine sahip kolon ile birlikte \u00e7al\u0131\u015f\u0131yor olaca\u011f\u0131z. X_reduced_col_names = X_encoded . corr () . abs ()[ \"Class\" ] . nlargest ( 10 ) . index X_encoded [ X_reduced_col_names ] . corr () Art\u0131k g\u00f6rselle\u015ftirme k\u0131sm\u0131na ge\u00e7ebiliriz. \u00c7izdirdi\u011fimiz g\u00f6rselin b\u00fcy\u00fckl\u00fc\u011f\u00fc ve \u00e7\u00f6z\u00fcn\u00fcrl\u00fc\u011f\u00fcn\u00fc de\u011fi\u015ftirmek ad\u0131na matplotlib k\u00fct\u00fcphanesini i\u00e7eri aktar\u0131yorum. figsize ile boyut, dpi ile \u00e7\u00f6z\u00fcn\u00fcr\u00fcl\u00fck ayarlanabilmektedir. heatmap i\u00e7indeki \"annot\" ile karelerin i\u00e7erisine de\u011ferlerini yazd\u0131rabiliyorum. import matplotlib.pyplot as plt plt . figure ( figsize = ( 10 , 10 ), dpi = 400 ) sns . heatmap ( X_encoded [ X_reduced_col_names ] . corr () . abs (), annot = True )","title":"Imports"},{"location":"helpers/","text":"Helper Codes Remote Connection SSH ssh -J mert@ { servername } .ddns.net:port mert@target SCP From Local scp -o \"ProxyJump mert@servername.ddns.net -p {port}\" test.txt mert@target-pc:/home/mert/ Download File From Remote Server scp -o \"ProxyJump mert@servername.ddns.net -p {port}\" mert@target-pc:/home/mert/ test.txt Various Download File wget --user-agent Mozilla/4.0 'big address' -O dest_file_name Rename Files ls -v | cat -n | while read n f ; do mv -n \" $f \" \" $n .ext\" ; done Extract Files 7za x test.7z String Slicing # From Character for f in raw_daily/*.csv ; do echo $f /dimensions_ \" ${ f #*blocks_ } \" ; done # TO Character for f in raw_daily/*.csv ; do echo $f /dimensions_ \" ${ f %*blocks_ } \" ; done Random File Name for i in *.jpg ; do mv -i \" $i \" ${ RANDOM }${ RANDOM } .jpg ; done Move Files for f in png-exports/* ; do cp $f /*.png all_images ; done Delete Files Recursively find e -maxdepth 10 -type f -name \".*\" -delete Get Dimensions from Folder ls -U | while read n; do identify -format \"%f,%w,%h\\n\" \"$n\"; done > file_size.csv FFMPEG MP3 \u2192 WAV for f in *.mp3 ; do ffmpeg -i \" $f \" -acodec pcm_s16le -ac 1 -ar 16000 \"wav-exports/ ${ f %. } .wav\" ; done for f in *.flac ; do ffmpeg -i \" $f \" \"wav-exports/ ${ f %. } .wav\" ; done WAV \u2192 mp3 for f in *.* ; do ffmpeg -i \" $f \" \"wav-exports/ ${ f %. } .wav\" ; done for f in * ; do ffmpeg -i \" ${ f } \" -vn -ab 128k -ar 44100 -y \" ${ f } .mp3\" ; done PNG Sequence \u2192 MP4 ffmpeg -f image2 -r 30 -i image_%6d.png -vcodec libx264 -crf 18 -pix_fmt yuv420p output.mp4 MP4 \u2192 PNG ffmpeg -i test.mp4 -vf fps = 1 /2 png-exports/video13_%06d.png for f in *.mp4 ; do ffmpeg -i \" $f \" -vf fps = 2 png-exports/ ${ f %.* } _%06d.png ; done MOV to Optimized GIF ffmpeg -i test.mov -vf scale=320:-1 -r 10 output/ffout%3d.png convert -delay 8 -loop 0 output/ffout*.png output/test.gif Image Convert all images in directory mogrify -format png *.* ESRGAN python inference_realesrgan.py -n RealESRGAN_x4plus -i v13 -s 3 --suffix 8k -t 1500 -o v13_out","title":"Helper one-liners"},{"location":"helpers/#helper-codes","text":"","title":"Helper Codes"},{"location":"helpers/#remote-connection","text":"","title":"Remote Connection"},{"location":"helpers/#ssh","text":"ssh -J mert@ { servername } .ddns.net:port mert@target","title":"SSH"},{"location":"helpers/#scp","text":"","title":"SCP"},{"location":"helpers/#from-local","text":"scp -o \"ProxyJump mert@servername.ddns.net -p {port}\" test.txt mert@target-pc:/home/mert/","title":"From Local"},{"location":"helpers/#download-file-from-remote-server","text":"scp -o \"ProxyJump mert@servername.ddns.net -p {port}\" mert@target-pc:/home/mert/ test.txt","title":"Download File From Remote Server"},{"location":"helpers/#various","text":"","title":"Various"},{"location":"helpers/#download-file","text":"wget --user-agent Mozilla/4.0 'big address' -O dest_file_name","title":"Download File"},{"location":"helpers/#rename-files","text":"ls -v | cat -n | while read n f ; do mv -n \" $f \" \" $n .ext\" ; done","title":"Rename Files"},{"location":"helpers/#extract-files","text":"7za x test.7z","title":"Extract Files"},{"location":"helpers/#string-slicing","text":"# From Character for f in raw_daily/*.csv ; do echo $f /dimensions_ \" ${ f #*blocks_ } \" ; done # TO Character for f in raw_daily/*.csv ; do echo $f /dimensions_ \" ${ f %*blocks_ } \" ; done","title":"String Slicing"},{"location":"helpers/#random-file-name","text":"for i in *.jpg ; do mv -i \" $i \" ${ RANDOM }${ RANDOM } .jpg ; done","title":"Random File Name"},{"location":"helpers/#move-files","text":"for f in png-exports/* ; do cp $f /*.png all_images ; done","title":"Move Files"},{"location":"helpers/#delete-files-recursively","text":"find e -maxdepth 10 -type f -name \".*\" -delete","title":"Delete Files Recursively"},{"location":"helpers/#get-dimensions-from-folder","text":"ls -U | while read n; do identify -format \"%f,%w,%h\\n\" \"$n\"; done > file_size.csv","title":"Get Dimensions from Folder"},{"location":"helpers/#ffmpeg","text":"","title":"FFMPEG"},{"location":"helpers/#mp3-wav","text":"for f in *.mp3 ; do ffmpeg -i \" $f \" -acodec pcm_s16le -ac 1 -ar 16000 \"wav-exports/ ${ f %. } .wav\" ; done for f in *.flac ; do ffmpeg -i \" $f \" \"wav-exports/ ${ f %. } .wav\" ; done","title":"MP3 \u2192 WAV"},{"location":"helpers/#wav-mp3","text":"for f in *.* ; do ffmpeg -i \" $f \" \"wav-exports/ ${ f %. } .wav\" ; done for f in * ; do ffmpeg -i \" ${ f } \" -vn -ab 128k -ar 44100 -y \" ${ f } .mp3\" ; done","title":"WAV  \u2192 mp3"},{"location":"helpers/#png-sequence-mp4","text":"ffmpeg -f image2 -r 30 -i image_%6d.png -vcodec libx264 -crf 18 -pix_fmt yuv420p output.mp4","title":"PNG Sequence \u2192 MP4"},{"location":"helpers/#mp4-png","text":"ffmpeg -i test.mp4 -vf fps = 1 /2 png-exports/video13_%06d.png for f in *.mp4 ; do ffmpeg -i \" $f \" -vf fps = 2 png-exports/ ${ f %.* } _%06d.png ; done","title":"MP4 \u2192 PNG"},{"location":"helpers/#mov-to-optimized-gif","text":"ffmpeg -i test.mov -vf scale=320:-1 -r 10 output/ffout%3d.png convert -delay 8 -loop 0 output/ffout*.png output/test.gif","title":"MOV to Optimized GIF"},{"location":"helpers/#image","text":"Convert all images in directory mogrify -format png *.*","title":"Image"},{"location":"helpers/#esrgan","text":"python inference_realesrgan.py -n RealESRGAN_x4plus -i v13 -s 3 --suffix 8k -t 1500 -o v13_out","title":"ESRGAN"},{"location":"instant-ngp-windows/","text":"Instant Neural Graphics Primitives ! Requirements An NVIDIA GPU ; tensor cores increase performance when available. All shown results come from an RTX 3090. Python ver: 3.9.* Visual Studio Community 2019 (Latest the best, ~8GB) Below are the install requirements CUDA v11.6 . You can check ur CUDA version via nvcc --version in any prompt and if it's not CUDA11.6, refer to this to swap/install the correct version. On some machines, pyexr refuses to install via pip . This can be resolved by installing OpenEXR from here . See later. This installation tutorial will be using Anaconda. Download anaconda prompt here . OptiX 7.3 or higher for faster mesh SDF training. You need to either login or join to obtain the installer. Set the system environment variables OptiX_INSTALL_DIR to the installation directory if it is not discovered automatically. Should look like this: Compilation copy these files C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v11.6\\extras\\visual_studio_integration\\MSBuildExtensions to here C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\MSBuild\\Microsoft\\VC\\v160\\BuildCustomizations cd into a directory that you want to download the codes at. Eg. cd F:\\Tutorial\\ngp\\ Begin by cloning this repository and all its submodules using the following command (if you don't have git, download here and add to path): $ git clone --recursive https://github.com/nvlabs/instant-ngp $ cd instant-ngp if your python is not 3.9 (check with command python --version ) then you need to run the following command to get it to ver 3.9.* conda install python=3.9 Then, open Developer Command Prompt , you can find this in your search bar. Then cd to where you cloned your repository so you are in its root folder /instant-ng/ : cmake . -B build cmake --build build --config RelWithDebInfo -j 16 If the any of these build fails, please consult this list of possible fixes before opening an issue. If automatic GPU architecture detection fails, (as can happen if you have multiple GPUs installed), set the TCNN_CUDA_ARCHITECTURES enivonment variable for the GPU you would like to use. The following table lists the values for common GPUs. If your GPU is not listed, consult this exhaustive list . RTX 30X0 A100 RTX 20X0 TITAN V / V100 GTX 10X0 / TITAN Xp GTX 9X0 K80 86 80 75 70 61 52 37 Interactive Training and Rendering on Custom Image Sets Install COLMAP , I used ver 3.7 Add it to your system environment variables at Environment Variables > System Variables Path > Edit environment variable open anaconda prompt, if you don't have you don't have you can get it here cd into isntant-ngp as root conda create -n ngp python = 3 .9 conda activate ngp pip install -r requirements.txt if pyexr cannot be installed via pip install pyexr , download OpenEXR\u20111.3.2\u2011cp39\u2011cp39\u2011win_amd64.whl and move it to your root folder. Then you can run: pip install OpenEXR-1.3.2-cp39-cp39-win_amd64.whl Place your custom image set under data/<image_set_name> Get transform.json from the following command. Insert your path to your images at <image/path> python scripts/colmap2nerf.py --colmap_matcher exhaustive --run_colmap --aabb_scale 16 --images <image/path> transform.json will be generated at the root folder, drag and drop it into your data/<image_set_name> folder. You have to reorganize the folder structure due to how transforms.json is created... For example: File Structure BEFORE generating transform.json \ud83d\udcc2instant-ngp/ # this is root \u251c\u2500\u2500 \ud83d\udcc2data/ \u2502 \u251c\u2500\u2500 \ud83d\udcc2toy_truck/ \u2502 \u2502 \u251c\u2500\u2500 \ud83d\udcdctoy_truck_001.jpg \u2502 \u2502 \u251c\u2500\u2500 \ud83d\udcdctoy_truck_002.jpg \u2502 \u2502 \u2502... \u2502 \u2502... \u2502... File Structure AFTER generating transform.json \ud83d\udcc2instant-ngp/ # this is root \u251c\u2500\u2500 \ud83d\udcc2data/ \u2502 \u251c\u2500\u2500 \ud83d\udcc2toy_truck/ \u2502 \u2502 \u251c\u2500\u2500 \ud83d\udcdctransforms.json/ \u2502 \u2502 \u251c\u2500\u2500 \ud83d\udcc2data/ \u2502 \u2502 \u2502 \u251c\u2500\u2500 \ud83d\udcc2toy_truck/ \u2502 \u2502 \u2502 \u2502 \u251c\u2500\u2500 \ud83d\udcdctoy_truck_001.jpg \u2502 \u2502 \u2502 \u2502 \u251c\u2500\u2500 \ud83d\udcdctoy_truck_002.jpg \u2502 \u2502 \u2502 \u2502 \u2502... \u2502 \u2502 \u2502 \u2502... \u2502 \u2502 \u2502... \u2502 \u2502... \u2502... Note: adjusting the \"aabb_scale\" inside transform.json can reduce load on GPU VRAM. The lower the value the less intensive it'll be. Finally, to run instant-ngp: <path_to_your_ngp> \\i nstant-ngp \\b uild \\t estbed.exe --scene data/<image_set_name> eg. C:\\user\\user\\download\\instant-ngp\\build\\testbed.exe --scene data/toy_truck And it should launch the GUI and everything amazing with it Rendering custom camera path May need to install more dependencies. Install pip install tqdm scipy pillow opencv-python , conda install -c conda-forge ffmpeg , might be needed in the conda virtual environment. Refer to installation of pyexr above in the installation section if you didn't install that too. Train any image set like above. After you have reached a point that you are satisfied with your training, save a Snapshot on the GUI. (one of the tabs & no need to edit the path & the name) Find another GUI called camera path, it'll play hide and seek with you but it is there so find that window. The GUI is so well made, if you know how to use any 3D engine, it's really similar. Add camera path will give you a new angle of the camera. After you have finished adding your camera points, save the camera path. (no need to edit the path & the name) Render the path with the following command: python scripts/render.py --scene <scene_path> --n_seconds <seconds> --fps <fps> --render_name <name> --width <resolution_width> --height <resolution_height> eg. python scripts/render.py --scene data/toy --n_seconds 5 --fps 60 --render_name test --width 1920 --height 1080 Your video will be saved at root. You might have to play around with the fps and n_seconds to speed up or slow down. I couldn't get it accurately because of the lack of information and this is the best I could come up with. To be honest, this is only a short-term solution too, since the author has promised to publish an official one. So stay tuned! And my fork edits end here. Interactive training and rendering This codebase comes with an interactive testbed that includes many features beyond our academic publication: Additional training features, such as extrinsics and intrinsics optimization. Marching cubes for NeRF->Mesh and SDF->Mesh conversion. A spline-based camera path editor to create videos. Debug visualizations of the activations of every neuron input and output. And many more task-specific settings. See also our one minute demonstration video of the tool . NeRF fox One test scene is provided in this repository, using a small number of frames from a casually captured phone video: instant-ngp$ ./build/testbed --scene data/nerf/fox Alternatively, download any NeRF-compatible scene (e.g. from the NeRF authors' drive ). Now you can run: instant-ngp$ ./build/testbed --scene data/nerf_synthetic/lego/transforms_train.json For more information about preparing datasets for use with our NeRF implementation, please see this document . SDF armadillo instant-ngp$ ./build/testbed --scene data/sdf/armadillo.obj Image of Einstein instant-ngp$ ./build/testbed --scene data/image/albert.exr To reproduce the gigapixel results, download, for example, the Tokyo image and convert it to .bin using the scripts/image2bin.py script. This custom format improves compatibility and loading speed when resolution is high. Now you can run: instant-ngp$ ./build/testbed --scene data/image/tokyo.bin Volume Renderer Download the nanovdb volume for the Disney cloud , which is derived from here ( CC BY-SA 3.0 ). instant-ngp$ ./build/testbed --mode volume --scene data/volume/wdas_cloud_quarter.nvdb Python bindings To conduct controlled experiments in an automated fashion, all features from the interactive testbed (and more!) have Python bindings that can be easily instrumented. For an example of how the ./build/testbed application can be implemented and extended from within Python, see ./scripts/run.py , which supports a superset of the command line arguments that ./build/testbed does. Happy hacking! Troubleshooting compile errors Before investigating further, make sure all submodules are up-to-date and try compiling again. instant-ngp$ git submodule sync --recursive instant-ngp$ git submodule update --init --recursive If instant-ngp still fails to compile, update CUDA as well as your compiler to the latest versions you can install on your system. It is crucial that you update both , as newer CUDA versions are not always compatible with earlier compilers and vice versa. If your problem persists, consult the following table of known issues. Problem Resolution CMake error: No CUDA toolset found / CUDA_ARCHITECTURES is empty for target \"cmTC_0c70f\" Windows: the Visual Studio CUDA integration was not installed correctly. Follow these instructions to fix the problem without re-installing CUDA. ( #18 ) Linux: Environment variables for your CUDA installation are probably incorrectly set. You may work around the issue using cmake . -B build -DCMAKE_CUDA_COMPILER=/usr/local/cuda-<your cuda version>/bin/nvcc ( #28 ) CMake error: No known features for CXX compiler \"MSVC\" Reinstall Visual Studio & make sure you run CMake from a developer shell. ( #21 ) Compile error: undefined references to \"cudaGraphExecUpdate\" / identifier \"cublasSetWorkspace\" is undefined Update your CUDA installation (which is likely 11.0) to 11.3 or higher. ( #34 #41 #42 ) Compile error: too few arguments in function call Update submodules with the above two git commands. ( #37 #52 ) Python error: No module named 'pyngp' It is likely that CMake did not detect your Python installation and therefore did not build pyngp . Check CMake logs to verify this. If pyngp was built in a different folder than instant-ngp/build , Python will be unable to detect it and you have to supply the full path to the import statement. ( #43 ) If you cannot find your problem in the table, please feel free to open an issue and ask for help. Thanks Many thanks to Jonathan Tremblay and Andrew Tao for testing early versions of this codebase and to Arman Toorians and Saurabh Jain for the factory robot dataset. We also thank Andrew Webb for noticing that one of the prime numbers in the spatial hash was not actually prime; this has been fixed since. This project makes use of a number of awesome open source libraries, including: tiny-cuda-nn for fast CUDA MLP networks tinyexr for EXR format support tinyobjloader for OBJ format support stb_image for PNG and JPEG support Dear ImGui an excellent immediate mode GUI library Eigen a C++ template library for linear algebra pybind11 for seamless C++ / Python interop and others! See the dependencies folder. Many thanks to the authors of these brilliant projects! License and Citation @article { mueller2022instant , title = {Instant Neural Graphics Primitives with a Multiresolution Hash Encoding} , author = {Thomas M\\\"uller and Alex Evans and Christoph Schied and Alexander Keller} , journal = {arXiv:2201.05989} , year = {2022} , month = jan } Copyright \u00a9 2022, NVIDIA Corporation. All rights reserved. This work is made available under the Nvidia Source Code License-NC. Click here to view a copy of this license.","title":"NeRF Windows Installations"},{"location":"instant-ngp-windows/#instant-neural-graphics-primitives","text":"","title":"Instant Neural Graphics Primitives !"},{"location":"instant-ngp-windows/#requirements","text":"An NVIDIA GPU ; tensor cores increase performance when available. All shown results come from an RTX 3090. Python ver: 3.9.* Visual Studio Community 2019 (Latest the best, ~8GB) Below are the install requirements CUDA v11.6 . You can check ur CUDA version via nvcc --version in any prompt and if it's not CUDA11.6, refer to this to swap/install the correct version. On some machines, pyexr refuses to install via pip . This can be resolved by installing OpenEXR from here . See later. This installation tutorial will be using Anaconda. Download anaconda prompt here . OptiX 7.3 or higher for faster mesh SDF training. You need to either login or join to obtain the installer. Set the system environment variables OptiX_INSTALL_DIR to the installation directory if it is not discovered automatically. Should look like this:","title":"Requirements"},{"location":"instant-ngp-windows/#compilation","text":"copy these files C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v11.6\\extras\\visual_studio_integration\\MSBuildExtensions to here C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\MSBuild\\Microsoft\\VC\\v160\\BuildCustomizations cd into a directory that you want to download the codes at. Eg. cd F:\\Tutorial\\ngp\\ Begin by cloning this repository and all its submodules using the following command (if you don't have git, download here and add to path): $ git clone --recursive https://github.com/nvlabs/instant-ngp $ cd instant-ngp if your python is not 3.9 (check with command python --version ) then you need to run the following command to get it to ver 3.9.* conda install python=3.9 Then, open Developer Command Prompt , you can find this in your search bar. Then cd to where you cloned your repository so you are in its root folder /instant-ng/ : cmake . -B build cmake --build build --config RelWithDebInfo -j 16 If the any of these build fails, please consult this list of possible fixes before opening an issue. If automatic GPU architecture detection fails, (as can happen if you have multiple GPUs installed), set the TCNN_CUDA_ARCHITECTURES enivonment variable for the GPU you would like to use. The following table lists the values for common GPUs. If your GPU is not listed, consult this exhaustive list . RTX 30X0 A100 RTX 20X0 TITAN V / V100 GTX 10X0 / TITAN Xp GTX 9X0 K80 86 80 75 70 61 52 37","title":"Compilation"},{"location":"instant-ngp-windows/#interactive-training-and-rendering-on-custom-image-sets","text":"Install COLMAP , I used ver 3.7 Add it to your system environment variables at Environment Variables > System Variables Path > Edit environment variable open anaconda prompt, if you don't have you don't have you can get it here cd into isntant-ngp as root conda create -n ngp python = 3 .9 conda activate ngp pip install -r requirements.txt if pyexr cannot be installed via pip install pyexr , download OpenEXR\u20111.3.2\u2011cp39\u2011cp39\u2011win_amd64.whl and move it to your root folder. Then you can run: pip install OpenEXR-1.3.2-cp39-cp39-win_amd64.whl Place your custom image set under data/<image_set_name> Get transform.json from the following command. Insert your path to your images at <image/path> python scripts/colmap2nerf.py --colmap_matcher exhaustive --run_colmap --aabb_scale 16 --images <image/path> transform.json will be generated at the root folder, drag and drop it into your data/<image_set_name> folder. You have to reorganize the folder structure due to how transforms.json is created... For example: File Structure BEFORE generating transform.json \ud83d\udcc2instant-ngp/ # this is root \u251c\u2500\u2500 \ud83d\udcc2data/ \u2502 \u251c\u2500\u2500 \ud83d\udcc2toy_truck/ \u2502 \u2502 \u251c\u2500\u2500 \ud83d\udcdctoy_truck_001.jpg \u2502 \u2502 \u251c\u2500\u2500 \ud83d\udcdctoy_truck_002.jpg \u2502 \u2502 \u2502... \u2502 \u2502... \u2502... File Structure AFTER generating transform.json \ud83d\udcc2instant-ngp/ # this is root \u251c\u2500\u2500 \ud83d\udcc2data/ \u2502 \u251c\u2500\u2500 \ud83d\udcc2toy_truck/ \u2502 \u2502 \u251c\u2500\u2500 \ud83d\udcdctransforms.json/ \u2502 \u2502 \u251c\u2500\u2500 \ud83d\udcc2data/ \u2502 \u2502 \u2502 \u251c\u2500\u2500 \ud83d\udcc2toy_truck/ \u2502 \u2502 \u2502 \u2502 \u251c\u2500\u2500 \ud83d\udcdctoy_truck_001.jpg \u2502 \u2502 \u2502 \u2502 \u251c\u2500\u2500 \ud83d\udcdctoy_truck_002.jpg \u2502 \u2502 \u2502 \u2502 \u2502... \u2502 \u2502 \u2502 \u2502... \u2502 \u2502 \u2502... \u2502 \u2502... \u2502... Note: adjusting the \"aabb_scale\" inside transform.json can reduce load on GPU VRAM. The lower the value the less intensive it'll be. Finally, to run instant-ngp: <path_to_your_ngp> \\i nstant-ngp \\b uild \\t estbed.exe --scene data/<image_set_name> eg. C:\\user\\user\\download\\instant-ngp\\build\\testbed.exe --scene data/toy_truck And it should launch the GUI and everything amazing with it","title":"Interactive Training and Rendering on Custom Image Sets"},{"location":"instant-ngp-windows/#rendering-custom-camera-path","text":"May need to install more dependencies. Install pip install tqdm scipy pillow opencv-python , conda install -c conda-forge ffmpeg , might be needed in the conda virtual environment. Refer to installation of pyexr above in the installation section if you didn't install that too. Train any image set like above. After you have reached a point that you are satisfied with your training, save a Snapshot on the GUI. (one of the tabs & no need to edit the path & the name) Find another GUI called camera path, it'll play hide and seek with you but it is there so find that window. The GUI is so well made, if you know how to use any 3D engine, it's really similar. Add camera path will give you a new angle of the camera. After you have finished adding your camera points, save the camera path. (no need to edit the path & the name) Render the path with the following command: python scripts/render.py --scene <scene_path> --n_seconds <seconds> --fps <fps> --render_name <name> --width <resolution_width> --height <resolution_height> eg. python scripts/render.py --scene data/toy --n_seconds 5 --fps 60 --render_name test --width 1920 --height 1080 Your video will be saved at root. You might have to play around with the fps and n_seconds to speed up or slow down. I couldn't get it accurately because of the lack of information and this is the best I could come up with. To be honest, this is only a short-term solution too, since the author has promised to publish an official one. So stay tuned! And my fork edits end here.","title":"Rendering custom camera path"},{"location":"instant-ngp-windows/#interactive-training-and-rendering","text":"This codebase comes with an interactive testbed that includes many features beyond our academic publication: Additional training features, such as extrinsics and intrinsics optimization. Marching cubes for NeRF->Mesh and SDF->Mesh conversion. A spline-based camera path editor to create videos. Debug visualizations of the activations of every neuron input and output. And many more task-specific settings. See also our one minute demonstration video of the tool .","title":"Interactive training and rendering"},{"location":"instant-ngp-windows/#nerf-fox","text":"One test scene is provided in this repository, using a small number of frames from a casually captured phone video: instant-ngp$ ./build/testbed --scene data/nerf/fox Alternatively, download any NeRF-compatible scene (e.g. from the NeRF authors' drive ). Now you can run: instant-ngp$ ./build/testbed --scene data/nerf_synthetic/lego/transforms_train.json For more information about preparing datasets for use with our NeRF implementation, please see this document .","title":"NeRF fox"},{"location":"instant-ngp-windows/#sdf-armadillo","text":"instant-ngp$ ./build/testbed --scene data/sdf/armadillo.obj","title":"SDF armadillo"},{"location":"instant-ngp-windows/#image-of-einstein","text":"instant-ngp$ ./build/testbed --scene data/image/albert.exr To reproduce the gigapixel results, download, for example, the Tokyo image and convert it to .bin using the scripts/image2bin.py script. This custom format improves compatibility and loading speed when resolution is high. Now you can run: instant-ngp$ ./build/testbed --scene data/image/tokyo.bin","title":"Image of Einstein"},{"location":"instant-ngp-windows/#volume-renderer","text":"Download the nanovdb volume for the Disney cloud , which is derived from here ( CC BY-SA 3.0 ). instant-ngp$ ./build/testbed --mode volume --scene data/volume/wdas_cloud_quarter.nvdb","title":"Volume Renderer"},{"location":"instant-ngp-windows/#python-bindings","text":"To conduct controlled experiments in an automated fashion, all features from the interactive testbed (and more!) have Python bindings that can be easily instrumented. For an example of how the ./build/testbed application can be implemented and extended from within Python, see ./scripts/run.py , which supports a superset of the command line arguments that ./build/testbed does. Happy hacking!","title":"Python bindings"},{"location":"instant-ngp-windows/#troubleshooting-compile-errors","text":"Before investigating further, make sure all submodules are up-to-date and try compiling again. instant-ngp$ git submodule sync --recursive instant-ngp$ git submodule update --init --recursive If instant-ngp still fails to compile, update CUDA as well as your compiler to the latest versions you can install on your system. It is crucial that you update both , as newer CUDA versions are not always compatible with earlier compilers and vice versa. If your problem persists, consult the following table of known issues. Problem Resolution CMake error: No CUDA toolset found / CUDA_ARCHITECTURES is empty for target \"cmTC_0c70f\" Windows: the Visual Studio CUDA integration was not installed correctly. Follow these instructions to fix the problem without re-installing CUDA. ( #18 ) Linux: Environment variables for your CUDA installation are probably incorrectly set. You may work around the issue using cmake . -B build -DCMAKE_CUDA_COMPILER=/usr/local/cuda-<your cuda version>/bin/nvcc ( #28 ) CMake error: No known features for CXX compiler \"MSVC\" Reinstall Visual Studio & make sure you run CMake from a developer shell. ( #21 ) Compile error: undefined references to \"cudaGraphExecUpdate\" / identifier \"cublasSetWorkspace\" is undefined Update your CUDA installation (which is likely 11.0) to 11.3 or higher. ( #34 #41 #42 ) Compile error: too few arguments in function call Update submodules with the above two git commands. ( #37 #52 ) Python error: No module named 'pyngp' It is likely that CMake did not detect your Python installation and therefore did not build pyngp . Check CMake logs to verify this. If pyngp was built in a different folder than instant-ngp/build , Python will be unable to detect it and you have to supply the full path to the import statement. ( #43 ) If you cannot find your problem in the table, please feel free to open an issue and ask for help.","title":"Troubleshooting compile errors"},{"location":"instant-ngp-windows/#thanks","text":"Many thanks to Jonathan Tremblay and Andrew Tao for testing early versions of this codebase and to Arman Toorians and Saurabh Jain for the factory robot dataset. We also thank Andrew Webb for noticing that one of the prime numbers in the spatial hash was not actually prime; this has been fixed since. This project makes use of a number of awesome open source libraries, including: tiny-cuda-nn for fast CUDA MLP networks tinyexr for EXR format support tinyobjloader for OBJ format support stb_image for PNG and JPEG support Dear ImGui an excellent immediate mode GUI library Eigen a C++ template library for linear algebra pybind11 for seamless C++ / Python interop and others! See the dependencies folder. Many thanks to the authors of these brilliant projects!","title":"Thanks"},{"location":"instant-ngp-windows/#license-and-citation","text":"@article { mueller2022instant , title = {Instant Neural Graphics Primitives with a Multiresolution Hash Encoding} , author = {Thomas M\\\"uller and Alex Evans and Christoph Schied and Alexander Keller} , journal = {arXiv:2201.05989} , year = {2022} , month = jan } Copyright \u00a9 2022, NVIDIA Corporation. All rights reserved. This work is made available under the Nvidia Source Code License-NC. Click here to view a copy of this license.","title":"License and Citation"},{"location":"nerf-studio-docker/","text":"NerfStudio Installation Docker Install Docker Pull cuda.11.3 image docker pull nvidia/cuda:11.3.0-base-ubuntu20.04 docker run --name nerf_docker --gpus all -p 3000:3000 -it cobanovgithub apt-get update apt-get install wget ns-download-data --dataset=nerfstudio --capture=poster ns-train nerfacto --viewer.websocket-port 3000 nerfstudio-data --data data/nerfstudio/poster --downscale-factor 4 CONDA Download the latest shell script wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh Make the miniconda installation script executable chmod +x Miniconda3-latest-Linux-x86_64.sh Run miniconda installation script ./Miniconda3-latest-Linux-x86_64.sh Create and activate an conda environment To create a conda environment, run conda create -n newenv You can also create the environment from a file like environment.yml, you can use use the conda env create -f command: conda env create -f environment.yml. The environment name will be the directory name. source ~/.bashrc Create environment conda create --name nerfstudio -y python=3.8 conda activate nerfstudio python -m pip install --upgrade pip TinyCudaNN apt-get install build-essential git source ~/.bashrc pip install torch==1.12.1+cu113 torchvision==0.13.1+cu113 -f https://download.pytorch.org/whl/torch_stable.html","title":"NerfStudio Installation"},{"location":"nerf-studio-docker/#nerfstudio-installation","text":"","title":"NerfStudio Installation"},{"location":"nerf-studio-docker/#docker","text":"Install Docker Pull cuda.11.3 image docker pull nvidia/cuda:11.3.0-base-ubuntu20.04 docker run --name nerf_docker --gpus all -p 3000:3000 -it cobanovgithub apt-get update apt-get install wget ns-download-data --dataset=nerfstudio --capture=poster ns-train nerfacto --viewer.websocket-port 3000 nerfstudio-data --data data/nerfstudio/poster --downscale-factor 4","title":"Docker"},{"location":"nerf-studio-docker/#conda","text":"Download the latest shell script wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh Make the miniconda installation script executable chmod +x Miniconda3-latest-Linux-x86_64.sh Run miniconda installation script ./Miniconda3-latest-Linux-x86_64.sh Create and activate an conda environment To create a conda environment, run conda create -n newenv You can also create the environment from a file like environment.yml, you can use use the conda env create -f command: conda env create -f environment.yml. The environment name will be the directory name. source ~/.bashrc","title":"CONDA"},{"location":"nerf-studio-docker/#create-environment","text":"conda create --name nerfstudio -y python=3.8 conda activate nerfstudio python -m pip install --upgrade pip","title":"Create environment"},{"location":"nerf-studio-docker/#tinycudann","text":"apt-get install build-essential git source ~/.bashrc pip install torch==1.12.1+cu113 torchvision==0.13.1+cu113 -f https://download.pytorch.org/whl/torch_stable.html","title":"TinyCudaNN"},{"location":"ogrenme-tekniklerim/","text":"\u25b6\ufe0f blog yaz\u0131s\u0131n\u0131n videosuna linkten ula\u015fabilirsin! Ben genellikle yeni bir \u015fey \u00f6\u011frenirken m\u00fczi\u011fi kapat\u0131yorum, \u00e7\u00fcnk\u00fc bu alg\u0131y\u0131 b\u00f6l\u00fcyor, fakat aksine i\u015f yaparken a\u00e7\u0131yorum \u00e7\u00fcnk\u00fc konsantrasyonu art\u0131r\u0131yor. Her \u015fey kabul etmek ile alakal\u0131 \u00d6\u011frenmenin bir s\u00fcre\u00e7 oldu\u011funu ve geli\u015fimini asl\u0131nda senin fark edemeyece\u011fin kadar yava\u015f oldu\u011funu kabul etmelisin. Burada bence umutsuzlu\u011fa s\u00fcr\u00fcklenilen konu, bir \u015feyi \u00f6\u011frenmeye ilk ba\u015flad\u0131\u011f\u0131ndaki heyecan her \u015feyi yapma hevesi do\u011furuyor, fakat kapabiliten hen\u00fcz haz\u0131r olmad\u0131\u011f\u0131 i\u00e7in kendini k\u00fc\u00e7\u00fck g\u00f6rme sendromuna kap\u0131labiliyorsun. Bunu kabul etmeli ve gerekli par\u00e7alar\u0131n zamanla bu yolda ancak y\u00fcr\u00fcyerek oturaca\u011f\u0131n\u0131 anlamak gerek. E\u011fer bir \u015fey \u00e7ok h\u0131zl\u0131 ba\u015far\u0131l\u0131yorsa muhtemelen bu basit bir \u015feydir ve herkes taraf\u0131ndan yap\u0131labilir. Kompleksite ve Derinlik Bir di\u011fer konu biraz karma\u015f\u0131k, l\u00fctfen bu paragraf\u0131 bir kez daha oku \u00e7\u00fcnk\u00fc sonda s\u00f6ylediklerim ba\u015flang\u0131\u00e7 ile birlikte paralel olarak ger\u00e7ekle\u015fen etmenler i\u00e7eriyor. Son k\u0131sm\u0131 anlad\u0131\u011f\u0131nda ilk k\u0131s\u0131m biraz daha ayd\u0131nlanm\u0131\u015f olacak. Literat\u00fcrde nas\u0131l adland\u0131r\u0131l\u0131yor bilmiyorum fakat ben bunu alg\u0131 ivmesi olarak adland\u0131r\u0131yorum. Bir konuyu \u00e7al\u0131\u015fmak \u00fczere masaya oturdun, telefonun yan\u0131nda duruyor ve odada ba\u015fka biri daha var. Sen \u00e7al\u0131\u015fmaya ba\u015flad\u0131\u011f\u0131nda beynin o i\u015flem i\u00e7in bir alan yaratmaya ba\u015flayacak. Okumaya veya \u00e7al\u0131\u015fmaya devam ettik\u00e7e bu kapasite b\u00fcy\u00fcyecek ve daha kompleks hale gelecek. Bunu bir \u00f6rnek ile anla\u015f\u0131l\u0131r hale getireyim Zor bir matematik veya fizik sorusu \u00e7\u00f6zmeye ba\u015flad\u0131\u011f\u0131n\u0131 d\u00fc\u015f\u00fcn, sonuca ula\u015fmak ad\u0131na problemin arg\u00fcmanlar\u0131nda baz\u0131 d\u00f6n\u00fc\u015f\u00fcmler uyguluyorsun (de\u011fi\u015fken de\u011fi\u015fimi, birim d\u00f6n\u00fc\u015f\u00fcm\u00fc veya geometri sorusu \u00e7\u00f6zerken indirilen dikmeler, \u00e7ekilen te\u011fetler gibi). Beynin problemin \u00e7\u00f6z\u00fcm\u00fc i\u00e7in karma\u015f\u0131kl\u0131\u011f\u0131 ge\u00e7ici bellekte tutmaya ba\u015fl\u0131yor, ilerleyen k\u0131s\u0131mlarda daha kompleks i\u015flemleri yapabilmen i\u00e7in bu ba\u011flamlar\u0131 oda\u011f\u0131na koyuyor. Dikkatin odaklanm\u0131\u015f bir durumda ve \u00e7\u0131k\u0131\u015f yolunu taramaya ba\u015fl\u0131yorsun, e\u011fer bir kesme i\u015flemi olursa (interrupt) bu zamana kadar \u00f6nbellekte tuttu\u011fun kompleksite da\u011f\u0131lm\u0131\u015f olacak. Yeniden problemin ba\u015f\u0131na d\u00f6nd\u00fc\u011f\u00fcnde o yollar\u0131 tekrar etmek zorunda kalacaks\u0131n. \u015eimdi \u00e7ok pop\u00fcler ve etkisi defalarca onaylanm\u0131\u015f olmas\u0131na ra\u011fmen iki arg\u00fcmana kar\u015f\u0131t bir arg\u00fcman sunaca\u011f\u0131m ve muhtemelen bu fikre kat\u0131lmak istemeyen bir\u00e7ok ki\u015fi olacak, ama yine de bu fikri de\u011ferlendirmeni istiyorum. Kendi ispat\u0131m\u0131 da arg\u00fcman\u0131m\u0131n sonunda payla\u015faca\u011f\u0131m. Birincisi pomodoro tekni\u011fi, ikinicisi ise problemi k\u00fc\u00e7\u00fck par\u00e7alara b\u00f6lmek. Bazen? pomodoro iyi de\u011fildir Pomodoro tekni\u011fini bilmeyenler i\u00e7in k\u0131saca a\u00e7\u0131klamak gerekirse 25 dakikal\u0131k periyotlarla \u00e7al\u0131\u015f\u0131yorsun ve sonras\u0131nda k\u0131sa bir mola veriyorsun. Problemi k\u00fc\u00e7\u00fck par\u00e7alara b\u00f6lmeyi a\u00e7\u0131klama gere\u011fi duymuyorum gayet a\u00e7\u0131k. Bu iki tekni\u011fin problemi anla\u015f\u0131lmas\u0131 g\u00f6rece zor ve detay i\u00e7eren ileri \u00f6\u011frenme konular\u0131nda negatif performans g\u00f6stermeleri. Yaz\u0131n\u0131n \u00f6nceki k\u0131sm\u0131nda yeni bir \u015fey \u00f6\u011frenirken m\u00fczi\u011fi kapatt\u0131\u011f\u0131m\u0131 fakat hali haz\u0131rda bildi\u011fim konularda i\u015f yaparken a\u00e7t\u0131\u011f\u0131m\u0131 s\u00f6ylemi\u015ftim, bununla ba\u011flant\u0131l\u0131 asl\u0131nda. Zor konular\u0131 \u00f6\u011frenirken beynini o konu ba\u011flam\u0131n\u0131n etraf\u0131nda s\u00fcrekli dola\u015ft\u0131rman gerekiyor. Konu derinle\u015ftik\u00e7e bu karma\u015f\u0131k yap\u0131n\u0131n her noktas\u0131n\u0131 gezmelisin ve bu vakit alan bir s\u00fcre\u00e7tir. Bunu \u015f\u00f6yle \u00f6rneklendirelim: Uzaya bir roket f\u0131rlatt\u0131\u011f\u0131n\u0131 d\u00fc\u015f\u00fcn ve a\u015fman gereken bir atmosfer var. Bir e\u015fi\u011fi ge\u00e7ene kadar s\u00fcrekli olarak enerji vermeye devam etmelisin. Yolun bir k\u0131sm\u0131nda enerjiyi kesmek ivmeni \u00e7ok fazla d\u00fc\u015f\u00fcrecek ve o ivmeyi tekrar alabilmek i\u00e7in daha fazla enerji kullanman gerekecek. Hatta atmosferden ayr\u0131lana kadar e\u011fer bu ivmeyi d\u00fc\u015f\u00fcr\u00fcrsen, roketi indirip tekrardan yery\u00fcz\u00fcnden ate\u015flemen gerekir. Bu y\u00fczden i\u015f yaparken pomodoro g\u00fczel bir tazeleyici olmas\u0131na ra\u011fmen \u00f6\u011frenirken h\u0131z kesmenin negatif bir etkisi oldu\u011funu d\u00fc\u015f\u00fcn\u00fcyorum. \u00d6rnekler san\u0131r\u0131m sonsuz say\u0131da art\u0131r\u0131labilir: \u00e7\u0131\u011f etkisi, lambal\u0131 bir amfiyi kullanmadan \u00f6nce \u0131s\u0131tmak, yol verme direncini a\u015fm\u0131\u015f bir elektrik motoru, r\u00fczgar trib\u00fcn\u00fcn\u00fcn ilk hareketi\u2026 Bunlar\u0131 durdurmak istemezsin. Problemi k\u00fc\u00e7\u00fck par\u00e7alara ay\u0131r (veya ay\u0131rma) Problemi k\u00fc\u00e7\u00fck par\u00e7alara ay\u0131rmak, m\u00fckemmel bir teknik, ger\u00e7ekten sorun \u00e7\u00f6zme konusunda daha iyi bir y\u00f6ntem d\u00fc\u015f\u00fcnemiyorum. (Zaten bu iki tekni\u011fe k\u00f6r\u00fc k\u00f6r\u00fcne kar\u015f\u0131 de\u011filim sadece her yetene\u011fin veriminin y\u00fcksek oldu\u011fu anlar vard\u0131r, do\u011fru anda do\u011fru tekni\u011fi kullanmak gerek.) Baz\u0131 problemler daha k\u00fc\u00e7\u00fck par\u00e7alara ayr\u0131lmazlar, bunlar\u0131 b\u00fct\u00fcn karma\u015f\u0131kl\u0131\u011f\u0131yla b\u00fcy\u00fck bir lokmada yutulmas\u0131 gereken durumlar olacakt\u0131r. B\u00f6yle zamanlarda problemin karma\u015f\u0131kl\u0131k seviyesi y\u00fcksek oldu\u011fu i\u00e7in sonraya b\u0131rakma veya anlamadan ge\u00e7me gibi eylemlerde bulunabilirsin. Bunu yapma. V\u00fccudundaki kaslar\u0131 d\u00fc\u015f\u00fcn, daha y\u00fcksek tansiyon alt\u0131nda b\u0131rakt\u0131\u011f\u0131nda kaslar\u0131n ertesi g\u00fcn i\u00e7in o kuvveti kar\u015f\u0131layabilecek \u015fekilde evrilecektir. Zor konular\u0131 anlamak i\u00e7in harcayaca\u011f\u0131n efor, soyut d\u00fc\u015f\u00fcnce bilincinin s\u0131n\u0131rlar\u0131n\u0131 geni\u015fletecektir. Hepimiz felsefe okulundaki \u201cGeometri bilmeyen giremez.\u201d s\u00f6z\u00fcn\u00fc biliyoruz. Matematik dedi\u011fimiz yap\u0131 soyut ve somut kavram\u0131n\u0131n aras\u0131na \u00e7ekilmi\u015f bir \u00e7izgidir asl\u0131nda. Ka\u011f\u0131t \u00fczerinde 300 boyutlu bir tens\u00f6r i\u015flemi yap\u0131labilir ve sonu\u00e7lar tutarl\u0131d\u0131r (ger\u00e7ek d\u00fcnyada b\u00f6yle bir formu somut hale getirmek imkans\u0131zd\u0131r) kompleks d\u00fczlemde o harflerle (i ve j) yap\u0131lan i\u015flemlerin etkisi inan\u0131l\u0131r gibi de\u011fil fakat ger\u00e7ek d\u00fcnyada g\u00f6zlemlenir. Bunun i\u00e7in elektrik, dalga teorisi gibi konular\u0131 inceleyebilirsin. Fakat en basit kondansat\u00f6r\u00fcn bile bu y\u00f6ntemle \u00e7al\u0131\u015f\u0131yor olmas\u0131 buna bir \u00f6rnek. Bu y\u00fczden baz\u0131 konular\u0131n par\u00e7alanamayaca\u011f\u0131, soyutluk kavram\u0131 ve beyin s\u0131n\u0131rlar\u0131n\u0131 geni\u015fletmek i\u00e7in beynini kompleksiteye zorlaman, alg\u0131n\u0131 olduk\u00e7a a\u00e7acakt\u0131r. Bundan l\u00fctfen ka\u00e7ma. Biraz mola Evet zor k\u0131sm\u0131 hallettik. Belki de en \u00f6nemli k\u0131s\u0131m buydu. \u00c7\u00fcnk\u00fc bu y\u00f6ntemi i\u00e7selle\u015ftirdi\u011finde problemlere bak\u0131\u015f a\u00e7\u0131n de\u011fi\u015fecek, vizyonun farkl\u0131la\u015facak, belki karakterin hatta g\u00fcnl\u00fck konu\u015fmandaki kelimelerin bile de\u011fi\u015fecek. Yer Tutucular ve Fikir Reg\u00fclarizasyonu Gelelim \u00e7al\u0131\u015f\u0131rken yapmay\u0131 sevdi\u011fim di\u011fer bir y\u00f6nteme. Yeni bir bilgi geldi\u011finde tamam\u0131n\u0131 kavramam\u0131\u015f olsam bile daha \u00f6nceden bildi\u011fim \u015feylerle bir ba\u011flam yaratmaya ve hatal\u0131 da olsa bir yere oturtmaya \u00e7al\u0131\u015f\u0131yorum, bu yeni edindi\u011fim bilgi hakk\u0131ndaki \u00f6ng\u00f6r\u00fcm oluyor ve her zaman hatal\u0131 bir \u00f6ng\u00f6r\u00fcm oldu\u011funu hemen kabul ediyorum. Beynimde onun i\u00e7in bir placeholder -yer tutucu- ayarl\u0131yorum. Sonras\u0131nda \u00f6\u011frenme i\u015flemim devam ederken soru sormaya ba\u015fl\u0131yorum, ben \u015f\u00f6yle d\u00fc\u015f\u00fcnm\u00fc\u015ft\u00fcm halbuki b\u00f6yleymi\u015f, \u015fimdi daha iyi anl\u0131yorum. Sonras\u0131nda yeni bir fikir daha olu\u015fuyor, ve yeni bir bilgi daha geldi\u011finde bunu yeniden test ediyorum, \u201chah evet tam da d\u00fc\u015f\u00fcnd\u00fc\u011f\u00fcm gibi, akl\u0131n yolu bir, mant\u0131kl\u0131 olan da buydu zaten\u201d ve bu his bana keyif veriyor. Zihnimi bu konu hakk\u0131nda canl\u0131 tutuyorum fakat en \u00f6nemlisi \u015funu anl\u0131yorum: Pozitif bilimlerde her \u015fey birbirine ba\u011fl\u0131d\u0131r, \u00e7\u00fcnk\u00fc evren temel yap\u0131ta\u015f\u0131nda belirli fizik \u00e7at\u0131s\u0131 alt\u0131nda var olan bir mimari. E\u011fer fizik tutarl\u0131 de\u011filse var olmak da m\u00fcmk\u00fcn olmayacakt\u0131 de\u011fil mi? Bu y\u00fczden ba\u011flant\u0131lar\u0131 yakalamaya \u00e7al\u0131\u015fmaktan asla vazge\u00e7me. Bu arada bu y\u00f6nteme diyalektik materyalizm deniyor. Fikirler b\u00f6yle do\u011far! Yapmay\u0131 sevmedi\u011fim bir i\u015fi nas\u0131l \u00f6\u011freniyorum? Harika, mesela bu soruyu cevaplamak istemiyor olmama ra\u011fmen, \u015fu anda yapmay\u0131 sevmedi\u011fim bir i\u015fi yapaca\u011f\u0131m. Neden yapmak istemiyorum? \u00c7\u00fcnk\u00fc olduk\u00e7a s\u0131k\u0131c\u0131, ve ak\u0131c\u0131 bir \u015fekilde ilerleyemiyorum. \u0130nsan istiyor ki \u00f6\u011frenmeden al\u0131nan haz ve bir i\u015fi halletmenin verdi\u011fi haz s\u00fcrekli sabit olsun. Yapmak zorunda oldu\u011fun ve belki de seni bir ad\u0131m \u00f6ne \u00e7\u0131kartacak \u015fey maalesef her zaman yapmay\u0131 sevmedi\u011fin bir i\u015f oluyor. Benim b\u00f6yle zamanlarda yapt\u0131\u011f\u0131m \u015feyler olduk\u00e7a k\u0131s\u0131tl\u0131, genellikle yan\u0131ma bu s\u0131k\u0131nt\u0131y\u0131 payla\u015facak bir ikinci ki\u015fi bulmak. Problemime ortak olan biri varsa hadi gel \u015funu yapal\u0131m diyorum. Bunu yorgunken spora gitmek gibi d\u00fc\u015f\u00fcnebilirsin. Ba\u015fka birisi konudan ba\u011f\u0131ms\u0131z bir motivasyon \u00f6zelli\u011fi g\u00f6sterir. \u00c7\u00fcnk\u00fc o anda birini allocate (tam anlam\u0131 veren T\u00fcrk\u00e7e kar\u015f\u0131l\u0131k bulamad\u0131m, o i\u015f i\u00e7in o ki\u015fiyi me\u015fgul etmek, ay\u0131rmak) etmi\u015fsindir ve art\u0131k bu i\u015fi o anda yapma zorunlulu\u011fun artm\u0131\u015ft\u0131r iyice ka\u00e7amazs\u0131n. Tam bir \u00e7\u00f6z\u00fcm de\u011fil biliyorum fakat yan\u0131na o i\u015f i\u00e7in herhangi birini al b\u00f6yle zamanlarda, i\u015fe yarad\u0131\u011f\u0131 \u00e7ok oluyor. Bu konuda bir ikinci konu da o i\u015fi sevmeme nedenin o konu hakk\u0131ndaki derinli\u011finin az olmas\u0131 olabilir. Bilgin az oldu\u011fu i\u00e7in seni konfor alan\u0131ndan \u00e7\u0131kar\u0131yordur, b\u00f6yle zamanlarda ise o i\u015fi bitirebilmek i\u00e7in harcad\u0131\u011f\u0131m vaktin %25'ini o i\u015fi yapabilece\u011fim temelleri yeniden \u00f6\u011frenerek veya ara\u015ft\u0131rarak harc\u0131yorum. Hem daha yetkin oldu\u011fum i\u00e7in daha az can\u0131m s\u0131k\u0131l\u0131yor hem de o harcad\u0131\u011f\u0131m %25'lik zaman\u0131 yeni \u00f6\u011frendi\u011fim tekniklerle kompanze edebiliyorum. S\u0131f\u0131r kay\u0131p, daha yetkin bir ben. Tek ki\u015filik Scrum ekibini kur Bunu yapmak i\u00e7in \u00f6ncelikle scrum tekniklerini \u00f6\u011frenmen gerekiyor olabilir, bu y\u00fczden bu k\u0131sm\u0131 \u00e7ok k\u0131sa ge\u00e7ece\u011fim, zaten a\u015fa\u011f\u0131daki iyi bir \u00f6\u011frenme ad\u0131na \u00f6nerdi\u011fim kitaplar\u0131 payla\u015f\u0131rken bununla alakal\u0131 kitab\u0131 da koydum. Scrum bir tak\u0131m \u00e7al\u0131\u015fmas\u0131d\u0131r fakat kendi \u00f6\u011frenme ser\u00fcvenin i\u00e7in de bu teknikleri kullanabilirsin. Bunlar genellikle \u201cagile\u201d olarak da adland\u0131r\u0131l\u0131r. Kendine sprintler haz\u0131rla ve d\u00fcn hangi problemlerle kar\u015f\u0131la\u015ft\u0131n, bug\u00fcn ne yapacaks\u0131n? Her sabah \u00e7al\u0131\u015fmaya ba\u015flamadan \u00f6nce ve her gece yar\u0131n ne \u00e7al\u0131\u015faca\u011f\u0131n\u0131 planlayabilirsin. S\u0131k\u00e7a sorulan sorular yaz\u0131mdaki roadmap\u2019i kullanarak kendine bir kanban haritas\u0131 yapabilirsin. Kitab\u0131 okuduktan sonra bu k\u0131s\u0131m \u00e7ok daha iyi \u015fekillenecek. Not: T\u00fcm hayat\u0131m\u0131 kanban ve takvim ile y\u00f6netiyorum desem yalan s\u00f6yl\u00fcyor olmam. Bendeki \u00f6nemini siz d\u00fc\u015f\u00fcn\u00fcn. \u0130nternetteki kaynaklardan nas\u0131l \u00e7al\u0131\u015f\u0131l\u0131r? Belki takip ediyorsundur bir\u00e7ok defa s\u00f6yledim fakat her zaman tekrar etmek gerek. Buradaki yaz\u0131mda kaliteli oldu\u011funu d\u00fc\u015f\u00fcnd\u00fc\u011f\u00fcm kaynaklar\u0131 payla\u015ft\u0131m. Eline ge\u00e7en her \u015feyi denemen ve nas\u0131l \u00f6\u011frenebiliyorsun bunu ke\u015ffetmen gerekiyor. Maalesef en iyi y\u00f6ntem diye bir \u015fey yok. Keza bunu birinin size anlatmas\u0131 sizin stilinizi bulma konusunda engel olaca\u011f\u0131n\u0131 d\u00fc\u015f\u00fcn\u00fcyorum. Kendimden bir \u00f6rnekle gitmek istiyorum. Her zaman g\u00fczel not tutan insanlara \u00f6zenmi\u015fimdir, bence harika bir yetenek. Bunu yapamaman\u0131n cezas\u0131n\u0131 o konuyu yeniden \u00e7al\u0131\u015farak zaman cinsinden para birimiyle \u00f6d\u00fcyorum. Fakat problem \u015fu ki ben h\u0131zl\u0131 \u00f6\u011frenicilerdenim ayn\u0131 zamanda dikkatim \u00e7ok da\u011f\u0131l\u0131yor, e\u011fer not almak i\u00e7in kendimi yava\u015flat\u0131rsam oda\u011f\u0131m kaymaya ba\u015fl\u0131yor ve akl\u0131mdaki d\u00fc\u015f\u00fcnce \u201cnas\u0131l olsa not al\u0131yorum tekrar okuyarak anlamaya \u00e7al\u0131\u015f\u0131r\u0131m\u201d oluyor. Bunu yapmak ho\u015fuma gitmedi\u011fi i\u00e7in not alarak \u00e7al\u0131\u015fm\u0131yorum, m\u00fcmk\u00fcn oldu\u011fu kadar beynime yazmaya \u00e7al\u0131\u015f\u0131yorum ve ders esnas\u0131nda sonras\u0131nda detayl\u0131ca bakaca\u011f\u0131m keywordleri not ediyorum. Hali haz\u0131rda \u00e7al\u0131\u015fmay\u0131 sevdi\u011fim ve kitap bulabildi\u011fim i\u00e7in bu teknik bende iyi sonu\u00e7 veriyor. \u0130kinci yapt\u0131\u011f\u0131m \u015fey ise bilgimi aktarmak. \u00d6\u011fretmek g\u00fczel bir \u00f6\u011frenme y\u00f6ntemidir, medium blogumun , youtube kanal\u0131m\u0131n ve twitter sayfam\u0131n da olmas\u0131 bu y\u00fczden. Asl\u0131nda orada \u00fcretti\u011fim her i\u00e7erik siz sevgili takip\u00e7ilerimden ziyade kendime bir not defteri \ud83d\ude07 S\u00f6z\u00fcn \u00f6z\u00fc, ula\u015fabildi\u011fin kadar kayna\u011fa kendini bula\u015ft\u0131r. Belki uygulayarak belki dinleyerek belki her ikisinin kar\u0131\u015f\u0131k oldu\u011fu platformlarda daha iyi bir \u00f6\u011frenme e\u011frisi yakal\u0131yorsundur, deneyerek kendini geli\u015ftir ve en iyi yolu bul! Her \u015feye bula\u015f, birinde usta ol M\u00fchendislik alanlar\u0131 sadece okudu\u011fun alan ile s\u0131n\u0131rl\u0131 de\u011fildir. E\u011fer ger\u00e7ekten daha iyi \u00f6\u011frenen biri olmak istiyorsan zihnini farkl\u0131 alanlarda geni\u015fletmelisin, eskiler buna polimatl\u0131k veya hezarfen der. Bu insanlar\u0131 biliyoruz, hem filozof, hem mimar, hem de m\u00fczisyen. Harika de\u011fil mi? M\u00fchendislik seviyen senin teknik problem \u00e7\u00f6zme seviyendir. Daha iyi problem \u00e7\u00f6zmek i\u00e7in daha fazla disiplin hakk\u0131nda ba\u011flant\u0131 kurman gerekir. Daha duru bir g\u00f6r\u00fc\u015f sana yapt\u0131\u011f\u0131n i\u015fin s\u0131n\u0131rlar\u0131 hakk\u0131nda bilgi verir. \u0130lkokul seviyesinden bir \u00f6rnek verece\u011fim, \u00e7arpma i\u015flemi toplama i\u015fleminin k\u0131sa \u015feklidir. 5 + 5 + 5 asl\u0131nda 5x3 anlam\u0131na geliyor veya n adet s\u0131ral\u0131 say\u0131n\u0131n toplam\u0131n\u0131 form\u00fclize ederek \u00e7ok daha kolay bir \u015fekilde bulabiliyorsun. Geni\u015fletirsek 3 bilinmeyenli lineer denklemi cramer ile \u00e7\u00f6zmek olabilir. Ricatti diferansiyel denklemi \u00e7\u00f6zmek i\u00e7in domen d\u00f6n\u00fc\u015f\u00fcm\u00fc yapt\u0131\u011f\u0131nda bu tekni\u011fi kullanarak bir ses sinyalini ayr\u0131\u015ft\u0131rmak i\u00e7in filtre yapabiliyorsun. Elektronik devre elemanlar\u0131n\u0131 tanyorsan ger\u00e7ek hayatta bu filtreyi modelleyebiliyorsun. E\u011fer malzeme bilgin varsa kondansat\u00f6r ve bobin yaparak bu devrenin par\u00e7alar\u0131n\u0131 \u00fcretebiliyorsun. Kendi tasarlad\u0131\u011f\u0131n\u0131 elektronik devrenin kodunu kendi yazman\u0131n keyfini hi\u00e7bir \u015fey veremez emin ol \ud83d\ude04 \u015eimdi bu \u00f6nermemi patlataca\u011f\u0131m. Bir birey olarak t\u00fcm bunlar\u0131 bilmen harika olurdu ama bu her zaman yap\u0131labilir de\u011fildir. Fakat bir \u00e7\u00f6z\u00fcm\u00fcn var oldu\u011funu giri\u015f seviyesindeki temel bilgileri \u00e7ok k\u0131sa zamanda edinebilece\u011fini bilmeni isterim. Projeni veya kendini geli\u015ftirirken yap\u0131labilirlik senin hayal g\u00fcc\u00fcn ve donan\u0131m\u0131n ile s\u0131n\u0131rl\u0131d\u0131r, e\u011fer bilmiyorsan fark etmek de o kadar zor olacakt\u0131r. Bu y\u00fczden eline ge\u00e7en her \u015feye merakla yakla\u015f, soru sor ve birka\u00e7 g\u00fcn o \u015feyi kurcala. Steve Jobs\u2019un tipografi \u00f6\u011frenmesi, DaVincinin lir ustas\u0131 olmas\u0131, benim edebiyat d\u00fc\u015fk\u00fcn\u00fc olmam \ud83d\ude02 Not: Her konu hakk\u0131nda bilgin olsun, fakat bu demek de\u011fil ki o konu hakk\u0131nda illa konu\u015fman gerekiyor, bu genelde antipatiktir \ud83d\ude42 Felsefe \u00f6\u011frenme konusu var ki e\u011fer buna girersem \u00e7ok fazla s\u0131k\u0131laca\u011f\u0131z. A\u011f\u0131r bir kitap fakat e\u011fer eline ge\u00e7erse G\u00f6del, Escher, Bach: Bir Ebedi G\u00f6k\u00e7e Belik. \u00c7al\u0131\u015ft\u0131\u011f\u0131n konuyu etraf\u0131n haline getir Bu asl\u0131nda her \u015fey i\u00e7in ge\u00e7erli, ne kadar maruz kal\u0131rsan bilgi o kadar kal\u0131c\u0131 olur. Bu konu hakk\u0131nda \u00e7al\u0131\u015f\u0131yorsan, topluluklara kat\u0131l, senin gibi insanlar\u0131 bul, muhabbet et. \u0130nsanlar\u0131 dinlerken yeni \u015feyler farkediyorsun, sen anlat\u0131rken bilgini tazeliyorsun. \u0130\u015fin en g\u00fczel k\u0131sm\u0131 ise e\u011flenerek yapt\u0131\u011f\u0131n i\u00e7in harika hissettiriyor. Bunlar\u0131 yapamaman m\u00fcmk\u00fcn de\u011fil, \u00e7\u00fcnk\u00fc insanlar fiziksel olarak etraf\u0131nda da olmas\u0131 gerekmiyor, farkl\u0131 bir dil \u00f6\u011freniyorsan o dili bilen insanlarla etkile\u015fime ge\u00e7, makine \u00f6\u011frenmesi \u00f6\u011freniyorsan Twitter\u2019dan bu insanlar\u0131 takip et, topluluklarda g\u00f6n\u00fcll\u00fc olarak etkinlik g\u00f6ster. Hatta bilgilerini insanlara aktarmak i\u00e7in bir YouTube kanal\u0131 a\u00e7 :) Sadece zihnini \u00e7al\u0131\u015ft\u0131\u011f\u0131n konu etraf\u0131nda aktif tutman yapaca\u011f\u0131n en g\u00fczel \u015fey olacakt\u0131r. Bir \u015feyi \u00f6\u011frenmek/tamamlamak i\u00e7in motivasyon bulam\u0131yorsan, 5 dakika zorlan K\u0131r\u0131lma noktas\u0131 \u00f6rne\u011fi. O misafirlikteki \u00e7ocuk oldu\u011fun g\u00fcn\u00fc hat\u0131rla, ilk yar\u0131m saat koltukta suspus oturdu\u011fun, ak\u015fam olup da eve d\u00f6nerken evi talan eden \u00e7ocuktan bahsediyorum. Bir i\u015fe ba\u015flayam\u0131yorsan bir be\u015f dakika ba\u015f\u0131na oturup bir \u015feylerle ilgileniyormu\u015f, \u00e7al\u0131\u015f\u0131yormu\u015f gibi davran. Sadece taklit et. E\u011fer halen olmuyorsa g\u00fcn i\u00e7inde yapaca\u011f\u0131n di\u011fer i\u015fleri \u00f6nceliklendir o saat i\u00e7in, sonra tekrardan otur masan\u0131n ba\u015f\u0131na ve bir be\u015f dakika daha zorla kendini. Belki su o kadar fena de\u011fildir girince al\u0131\u015f\u0131yorsundur \ud83d\ude42 Ba\u015flamadan \u00f6nce sak\u0131n telefona bakma Zor yoldan \u00f6\u011frendi\u011fim bir tuzak asl\u0131nda bu ve en k\u00f6t\u00fcs\u00fc ne biliyor musun? Bunu fark\u0131nda olmama ra\u011fmen halen d\u00fc\u015f\u00fcyorum. Eminim sen de d\u00fc\u015f\u00fcyorsun. \u00c7\u00fcnk\u00fc d\u00fc\u015fmemek elde de\u011fil. Sabah uyan\u0131yorsun ve evet bug\u00fcn bunu yapaca\u011f\u0131m diyorsun, yapaca\u011f\u0131n \u015fey \u00e7al\u0131\u015fmak veya seni zorlayan bir konu. E\u011fer \u00e7al\u0131\u015fmadan \u00f6nce bir kahvalt\u0131 yapay\u0131m, bir kendime geleyim gibi vakitlerinde telefonu eline al\u0131yorsan, o g\u00fcn i\u015fe ba\u015flaman a\u015f\u0131r\u0131 zor olacak. Bir t\u00fcrl\u00fc o konsantrasyon seviyesine ula\u015famayacaks\u0131n eminim. Bu y\u00fczden bir \u015fey yapaca\u011f\u0131m g\u00fcnlerde telefonu elime almamaya \u00e7al\u0131\u015f\u0131yorum. Verdi\u011fim molalarda biraz telefona bakay\u0131m demiyorum, tekrar i\u015fe d\u00f6nmesi en zor konumlardan biri bu oluyor. Laf\u0131 dalland\u0131r\u0131p uzatmayaca\u011f\u0131m bunu hepimiz biliyoruz, e\u011fer bir i\u015f yapacaksan o i\u015ften \u00f6nce telefona bakma. Kitap \u00f6nerileri Burada hangi kaynaklardan daha iyi makine \u00f6\u011frenimi \u00e7al\u0131\u015fabilirim gibi kitaplar\u0131 vermeyece\u011fim, bunu s\u0131k\u00e7a sorulan sorular makalemde payla\u015fm\u0131\u015ft\u0131m linki b\u0131rak\u0131yorum. Burada \u00e7al\u0131\u015fma tekni\u011finizi ve bak\u0131\u015f a\u00e7\u0131n\u0131z\u0131 ilerleten iki kitaptan bahsedece\u011fim, eminim \u00e7ok daha iyi veya harika kitaplar da vard\u0131r fakat bu ikisini okuyarak ba\u015flayabilirsin. Benim i\u00e7in ger\u00e7ekten \u00e7ok etkili oldular ve buraya bunlar\u0131 sadece yazmak i\u00e7in yazmad\u0131\u011f\u0131m bil. Eminim \u015eaka Yap\u0131yorsunuz Bay Feynman Scrum: \u0130ki kat\u0131 i\u015fi yar\u0131 zamanda yapma sanat\u0131 Referans kaynaklar, yani ezberlemek zorunda olmad\u0131klar\u0131n Bu b\u00f6l\u00fcme Einstein\u2019\u0131n \u00e7ok sevdi\u011fim bir s\u00f6z\u00fcyle ba\u015flamak istiyorum. G\u00fcn\u00fcn birinde Albert Einstein\u2019\u0131n bir meslekta\u015f\u0131 ona telefon numaras\u0131n\u0131 sorar. Einstein bir telefon rehberi al\u0131p numaras\u0131na bakar. Meslekta\u015f\u0131 \u015fa\u015f\u0131r\u0131r ve \u201cKendi numaran\u0131 bilmiyor musun?\u201d diye sorar. \u201cHay\u0131r\u201d der Einstein ve ekler, \u201cBir kitapta kolayca bulabilece\u011fim bir \u015feyi neden ezberleyeyim ki?\u201d. Asl\u0131nda Einstein 2 dakikadan daha k\u0131sa s\u00fcrede bulabilece\u011fi hi\u00e7bir \u015feyi ezberlemedi\u011fini a\u00e7\u0131klam\u0131\u015ft\u0131r. \u00d6\u011frenme a\u015famas\u0131nda ezbere ger\u00e7ekten kar\u015f\u0131y\u0131m, bir konuyu \u00f6\u011frenirken akl\u0131nda kalmas\u0131 gereken bilgiler veya y\u00fcksek \u00f6neme sahip olanlar kullanma s\u0131kl\u0131\u011f\u0131 nedeniyle her hal\u00fckarda beyninde ezbere oturur. Bunun d\u0131\u015f\u0131nda beyni ezberlemek i\u00e7in zorlamak seni ancak \u2018daha \u00e7ok biliyorum\u2019 g\u00f6r\u00fcnt\u00fcs\u00fc vermek i\u00e7in kendine yapt\u0131\u011f\u0131n bir il\u00fczyonun \u00f6tesine g\u00f6t\u00fcrmeyecektir. \u015e\u00f6yle d\u00fc\u015f\u00fcnelim, adaptif momentum(ADAM) optimizat\u00f6r\u00fcn\u00fcn form\u00fcl\u00fcn\u00fc ezberleyebilirim veya onu neden kulland\u0131\u011f\u0131m\u0131 ve ne zaman kullanmam gerekti\u011fini \u00f6\u011frenebilirim. Sence hangisini yapmam beni daha yetkin biri k\u0131lard\u0131? Bu soruya cevap vererek karar verebilirsin. Bir \u015feyi unuttu\u011funda o tamamen yok olmam\u0131\u015ft\u0131r Gelelim bir di\u011fer yan\u0131lg\u0131ya. Kaliteli bir kitap okuyorsun, g\u00fczel bir video e\u011fitim serisine denk geldin. \u00c7al\u0131\u015f\u0131yorsun, notlar\u0131n\u0131 ald\u0131n g\u00fczel birka\u00e7 noktay\u0131 kavrad\u0131n ve art\u0131k bu konuda daha bilgili oldu\u011funu hissediyorsun. Ertesi g\u00fcn bakt\u0131\u011f\u0131nda veya videoyu ikinci kez izledi\u011finde haf\u0131zanda birka\u00e7 iz oldu\u011funu fark ediyorsun fakat tam olarak ne oldu\u011funu hat\u0131rlam\u0131yorsun. Hepimiz ya\u015f\u0131yoruz bunu de\u011fil mi? Gayet normal, asl\u0131nda bu bir problem de de\u011fil. Maalesef halen belle\u011fimize veri yazam\u0131yoruz (yazsak harika olurdu). Her zaman yapt\u0131\u011f\u0131m\u0131z gibi bu durumu da kabullenmemiz gerekiyor fakat ben yine de senin i\u00e7in birka\u00e7 teknik verece\u011fim. Birinicisi \u00f6\u011frenme s\u00fcreci kolay de\u011fildir ve tekrar etmek gerekir. \u0130kincisi bunu hayat\u0131nda bir \u015fekilde uygulayarak peki\u015ftirmelisin. \u00dc\u00e7\u00fcnc\u00fcs\u00fc ayn\u0131 konuyu farkl\u0131 kaynaklardan \u00e7apraz \u00f6\u011frenme ile oturtman gerekir. Tabiat\u0131yla bu \u00f6\u011frenme s\u00fcrecini uzatacakt\u0131r burada bir pazarl\u0131k yapman gerek fakat ben genellikle \u015f\u00f6yle d\u00fc\u015f\u00fcn\u00fcyorum. Yola devam et ihtiyac\u0131n oldu\u011funda tekrar geriye d\u00f6n ve bak. E\u011fer hi\u00e7 kar\u015f\u0131la\u015fm\u0131yorsan \u00f6nem derecesi d\u00fc\u015f\u00fckt\u00fcr. Bunlar\u0131n yan\u0131nda bilgiyi \u00f6\u011frenirken beynin yeniden \u015fekillenir, ne oldu\u011funu unutsan dahi art\u0131k sen ayn\u0131 ki\u015fi de\u011filsin. Sana \u00e7al\u0131\u015ft\u0131\u011f\u0131n konu hakk\u0131nda farkl\u0131 bir bak\u0131\u015f a\u00e7\u0131s\u0131 \u00e7oktan kat\u0131ld\u0131, belki akl\u0131nda kalmad\u0131 fakat ba\u015fka bir konuyla kurulacak ba\u011f\u0131nt\u0131n\u0131n derecesi kuvvetlenmi\u015f oldu. Okumaya devam ettik\u00e7e sen d\u00fcnk\u00fc senden daha farkl\u0131 birisin! \u201cayn\u0131 nehirde iki kez y\u0131kan\u0131lmaz.\u201d Makine \u00f6\u011frenmesinden \u00f6\u011fren Makine \u00f6\u011frenemesi teknikleri asl\u0131nda \u00f6\u011frenme felsefesinin rasyonel halidir. Modelleri daha iyi e\u011fitmek i\u00e7in kullan\u0131lan t\u00fcm teknikleri kendine yorabilirsin. \u00c7\u00fcnk\u00fc onlar da insanlardan ilham al\u0131narak geli\u015ftirildi, bu ba\u011flamda daha senin kendi i\u00e7inde ke\u015ffetmedi\u011fin teknikleri ke\u015ffeden di\u011fer insanlar bunu makinelere yapt\u0131rabilmek i\u00e7in \u00e7oktan matematiksel bir forma d\u00f6kt\u00fcler bile. \u0130ki \u00f6rnek b\u0131rakaca\u011f\u0131m fakat bunu d\u00fc\u015f\u00fcnerek geni\u015fletmelisin: Overfitting problemini \u00e7\u00f6zmek i\u00e7in modele daha fazla veri vermek. \u00dcniversitede \u00e7\u0131km\u0131\u015f sorularla okulu ge\u00e7en b\u00fcy\u00fck bir topluluk var, hepiniz onlar\u0131 tan\u0131yorsunuz. Bunlar k\u0131s\u0131tl\u0131 birka\u00e7 soru tipiyle s\u0131nava girerler ve belirli bir yere kadar ba\u015far\u0131 g\u00f6sterirler fakat hoca soru tipinde en ufak bir de\u011fi\u015fiklik yapt\u0131\u011f\u0131nda patlarlar. Fakat \u00e7ok fazla soru tipi g\u00f6rm\u00fc\u015f ki\u015filer i\u00e7in bu durum bir problem de\u011fildir. Model e\u011fitimi i\u00e7in veri \u00f6nhaz\u0131rl\u0131\u011f\u0131 yapmak. Herkes derli toplu kaynaklar\u0131, temiz bir yaz\u0131yla tutulmu\u015f notlar\u0131, iyi anlat\u0131lm\u0131\u015f konu anlat\u0131mlar\u0131n\u0131 sever. Bir konuya \u00e7al\u0131\u015fmadan \u00f6nce \u00e7al\u0131\u015faca\u011f\u0131n\u0131z kaynaklar\u0131 bu hale getirmek, hem motivasyonunuzu ayakta tutacakt\u0131r hem de fazla bilgi aras\u0131nda kaybolman\u0131z\u0131 engelleyecektir. E\u011fer \u00e7eviri hatalar\u0131 olan veya yanl\u0131\u015f bilgi i\u00e7ermesi muhtemel kaynaklar\u0131 (wikipedia, ek\u015fis\u00f6zl\u00fck, forumlar) akademik dersleriniz i\u00e7in kullan\u0131yorsan\u0131z yanl\u0131\u015f yere kur\u015fun at\u0131yor olabilirsiniz. Bu da size e\u011fitiminde daha y\u00fcksek cost ve daha d\u00fc\u015f\u00fck accuracy\u2019ye sebep olacakt\u0131r. Genel olarak benim \u00f6\u011frenme s\u00fcrecim b\u00f6yle i\u015fliyor. Bunlar\u0131 yaz\u0131ya d\u00f6kmesem belki ben de fark etmezdim neler yapt\u0131\u011f\u0131m\u0131. Belki de yapt\u0131\u011f\u0131m fakat unuttu\u011fum bir\u00e7ok \u015fey daha var. Di\u011fer \u00e7al\u0131\u015fmalar\u0131m\u0131 da takip etmek istersen twitter, youtube, medium ve githubday\u0131m. Twitter: mertcobanov Youtube: mertcobanov Medium: mertcobanov Originally published at https://cobanov.github.io .","title":"Ogrenme Tekniklerim"},{"location":"ogrenme-tekniklerim/#her-sey-kabul-etmek-ile-alakal","text":"\u00d6\u011frenmenin bir s\u00fcre\u00e7 oldu\u011funu ve geli\u015fimini asl\u0131nda senin fark edemeyece\u011fin kadar yava\u015f oldu\u011funu kabul etmelisin. Burada bence umutsuzlu\u011fa s\u00fcr\u00fcklenilen konu, bir \u015feyi \u00f6\u011frenmeye ilk ba\u015flad\u0131\u011f\u0131ndaki heyecan her \u015feyi yapma hevesi do\u011furuyor, fakat kapabiliten hen\u00fcz haz\u0131r olmad\u0131\u011f\u0131 i\u00e7in kendini k\u00fc\u00e7\u00fck g\u00f6rme sendromuna kap\u0131labiliyorsun. Bunu kabul etmeli ve gerekli par\u00e7alar\u0131n zamanla bu yolda ancak y\u00fcr\u00fcyerek oturaca\u011f\u0131n\u0131 anlamak gerek. E\u011fer bir \u015fey \u00e7ok h\u0131zl\u0131 ba\u015far\u0131l\u0131yorsa muhtemelen bu basit bir \u015feydir ve herkes taraf\u0131ndan yap\u0131labilir.","title":"Her \u015fey kabul etmek ile alakal\u0131"},{"location":"ogrenme-tekniklerim/#kompleksite-ve-derinlik","text":"Bir di\u011fer konu biraz karma\u015f\u0131k, l\u00fctfen bu paragraf\u0131 bir kez daha oku \u00e7\u00fcnk\u00fc sonda s\u00f6ylediklerim ba\u015flang\u0131\u00e7 ile birlikte paralel olarak ger\u00e7ekle\u015fen etmenler i\u00e7eriyor. Son k\u0131sm\u0131 anlad\u0131\u011f\u0131nda ilk k\u0131s\u0131m biraz daha ayd\u0131nlanm\u0131\u015f olacak. Literat\u00fcrde nas\u0131l adland\u0131r\u0131l\u0131yor bilmiyorum fakat ben bunu alg\u0131 ivmesi olarak adland\u0131r\u0131yorum. Bir konuyu \u00e7al\u0131\u015fmak \u00fczere masaya oturdun, telefonun yan\u0131nda duruyor ve odada ba\u015fka biri daha var. Sen \u00e7al\u0131\u015fmaya ba\u015flad\u0131\u011f\u0131nda beynin o i\u015flem i\u00e7in bir alan yaratmaya ba\u015flayacak. Okumaya veya \u00e7al\u0131\u015fmaya devam ettik\u00e7e bu kapasite b\u00fcy\u00fcyecek ve daha kompleks hale gelecek. Bunu bir \u00f6rnek ile anla\u015f\u0131l\u0131r hale getireyim Zor bir matematik veya fizik sorusu \u00e7\u00f6zmeye ba\u015flad\u0131\u011f\u0131n\u0131 d\u00fc\u015f\u00fcn, sonuca ula\u015fmak ad\u0131na problemin arg\u00fcmanlar\u0131nda baz\u0131 d\u00f6n\u00fc\u015f\u00fcmler uyguluyorsun (de\u011fi\u015fken de\u011fi\u015fimi, birim d\u00f6n\u00fc\u015f\u00fcm\u00fc veya geometri sorusu \u00e7\u00f6zerken indirilen dikmeler, \u00e7ekilen te\u011fetler gibi). Beynin problemin \u00e7\u00f6z\u00fcm\u00fc i\u00e7in karma\u015f\u0131kl\u0131\u011f\u0131 ge\u00e7ici bellekte tutmaya ba\u015fl\u0131yor, ilerleyen k\u0131s\u0131mlarda daha kompleks i\u015flemleri yapabilmen i\u00e7in bu ba\u011flamlar\u0131 oda\u011f\u0131na koyuyor. Dikkatin odaklanm\u0131\u015f bir durumda ve \u00e7\u0131k\u0131\u015f yolunu taramaya ba\u015fl\u0131yorsun, e\u011fer bir kesme i\u015flemi olursa (interrupt) bu zamana kadar \u00f6nbellekte tuttu\u011fun kompleksite da\u011f\u0131lm\u0131\u015f olacak. Yeniden problemin ba\u015f\u0131na d\u00f6nd\u00fc\u011f\u00fcnde o yollar\u0131 tekrar etmek zorunda kalacaks\u0131n. \u015eimdi \u00e7ok pop\u00fcler ve etkisi defalarca onaylanm\u0131\u015f olmas\u0131na ra\u011fmen iki arg\u00fcmana kar\u015f\u0131t bir arg\u00fcman sunaca\u011f\u0131m ve muhtemelen bu fikre kat\u0131lmak istemeyen bir\u00e7ok ki\u015fi olacak, ama yine de bu fikri de\u011ferlendirmeni istiyorum. Kendi ispat\u0131m\u0131 da arg\u00fcman\u0131m\u0131n sonunda payla\u015faca\u011f\u0131m. Birincisi pomodoro tekni\u011fi, ikinicisi ise problemi k\u00fc\u00e7\u00fck par\u00e7alara b\u00f6lmek.","title":"Kompleksite ve Derinlik"},{"location":"ogrenme-tekniklerim/#bazen-pomodoro-iyi-degildir","text":"Pomodoro tekni\u011fini bilmeyenler i\u00e7in k\u0131saca a\u00e7\u0131klamak gerekirse 25 dakikal\u0131k periyotlarla \u00e7al\u0131\u015f\u0131yorsun ve sonras\u0131nda k\u0131sa bir mola veriyorsun. Problemi k\u00fc\u00e7\u00fck par\u00e7alara b\u00f6lmeyi a\u00e7\u0131klama gere\u011fi duymuyorum gayet a\u00e7\u0131k. Bu iki tekni\u011fin problemi anla\u015f\u0131lmas\u0131 g\u00f6rece zor ve detay i\u00e7eren ileri \u00f6\u011frenme konular\u0131nda negatif performans g\u00f6stermeleri. Yaz\u0131n\u0131n \u00f6nceki k\u0131sm\u0131nda yeni bir \u015fey \u00f6\u011frenirken m\u00fczi\u011fi kapatt\u0131\u011f\u0131m\u0131 fakat hali haz\u0131rda bildi\u011fim konularda i\u015f yaparken a\u00e7t\u0131\u011f\u0131m\u0131 s\u00f6ylemi\u015ftim, bununla ba\u011flant\u0131l\u0131 asl\u0131nda. Zor konular\u0131 \u00f6\u011frenirken beynini o konu ba\u011flam\u0131n\u0131n etraf\u0131nda s\u00fcrekli dola\u015ft\u0131rman gerekiyor. Konu derinle\u015ftik\u00e7e bu karma\u015f\u0131k yap\u0131n\u0131n her noktas\u0131n\u0131 gezmelisin ve bu vakit alan bir s\u00fcre\u00e7tir. Bunu \u015f\u00f6yle \u00f6rneklendirelim: Uzaya bir roket f\u0131rlatt\u0131\u011f\u0131n\u0131 d\u00fc\u015f\u00fcn ve a\u015fman gereken bir atmosfer var. Bir e\u015fi\u011fi ge\u00e7ene kadar s\u00fcrekli olarak enerji vermeye devam etmelisin. Yolun bir k\u0131sm\u0131nda enerjiyi kesmek ivmeni \u00e7ok fazla d\u00fc\u015f\u00fcrecek ve o ivmeyi tekrar alabilmek i\u00e7in daha fazla enerji kullanman gerekecek. Hatta atmosferden ayr\u0131lana kadar e\u011fer bu ivmeyi d\u00fc\u015f\u00fcr\u00fcrsen, roketi indirip tekrardan yery\u00fcz\u00fcnden ate\u015flemen gerekir. Bu y\u00fczden i\u015f yaparken pomodoro g\u00fczel bir tazeleyici olmas\u0131na ra\u011fmen \u00f6\u011frenirken h\u0131z kesmenin negatif bir etkisi oldu\u011funu d\u00fc\u015f\u00fcn\u00fcyorum. \u00d6rnekler san\u0131r\u0131m sonsuz say\u0131da art\u0131r\u0131labilir: \u00e7\u0131\u011f etkisi, lambal\u0131 bir amfiyi kullanmadan \u00f6nce \u0131s\u0131tmak, yol verme direncini a\u015fm\u0131\u015f bir elektrik motoru, r\u00fczgar trib\u00fcn\u00fcn\u00fcn ilk hareketi\u2026 Bunlar\u0131 durdurmak istemezsin.","title":"Bazen? pomodoro iyi de\u011fildir"},{"location":"ogrenme-tekniklerim/#problemi-kucuk-parcalara-ayr-veya-ayrma","text":"Problemi k\u00fc\u00e7\u00fck par\u00e7alara ay\u0131rmak, m\u00fckemmel bir teknik, ger\u00e7ekten sorun \u00e7\u00f6zme konusunda daha iyi bir y\u00f6ntem d\u00fc\u015f\u00fcnemiyorum. (Zaten bu iki tekni\u011fe k\u00f6r\u00fc k\u00f6r\u00fcne kar\u015f\u0131 de\u011filim sadece her yetene\u011fin veriminin y\u00fcksek oldu\u011fu anlar vard\u0131r, do\u011fru anda do\u011fru tekni\u011fi kullanmak gerek.) Baz\u0131 problemler daha k\u00fc\u00e7\u00fck par\u00e7alara ayr\u0131lmazlar, bunlar\u0131 b\u00fct\u00fcn karma\u015f\u0131kl\u0131\u011f\u0131yla b\u00fcy\u00fck bir lokmada yutulmas\u0131 gereken durumlar olacakt\u0131r. B\u00f6yle zamanlarda problemin karma\u015f\u0131kl\u0131k seviyesi y\u00fcksek oldu\u011fu i\u00e7in sonraya b\u0131rakma veya anlamadan ge\u00e7me gibi eylemlerde bulunabilirsin. Bunu yapma. V\u00fccudundaki kaslar\u0131 d\u00fc\u015f\u00fcn, daha y\u00fcksek tansiyon alt\u0131nda b\u0131rakt\u0131\u011f\u0131nda kaslar\u0131n ertesi g\u00fcn i\u00e7in o kuvveti kar\u015f\u0131layabilecek \u015fekilde evrilecektir. Zor konular\u0131 anlamak i\u00e7in harcayaca\u011f\u0131n efor, soyut d\u00fc\u015f\u00fcnce bilincinin s\u0131n\u0131rlar\u0131n\u0131 geni\u015fletecektir. Hepimiz felsefe okulundaki \u201cGeometri bilmeyen giremez.\u201d s\u00f6z\u00fcn\u00fc biliyoruz. Matematik dedi\u011fimiz yap\u0131 soyut ve somut kavram\u0131n\u0131n aras\u0131na \u00e7ekilmi\u015f bir \u00e7izgidir asl\u0131nda. Ka\u011f\u0131t \u00fczerinde 300 boyutlu bir tens\u00f6r i\u015flemi yap\u0131labilir ve sonu\u00e7lar tutarl\u0131d\u0131r (ger\u00e7ek d\u00fcnyada b\u00f6yle bir formu somut hale getirmek imkans\u0131zd\u0131r) kompleks d\u00fczlemde o harflerle (i ve j) yap\u0131lan i\u015flemlerin etkisi inan\u0131l\u0131r gibi de\u011fil fakat ger\u00e7ek d\u00fcnyada g\u00f6zlemlenir. Bunun i\u00e7in elektrik, dalga teorisi gibi konular\u0131 inceleyebilirsin. Fakat en basit kondansat\u00f6r\u00fcn bile bu y\u00f6ntemle \u00e7al\u0131\u015f\u0131yor olmas\u0131 buna bir \u00f6rnek. Bu y\u00fczden baz\u0131 konular\u0131n par\u00e7alanamayaca\u011f\u0131, soyutluk kavram\u0131 ve beyin s\u0131n\u0131rlar\u0131n\u0131 geni\u015fletmek i\u00e7in beynini kompleksiteye zorlaman, alg\u0131n\u0131 olduk\u00e7a a\u00e7acakt\u0131r. Bundan l\u00fctfen ka\u00e7ma.","title":"Problemi k\u00fc\u00e7\u00fck par\u00e7alara ay\u0131r (veya ay\u0131rma)"},{"location":"ogrenme-tekniklerim/#biraz-mola","text":"Evet zor k\u0131sm\u0131 hallettik. Belki de en \u00f6nemli k\u0131s\u0131m buydu. \u00c7\u00fcnk\u00fc bu y\u00f6ntemi i\u00e7selle\u015ftirdi\u011finde problemlere bak\u0131\u015f a\u00e7\u0131n de\u011fi\u015fecek, vizyonun farkl\u0131la\u015facak, belki karakterin hatta g\u00fcnl\u00fck konu\u015fmandaki kelimelerin bile de\u011fi\u015fecek.","title":"Biraz mola"},{"location":"ogrenme-tekniklerim/#yer-tutucular-ve-fikir-regularizasyonu","text":"Gelelim \u00e7al\u0131\u015f\u0131rken yapmay\u0131 sevdi\u011fim di\u011fer bir y\u00f6nteme. Yeni bir bilgi geldi\u011finde tamam\u0131n\u0131 kavramam\u0131\u015f olsam bile daha \u00f6nceden bildi\u011fim \u015feylerle bir ba\u011flam yaratmaya ve hatal\u0131 da olsa bir yere oturtmaya \u00e7al\u0131\u015f\u0131yorum, bu yeni edindi\u011fim bilgi hakk\u0131ndaki \u00f6ng\u00f6r\u00fcm oluyor ve her zaman hatal\u0131 bir \u00f6ng\u00f6r\u00fcm oldu\u011funu hemen kabul ediyorum. Beynimde onun i\u00e7in bir placeholder -yer tutucu- ayarl\u0131yorum. Sonras\u0131nda \u00f6\u011frenme i\u015flemim devam ederken soru sormaya ba\u015fl\u0131yorum, ben \u015f\u00f6yle d\u00fc\u015f\u00fcnm\u00fc\u015ft\u00fcm halbuki b\u00f6yleymi\u015f, \u015fimdi daha iyi anl\u0131yorum. Sonras\u0131nda yeni bir fikir daha olu\u015fuyor, ve yeni bir bilgi daha geldi\u011finde bunu yeniden test ediyorum, \u201chah evet tam da d\u00fc\u015f\u00fcnd\u00fc\u011f\u00fcm gibi, akl\u0131n yolu bir, mant\u0131kl\u0131 olan da buydu zaten\u201d ve bu his bana keyif veriyor. Zihnimi bu konu hakk\u0131nda canl\u0131 tutuyorum fakat en \u00f6nemlisi \u015funu anl\u0131yorum: Pozitif bilimlerde her \u015fey birbirine ba\u011fl\u0131d\u0131r, \u00e7\u00fcnk\u00fc evren temel yap\u0131ta\u015f\u0131nda belirli fizik \u00e7at\u0131s\u0131 alt\u0131nda var olan bir mimari. E\u011fer fizik tutarl\u0131 de\u011filse var olmak da m\u00fcmk\u00fcn olmayacakt\u0131 de\u011fil mi? Bu y\u00fczden ba\u011flant\u0131lar\u0131 yakalamaya \u00e7al\u0131\u015fmaktan asla vazge\u00e7me. Bu arada bu y\u00f6nteme diyalektik materyalizm deniyor. Fikirler b\u00f6yle do\u011far!","title":"Yer Tutucular ve Fikir Reg\u00fclarizasyonu"},{"location":"ogrenme-tekniklerim/#yapmay-sevmedigim-bir-isi-nasl-ogreniyorum","text":"Harika, mesela bu soruyu cevaplamak istemiyor olmama ra\u011fmen, \u015fu anda yapmay\u0131 sevmedi\u011fim bir i\u015fi yapaca\u011f\u0131m. Neden yapmak istemiyorum? \u00c7\u00fcnk\u00fc olduk\u00e7a s\u0131k\u0131c\u0131, ve ak\u0131c\u0131 bir \u015fekilde ilerleyemiyorum. \u0130nsan istiyor ki \u00f6\u011frenmeden al\u0131nan haz ve bir i\u015fi halletmenin verdi\u011fi haz s\u00fcrekli sabit olsun. Yapmak zorunda oldu\u011fun ve belki de seni bir ad\u0131m \u00f6ne \u00e7\u0131kartacak \u015fey maalesef her zaman yapmay\u0131 sevmedi\u011fin bir i\u015f oluyor. Benim b\u00f6yle zamanlarda yapt\u0131\u011f\u0131m \u015feyler olduk\u00e7a k\u0131s\u0131tl\u0131, genellikle yan\u0131ma bu s\u0131k\u0131nt\u0131y\u0131 payla\u015facak bir ikinci ki\u015fi bulmak. Problemime ortak olan biri varsa hadi gel \u015funu yapal\u0131m diyorum. Bunu yorgunken spora gitmek gibi d\u00fc\u015f\u00fcnebilirsin. Ba\u015fka birisi konudan ba\u011f\u0131ms\u0131z bir motivasyon \u00f6zelli\u011fi g\u00f6sterir. \u00c7\u00fcnk\u00fc o anda birini allocate (tam anlam\u0131 veren T\u00fcrk\u00e7e kar\u015f\u0131l\u0131k bulamad\u0131m, o i\u015f i\u00e7in o ki\u015fiyi me\u015fgul etmek, ay\u0131rmak) etmi\u015fsindir ve art\u0131k bu i\u015fi o anda yapma zorunlulu\u011fun artm\u0131\u015ft\u0131r iyice ka\u00e7amazs\u0131n. Tam bir \u00e7\u00f6z\u00fcm de\u011fil biliyorum fakat yan\u0131na o i\u015f i\u00e7in herhangi birini al b\u00f6yle zamanlarda, i\u015fe yarad\u0131\u011f\u0131 \u00e7ok oluyor. Bu konuda bir ikinci konu da o i\u015fi sevmeme nedenin o konu hakk\u0131ndaki derinli\u011finin az olmas\u0131 olabilir. Bilgin az oldu\u011fu i\u00e7in seni konfor alan\u0131ndan \u00e7\u0131kar\u0131yordur, b\u00f6yle zamanlarda ise o i\u015fi bitirebilmek i\u00e7in harcad\u0131\u011f\u0131m vaktin %25'ini o i\u015fi yapabilece\u011fim temelleri yeniden \u00f6\u011frenerek veya ara\u015ft\u0131rarak harc\u0131yorum. Hem daha yetkin oldu\u011fum i\u00e7in daha az can\u0131m s\u0131k\u0131l\u0131yor hem de o harcad\u0131\u011f\u0131m %25'lik zaman\u0131 yeni \u00f6\u011frendi\u011fim tekniklerle kompanze edebiliyorum. S\u0131f\u0131r kay\u0131p, daha yetkin bir ben.","title":"Yapmay\u0131 sevmedi\u011fim bir i\u015fi nas\u0131l \u00f6\u011freniyorum?"},{"location":"ogrenme-tekniklerim/#tek-kisilik-scrum-ekibini-kur","text":"Bunu yapmak i\u00e7in \u00f6ncelikle scrum tekniklerini \u00f6\u011frenmen gerekiyor olabilir, bu y\u00fczden bu k\u0131sm\u0131 \u00e7ok k\u0131sa ge\u00e7ece\u011fim, zaten a\u015fa\u011f\u0131daki iyi bir \u00f6\u011frenme ad\u0131na \u00f6nerdi\u011fim kitaplar\u0131 payla\u015f\u0131rken bununla alakal\u0131 kitab\u0131 da koydum. Scrum bir tak\u0131m \u00e7al\u0131\u015fmas\u0131d\u0131r fakat kendi \u00f6\u011frenme ser\u00fcvenin i\u00e7in de bu teknikleri kullanabilirsin. Bunlar genellikle \u201cagile\u201d olarak da adland\u0131r\u0131l\u0131r. Kendine sprintler haz\u0131rla ve d\u00fcn hangi problemlerle kar\u015f\u0131la\u015ft\u0131n, bug\u00fcn ne yapacaks\u0131n? Her sabah \u00e7al\u0131\u015fmaya ba\u015flamadan \u00f6nce ve her gece yar\u0131n ne \u00e7al\u0131\u015faca\u011f\u0131n\u0131 planlayabilirsin. S\u0131k\u00e7a sorulan sorular yaz\u0131mdaki roadmap\u2019i kullanarak kendine bir kanban haritas\u0131 yapabilirsin. Kitab\u0131 okuduktan sonra bu k\u0131s\u0131m \u00e7ok daha iyi \u015fekillenecek. Not: T\u00fcm hayat\u0131m\u0131 kanban ve takvim ile y\u00f6netiyorum desem yalan s\u00f6yl\u00fcyor olmam. Bendeki \u00f6nemini siz d\u00fc\u015f\u00fcn\u00fcn.","title":"Tek ki\u015filik Scrum ekibini kur"},{"location":"ogrenme-tekniklerim/#internetteki-kaynaklardan-nasl-calslr","text":"Belki takip ediyorsundur bir\u00e7ok defa s\u00f6yledim fakat her zaman tekrar etmek gerek. Buradaki yaz\u0131mda kaliteli oldu\u011funu d\u00fc\u015f\u00fcnd\u00fc\u011f\u00fcm kaynaklar\u0131 payla\u015ft\u0131m. Eline ge\u00e7en her \u015feyi denemen ve nas\u0131l \u00f6\u011frenebiliyorsun bunu ke\u015ffetmen gerekiyor. Maalesef en iyi y\u00f6ntem diye bir \u015fey yok. Keza bunu birinin size anlatmas\u0131 sizin stilinizi bulma konusunda engel olaca\u011f\u0131n\u0131 d\u00fc\u015f\u00fcn\u00fcyorum. Kendimden bir \u00f6rnekle gitmek istiyorum. Her zaman g\u00fczel not tutan insanlara \u00f6zenmi\u015fimdir, bence harika bir yetenek. Bunu yapamaman\u0131n cezas\u0131n\u0131 o konuyu yeniden \u00e7al\u0131\u015farak zaman cinsinden para birimiyle \u00f6d\u00fcyorum. Fakat problem \u015fu ki ben h\u0131zl\u0131 \u00f6\u011frenicilerdenim ayn\u0131 zamanda dikkatim \u00e7ok da\u011f\u0131l\u0131yor, e\u011fer not almak i\u00e7in kendimi yava\u015flat\u0131rsam oda\u011f\u0131m kaymaya ba\u015fl\u0131yor ve akl\u0131mdaki d\u00fc\u015f\u00fcnce \u201cnas\u0131l olsa not al\u0131yorum tekrar okuyarak anlamaya \u00e7al\u0131\u015f\u0131r\u0131m\u201d oluyor. Bunu yapmak ho\u015fuma gitmedi\u011fi i\u00e7in not alarak \u00e7al\u0131\u015fm\u0131yorum, m\u00fcmk\u00fcn oldu\u011fu kadar beynime yazmaya \u00e7al\u0131\u015f\u0131yorum ve ders esnas\u0131nda sonras\u0131nda detayl\u0131ca bakaca\u011f\u0131m keywordleri not ediyorum. Hali haz\u0131rda \u00e7al\u0131\u015fmay\u0131 sevdi\u011fim ve kitap bulabildi\u011fim i\u00e7in bu teknik bende iyi sonu\u00e7 veriyor. \u0130kinci yapt\u0131\u011f\u0131m \u015fey ise bilgimi aktarmak. \u00d6\u011fretmek g\u00fczel bir \u00f6\u011frenme y\u00f6ntemidir, medium blogumun , youtube kanal\u0131m\u0131n ve twitter sayfam\u0131n da olmas\u0131 bu y\u00fczden. Asl\u0131nda orada \u00fcretti\u011fim her i\u00e7erik siz sevgili takip\u00e7ilerimden ziyade kendime bir not defteri \ud83d\ude07 S\u00f6z\u00fcn \u00f6z\u00fc, ula\u015fabildi\u011fin kadar kayna\u011fa kendini bula\u015ft\u0131r. Belki uygulayarak belki dinleyerek belki her ikisinin kar\u0131\u015f\u0131k oldu\u011fu platformlarda daha iyi bir \u00f6\u011frenme e\u011frisi yakal\u0131yorsundur, deneyerek kendini geli\u015ftir ve en iyi yolu bul!","title":"\u0130nternetteki kaynaklardan nas\u0131l \u00e7al\u0131\u015f\u0131l\u0131r?"},{"location":"ogrenme-tekniklerim/#her-seye-bulas-birinde-usta-ol","text":"M\u00fchendislik alanlar\u0131 sadece okudu\u011fun alan ile s\u0131n\u0131rl\u0131 de\u011fildir. E\u011fer ger\u00e7ekten daha iyi \u00f6\u011frenen biri olmak istiyorsan zihnini farkl\u0131 alanlarda geni\u015fletmelisin, eskiler buna polimatl\u0131k veya hezarfen der. Bu insanlar\u0131 biliyoruz, hem filozof, hem mimar, hem de m\u00fczisyen. Harika de\u011fil mi? M\u00fchendislik seviyen senin teknik problem \u00e7\u00f6zme seviyendir. Daha iyi problem \u00e7\u00f6zmek i\u00e7in daha fazla disiplin hakk\u0131nda ba\u011flant\u0131 kurman gerekir. Daha duru bir g\u00f6r\u00fc\u015f sana yapt\u0131\u011f\u0131n i\u015fin s\u0131n\u0131rlar\u0131 hakk\u0131nda bilgi verir. \u0130lkokul seviyesinden bir \u00f6rnek verece\u011fim, \u00e7arpma i\u015flemi toplama i\u015fleminin k\u0131sa \u015feklidir. 5 + 5 + 5 asl\u0131nda 5x3 anlam\u0131na geliyor veya n adet s\u0131ral\u0131 say\u0131n\u0131n toplam\u0131n\u0131 form\u00fclize ederek \u00e7ok daha kolay bir \u015fekilde bulabiliyorsun. Geni\u015fletirsek 3 bilinmeyenli lineer denklemi cramer ile \u00e7\u00f6zmek olabilir. Ricatti diferansiyel denklemi \u00e7\u00f6zmek i\u00e7in domen d\u00f6n\u00fc\u015f\u00fcm\u00fc yapt\u0131\u011f\u0131nda bu tekni\u011fi kullanarak bir ses sinyalini ayr\u0131\u015ft\u0131rmak i\u00e7in filtre yapabiliyorsun. Elektronik devre elemanlar\u0131n\u0131 tanyorsan ger\u00e7ek hayatta bu filtreyi modelleyebiliyorsun. E\u011fer malzeme bilgin varsa kondansat\u00f6r ve bobin yaparak bu devrenin par\u00e7alar\u0131n\u0131 \u00fcretebiliyorsun. Kendi tasarlad\u0131\u011f\u0131n\u0131 elektronik devrenin kodunu kendi yazman\u0131n keyfini hi\u00e7bir \u015fey veremez emin ol \ud83d\ude04 \u015eimdi bu \u00f6nermemi patlataca\u011f\u0131m. Bir birey olarak t\u00fcm bunlar\u0131 bilmen harika olurdu ama bu her zaman yap\u0131labilir de\u011fildir. Fakat bir \u00e7\u00f6z\u00fcm\u00fcn var oldu\u011funu giri\u015f seviyesindeki temel bilgileri \u00e7ok k\u0131sa zamanda edinebilece\u011fini bilmeni isterim. Projeni veya kendini geli\u015ftirirken yap\u0131labilirlik senin hayal g\u00fcc\u00fcn ve donan\u0131m\u0131n ile s\u0131n\u0131rl\u0131d\u0131r, e\u011fer bilmiyorsan fark etmek de o kadar zor olacakt\u0131r. Bu y\u00fczden eline ge\u00e7en her \u015feye merakla yakla\u015f, soru sor ve birka\u00e7 g\u00fcn o \u015feyi kurcala. Steve Jobs\u2019un tipografi \u00f6\u011frenmesi, DaVincinin lir ustas\u0131 olmas\u0131, benim edebiyat d\u00fc\u015fk\u00fcn\u00fc olmam \ud83d\ude02 Not: Her konu hakk\u0131nda bilgin olsun, fakat bu demek de\u011fil ki o konu hakk\u0131nda illa konu\u015fman gerekiyor, bu genelde antipatiktir \ud83d\ude42 Felsefe \u00f6\u011frenme konusu var ki e\u011fer buna girersem \u00e7ok fazla s\u0131k\u0131laca\u011f\u0131z. A\u011f\u0131r bir kitap fakat e\u011fer eline ge\u00e7erse G\u00f6del, Escher, Bach: Bir Ebedi G\u00f6k\u00e7e Belik.","title":"Her \u015feye bula\u015f, birinde usta ol"},{"location":"ogrenme-tekniklerim/#calstgn-konuyu-etrafn-haline-getir","text":"Bu asl\u0131nda her \u015fey i\u00e7in ge\u00e7erli, ne kadar maruz kal\u0131rsan bilgi o kadar kal\u0131c\u0131 olur. Bu konu hakk\u0131nda \u00e7al\u0131\u015f\u0131yorsan, topluluklara kat\u0131l, senin gibi insanlar\u0131 bul, muhabbet et. \u0130nsanlar\u0131 dinlerken yeni \u015feyler farkediyorsun, sen anlat\u0131rken bilgini tazeliyorsun. \u0130\u015fin en g\u00fczel k\u0131sm\u0131 ise e\u011flenerek yapt\u0131\u011f\u0131n i\u00e7in harika hissettiriyor. Bunlar\u0131 yapamaman m\u00fcmk\u00fcn de\u011fil, \u00e7\u00fcnk\u00fc insanlar fiziksel olarak etraf\u0131nda da olmas\u0131 gerekmiyor, farkl\u0131 bir dil \u00f6\u011freniyorsan o dili bilen insanlarla etkile\u015fime ge\u00e7, makine \u00f6\u011frenmesi \u00f6\u011freniyorsan Twitter\u2019dan bu insanlar\u0131 takip et, topluluklarda g\u00f6n\u00fcll\u00fc olarak etkinlik g\u00f6ster. Hatta bilgilerini insanlara aktarmak i\u00e7in bir YouTube kanal\u0131 a\u00e7 :) Sadece zihnini \u00e7al\u0131\u015ft\u0131\u011f\u0131n konu etraf\u0131nda aktif tutman yapaca\u011f\u0131n en g\u00fczel \u015fey olacakt\u0131r.","title":"\u00c7al\u0131\u015ft\u0131\u011f\u0131n konuyu etraf\u0131n haline getir"},{"location":"ogrenme-tekniklerim/#bir-seyi-ogrenmektamamlamak-icin-motivasyon-bulamyorsan-5-dakika-zorlan","text":"K\u0131r\u0131lma noktas\u0131 \u00f6rne\u011fi. O misafirlikteki \u00e7ocuk oldu\u011fun g\u00fcn\u00fc hat\u0131rla, ilk yar\u0131m saat koltukta suspus oturdu\u011fun, ak\u015fam olup da eve d\u00f6nerken evi talan eden \u00e7ocuktan bahsediyorum. Bir i\u015fe ba\u015flayam\u0131yorsan bir be\u015f dakika ba\u015f\u0131na oturup bir \u015feylerle ilgileniyormu\u015f, \u00e7al\u0131\u015f\u0131yormu\u015f gibi davran. Sadece taklit et. E\u011fer halen olmuyorsa g\u00fcn i\u00e7inde yapaca\u011f\u0131n di\u011fer i\u015fleri \u00f6nceliklendir o saat i\u00e7in, sonra tekrardan otur masan\u0131n ba\u015f\u0131na ve bir be\u015f dakika daha zorla kendini. Belki su o kadar fena de\u011fildir girince al\u0131\u015f\u0131yorsundur \ud83d\ude42","title":"Bir \u015feyi \u00f6\u011frenmek/tamamlamak i\u00e7in motivasyon bulam\u0131yorsan, 5 dakika zorlan"},{"location":"ogrenme-tekniklerim/#baslamadan-once-sakn-telefona-bakma","text":"Zor yoldan \u00f6\u011frendi\u011fim bir tuzak asl\u0131nda bu ve en k\u00f6t\u00fcs\u00fc ne biliyor musun? Bunu fark\u0131nda olmama ra\u011fmen halen d\u00fc\u015f\u00fcyorum. Eminim sen de d\u00fc\u015f\u00fcyorsun. \u00c7\u00fcnk\u00fc d\u00fc\u015fmemek elde de\u011fil. Sabah uyan\u0131yorsun ve evet bug\u00fcn bunu yapaca\u011f\u0131m diyorsun, yapaca\u011f\u0131n \u015fey \u00e7al\u0131\u015fmak veya seni zorlayan bir konu. E\u011fer \u00e7al\u0131\u015fmadan \u00f6nce bir kahvalt\u0131 yapay\u0131m, bir kendime geleyim gibi vakitlerinde telefonu eline al\u0131yorsan, o g\u00fcn i\u015fe ba\u015flaman a\u015f\u0131r\u0131 zor olacak. Bir t\u00fcrl\u00fc o konsantrasyon seviyesine ula\u015famayacaks\u0131n eminim. Bu y\u00fczden bir \u015fey yapaca\u011f\u0131m g\u00fcnlerde telefonu elime almamaya \u00e7al\u0131\u015f\u0131yorum. Verdi\u011fim molalarda biraz telefona bakay\u0131m demiyorum, tekrar i\u015fe d\u00f6nmesi en zor konumlardan biri bu oluyor. Laf\u0131 dalland\u0131r\u0131p uzatmayaca\u011f\u0131m bunu hepimiz biliyoruz, e\u011fer bir i\u015f yapacaksan o i\u015ften \u00f6nce telefona bakma.","title":"Ba\u015flamadan \u00f6nce sak\u0131n telefona bakma"},{"location":"ogrenme-tekniklerim/#kitap-onerileri","text":"Burada hangi kaynaklardan daha iyi makine \u00f6\u011frenimi \u00e7al\u0131\u015fabilirim gibi kitaplar\u0131 vermeyece\u011fim, bunu s\u0131k\u00e7a sorulan sorular makalemde payla\u015fm\u0131\u015ft\u0131m linki b\u0131rak\u0131yorum. Burada \u00e7al\u0131\u015fma tekni\u011finizi ve bak\u0131\u015f a\u00e7\u0131n\u0131z\u0131 ilerleten iki kitaptan bahsedece\u011fim, eminim \u00e7ok daha iyi veya harika kitaplar da vard\u0131r fakat bu ikisini okuyarak ba\u015flayabilirsin. Benim i\u00e7in ger\u00e7ekten \u00e7ok etkili oldular ve buraya bunlar\u0131 sadece yazmak i\u00e7in yazmad\u0131\u011f\u0131m bil.","title":"Kitap \u00f6nerileri"},{"location":"ogrenme-tekniklerim/#eminim-saka-yapyorsunuz-bay-feynman","text":"","title":"Eminim \u015eaka Yap\u0131yorsunuz Bay Feynman"},{"location":"ogrenme-tekniklerim/#scrum-iki-kat-isi-yar-zamanda-yapma-sanat","text":"","title":"Scrum: \u0130ki kat\u0131 i\u015fi yar\u0131 zamanda yapma sanat\u0131"},{"location":"ogrenme-tekniklerim/#referans-kaynaklar-yani-ezberlemek-zorunda-olmadklarn","text":"Bu b\u00f6l\u00fcme Einstein\u2019\u0131n \u00e7ok sevdi\u011fim bir s\u00f6z\u00fcyle ba\u015flamak istiyorum. G\u00fcn\u00fcn birinde Albert Einstein\u2019\u0131n bir meslekta\u015f\u0131 ona telefon numaras\u0131n\u0131 sorar. Einstein bir telefon rehberi al\u0131p numaras\u0131na bakar. Meslekta\u015f\u0131 \u015fa\u015f\u0131r\u0131r ve \u201cKendi numaran\u0131 bilmiyor musun?\u201d diye sorar. \u201cHay\u0131r\u201d der Einstein ve ekler, \u201cBir kitapta kolayca bulabilece\u011fim bir \u015feyi neden ezberleyeyim ki?\u201d. Asl\u0131nda Einstein 2 dakikadan daha k\u0131sa s\u00fcrede bulabilece\u011fi hi\u00e7bir \u015feyi ezberlemedi\u011fini a\u00e7\u0131klam\u0131\u015ft\u0131r. \u00d6\u011frenme a\u015famas\u0131nda ezbere ger\u00e7ekten kar\u015f\u0131y\u0131m, bir konuyu \u00f6\u011frenirken akl\u0131nda kalmas\u0131 gereken bilgiler veya y\u00fcksek \u00f6neme sahip olanlar kullanma s\u0131kl\u0131\u011f\u0131 nedeniyle her hal\u00fckarda beyninde ezbere oturur. Bunun d\u0131\u015f\u0131nda beyni ezberlemek i\u00e7in zorlamak seni ancak \u2018daha \u00e7ok biliyorum\u2019 g\u00f6r\u00fcnt\u00fcs\u00fc vermek i\u00e7in kendine yapt\u0131\u011f\u0131n bir il\u00fczyonun \u00f6tesine g\u00f6t\u00fcrmeyecektir. \u015e\u00f6yle d\u00fc\u015f\u00fcnelim, adaptif momentum(ADAM) optimizat\u00f6r\u00fcn\u00fcn form\u00fcl\u00fcn\u00fc ezberleyebilirim veya onu neden kulland\u0131\u011f\u0131m\u0131 ve ne zaman kullanmam gerekti\u011fini \u00f6\u011frenebilirim. Sence hangisini yapmam beni daha yetkin biri k\u0131lard\u0131? Bu soruya cevap vererek karar verebilirsin.","title":"Referans kaynaklar, yani ezberlemek zorunda olmad\u0131klar\u0131n"},{"location":"ogrenme-tekniklerim/#bir-seyi-unuttugunda-o-tamamen-yok-olmamstr","text":"Gelelim bir di\u011fer yan\u0131lg\u0131ya. Kaliteli bir kitap okuyorsun, g\u00fczel bir video e\u011fitim serisine denk geldin. \u00c7al\u0131\u015f\u0131yorsun, notlar\u0131n\u0131 ald\u0131n g\u00fczel birka\u00e7 noktay\u0131 kavrad\u0131n ve art\u0131k bu konuda daha bilgili oldu\u011funu hissediyorsun. Ertesi g\u00fcn bakt\u0131\u011f\u0131nda veya videoyu ikinci kez izledi\u011finde haf\u0131zanda birka\u00e7 iz oldu\u011funu fark ediyorsun fakat tam olarak ne oldu\u011funu hat\u0131rlam\u0131yorsun. Hepimiz ya\u015f\u0131yoruz bunu de\u011fil mi? Gayet normal, asl\u0131nda bu bir problem de de\u011fil. Maalesef halen belle\u011fimize veri yazam\u0131yoruz (yazsak harika olurdu). Her zaman yapt\u0131\u011f\u0131m\u0131z gibi bu durumu da kabullenmemiz gerekiyor fakat ben yine de senin i\u00e7in birka\u00e7 teknik verece\u011fim. Birinicisi \u00f6\u011frenme s\u00fcreci kolay de\u011fildir ve tekrar etmek gerekir. \u0130kincisi bunu hayat\u0131nda bir \u015fekilde uygulayarak peki\u015ftirmelisin. \u00dc\u00e7\u00fcnc\u00fcs\u00fc ayn\u0131 konuyu farkl\u0131 kaynaklardan \u00e7apraz \u00f6\u011frenme ile oturtman gerekir. Tabiat\u0131yla bu \u00f6\u011frenme s\u00fcrecini uzatacakt\u0131r burada bir pazarl\u0131k yapman gerek fakat ben genellikle \u015f\u00f6yle d\u00fc\u015f\u00fcn\u00fcyorum. Yola devam et ihtiyac\u0131n oldu\u011funda tekrar geriye d\u00f6n ve bak. E\u011fer hi\u00e7 kar\u015f\u0131la\u015fm\u0131yorsan \u00f6nem derecesi d\u00fc\u015f\u00fckt\u00fcr. Bunlar\u0131n yan\u0131nda bilgiyi \u00f6\u011frenirken beynin yeniden \u015fekillenir, ne oldu\u011funu unutsan dahi art\u0131k sen ayn\u0131 ki\u015fi de\u011filsin. Sana \u00e7al\u0131\u015ft\u0131\u011f\u0131n konu hakk\u0131nda farkl\u0131 bir bak\u0131\u015f a\u00e7\u0131s\u0131 \u00e7oktan kat\u0131ld\u0131, belki akl\u0131nda kalmad\u0131 fakat ba\u015fka bir konuyla kurulacak ba\u011f\u0131nt\u0131n\u0131n derecesi kuvvetlenmi\u015f oldu. Okumaya devam ettik\u00e7e sen d\u00fcnk\u00fc senden daha farkl\u0131 birisin! \u201cayn\u0131 nehirde iki kez y\u0131kan\u0131lmaz.\u201d","title":"Bir \u015feyi unuttu\u011funda o tamamen yok olmam\u0131\u015ft\u0131r"},{"location":"ogrenme-tekniklerim/#makine-ogrenmesinden-ogren","text":"Makine \u00f6\u011frenemesi teknikleri asl\u0131nda \u00f6\u011frenme felsefesinin rasyonel halidir. Modelleri daha iyi e\u011fitmek i\u00e7in kullan\u0131lan t\u00fcm teknikleri kendine yorabilirsin. \u00c7\u00fcnk\u00fc onlar da insanlardan ilham al\u0131narak geli\u015ftirildi, bu ba\u011flamda daha senin kendi i\u00e7inde ke\u015ffetmedi\u011fin teknikleri ke\u015ffeden di\u011fer insanlar bunu makinelere yapt\u0131rabilmek i\u00e7in \u00e7oktan matematiksel bir forma d\u00f6kt\u00fcler bile. \u0130ki \u00f6rnek b\u0131rakaca\u011f\u0131m fakat bunu d\u00fc\u015f\u00fcnerek geni\u015fletmelisin: Overfitting problemini \u00e7\u00f6zmek i\u00e7in modele daha fazla veri vermek. \u00dcniversitede \u00e7\u0131km\u0131\u015f sorularla okulu ge\u00e7en b\u00fcy\u00fck bir topluluk var, hepiniz onlar\u0131 tan\u0131yorsunuz. Bunlar k\u0131s\u0131tl\u0131 birka\u00e7 soru tipiyle s\u0131nava girerler ve belirli bir yere kadar ba\u015far\u0131 g\u00f6sterirler fakat hoca soru tipinde en ufak bir de\u011fi\u015fiklik yapt\u0131\u011f\u0131nda patlarlar. Fakat \u00e7ok fazla soru tipi g\u00f6rm\u00fc\u015f ki\u015filer i\u00e7in bu durum bir problem de\u011fildir. Model e\u011fitimi i\u00e7in veri \u00f6nhaz\u0131rl\u0131\u011f\u0131 yapmak. Herkes derli toplu kaynaklar\u0131, temiz bir yaz\u0131yla tutulmu\u015f notlar\u0131, iyi anlat\u0131lm\u0131\u015f konu anlat\u0131mlar\u0131n\u0131 sever. Bir konuya \u00e7al\u0131\u015fmadan \u00f6nce \u00e7al\u0131\u015faca\u011f\u0131n\u0131z kaynaklar\u0131 bu hale getirmek, hem motivasyonunuzu ayakta tutacakt\u0131r hem de fazla bilgi aras\u0131nda kaybolman\u0131z\u0131 engelleyecektir. E\u011fer \u00e7eviri hatalar\u0131 olan veya yanl\u0131\u015f bilgi i\u00e7ermesi muhtemel kaynaklar\u0131 (wikipedia, ek\u015fis\u00f6zl\u00fck, forumlar) akademik dersleriniz i\u00e7in kullan\u0131yorsan\u0131z yanl\u0131\u015f yere kur\u015fun at\u0131yor olabilirsiniz. Bu da size e\u011fitiminde daha y\u00fcksek cost ve daha d\u00fc\u015f\u00fck accuracy\u2019ye sebep olacakt\u0131r. Genel olarak benim \u00f6\u011frenme s\u00fcrecim b\u00f6yle i\u015fliyor. Bunlar\u0131 yaz\u0131ya d\u00f6kmesem belki ben de fark etmezdim neler yapt\u0131\u011f\u0131m\u0131. Belki de yapt\u0131\u011f\u0131m fakat unuttu\u011fum bir\u00e7ok \u015fey daha var. Di\u011fer \u00e7al\u0131\u015fmalar\u0131m\u0131 da takip etmek istersen twitter, youtube, medium ve githubday\u0131m. Twitter: mertcobanov Youtube: mertcobanov Medium: mertcobanov Originally published at https://cobanov.github.io .","title":"Makine \u00f6\u011frenmesinden \u00f6\u011fren"},{"location":"portfolio/","text":"Hey Cobanov Chrome Little Girls Women Cartoon Concept Art Cosmic People Line-art WLOP Coral & Glacier","title":"Hey"},{"location":"portfolio/#hey","text":"","title":"Hey"},{"location":"portfolio/#cobanov","text":"","title":"Cobanov"},{"location":"portfolio/#chrome","text":"","title":"Chrome"},{"location":"portfolio/#little-girls","text":"","title":"Little Girls"},{"location":"portfolio/#women","text":"","title":"Women"},{"location":"portfolio/#cartoon","text":"","title":"Cartoon"},{"location":"portfolio/#concept-art","text":"","title":"Concept Art"},{"location":"portfolio/#cosmic-people","text":"","title":"Cosmic People"},{"location":"portfolio/#line-art","text":"","title":"Line-art"},{"location":"portfolio/#wlop","text":"","title":"WLOP"},{"location":"portfolio/#coral-glacier","text":"","title":"Coral &amp; Glacier"},{"location":"stable/","text":"Cobanov's Stable Diffusion Notes Type's of Fine-tuning Source: reddit post 1. Textual Inversion Textual Inversion - trains a word with one or more vectors that approximate your image. So if it is something it already has seen lots of examples of, it might have the concept and just need to 'point' at it. It is just expanding the vocabulary of model but all information it uses is already in the model. 2. Dreambooth Dreambooth - this is essentially model fine tuning, which changes the weights of the main model. Dreambooth differs from typical fine tuning in that in tries to keep from forgetting/overwriting adjacent concepts during the tuning. 3. Hypernetwork Hypernetworks - this is basically an adaptive head - it takes information from late in the model but injects information from the prompt 'skipping' the rest of the model. So it is similar to fine tuning the last 2 layers of a model but it gets much more signal from the prompt (it is taking the clip embedding of the prompt right before the output layer). Discussions: Hypernetwork training topic Links Stable Diffusion Models","title":"Cobanov's Stable Diffusion Guide"},{"location":"stable/#cobanovs-stable-diffusion-notes","text":"","title":"Cobanov's Stable Diffusion Notes"},{"location":"stable/#types-of-fine-tuning","text":"Source: reddit post","title":"Type's of Fine-tuning"},{"location":"stable/#1-textual-inversion","text":"Textual Inversion - trains a word with one or more vectors that approximate your image. So if it is something it already has seen lots of examples of, it might have the concept and just need to 'point' at it. It is just expanding the vocabulary of model but all information it uses is already in the model.","title":"1. Textual Inversion"},{"location":"stable/#2-dreambooth","text":"Dreambooth - this is essentially model fine tuning, which changes the weights of the main model. Dreambooth differs from typical fine tuning in that in tries to keep from forgetting/overwriting adjacent concepts during the tuning.","title":"2. Dreambooth"},{"location":"stable/#3-hypernetwork","text":"Hypernetworks - this is basically an adaptive head - it takes information from late in the model but injects information from the prompt 'skipping' the rest of the model. So it is similar to fine tuning the last 2 layers of a model but it gets much more signal from the prompt (it is taking the clip embedding of the prompt right before the output layer).","title":"3. Hypernetwork"},{"location":"stable/#discussions","text":"Hypernetwork training topic","title":"Discussions:"},{"location":"stable/#links","text":"Stable Diffusion Models","title":"Links"}]}